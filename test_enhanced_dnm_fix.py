#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºDNMæ¡†æ¶ä¿®å¤ - Test Enhanced DNM Framework Fixes

éªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦æ­£å¸¸å·¥ä½œï¼š
1. æ¥å£å…¼å®¹æ€§ä¿®å¤
2. Net2Netå­ç½‘ç»œåˆ†æé›†æˆ
3. Sourceryä»£ç å®¡æŸ¥å»ºè®®å®ç°
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

def test_interface_compatibility():
    """æµ‹è¯•æ¥å£å…¼å®¹æ€§"""
    print("ğŸ”§ æµ‹è¯•æ¥å£å…¼å®¹æ€§...")
    
    try:
        from neuroexapt.core.enhanced_dnm_framework import EnhancedDNMFramework
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹
        model = nn.Sequential(
            nn.Linear(10, 20),
            nn.ReLU(),
            nn.Linear(20, 5)
        )
        
        # åˆ›å»ºDNMæ¡†æ¶
        dnm_framework = EnhancedDNMFramework()
        
        # æµ‹è¯•æ–°æ¥å£
        activations = {'layer1': torch.randn(32, 20)}
        gradients = {'layer1': torch.randn(32, 20)}
        performance_history = [0.7, 0.75, 0.8]
        epoch = 10
        targets = torch.randint(0, 5, (32,))
        
        result = dnm_framework.execute_morphogenesis(
            model, activations, gradients, performance_history, epoch, targets
        )
        
        print(f"   âœ… æ–°æ¥å£æµ‹è¯•é€šè¿‡: {result['morphogenesis_type']}")
        
        # æµ‹è¯•è€æ¥å£å…¼å®¹æ€§
        context = {
            'activations': activations,
            'gradients': gradients,
            'performance_history': performance_history,
            'epoch': epoch,
            'targets': targets
        }
        
        result_old = dnm_framework.execute_morphogenesis(model, context)
        
        print(f"   âœ… è€æ¥å£å…¼å®¹æ€§æµ‹è¯•é€šè¿‡: {result_old['morphogenesis_type']}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ¥å£å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_net2net_integration():
    """æµ‹è¯•Net2Neté›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•Net2Netå­ç½‘ç»œåˆ†æé›†æˆ...")
    
    try:
        from neuroexapt.core.net2net_subnetwork_analyzer import Net2NetSubnetworkAnalyzer
        
        # åˆ›å»ºå¤æ‚æ¨¡å‹
        model = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 10)
        )
        
        # åˆ›å»ºNet2Netåˆ†æå™¨
        analyzer = Net2NetSubnetworkAnalyzer()
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        activations = {
            '0': torch.randn(32, 32, 32, 32),  # Conv2dè¾“å‡º
            '2': torch.randn(32, 64, 32, 32),  # Conv2dè¾“å‡º
            '6': torch.randn(32, 10)           # Linearè¾“å‡º
        }
        
        gradients = {
            '0': torch.randn(32, 32, 32, 32),
            '2': torch.randn(32, 64, 32, 32),
            '6': torch.randn(32, 10)
        }
        
        targets = torch.randint(0, 10, (32,))
        current_accuracy = 0.75
        
        # æµ‹è¯•å±‚åˆ†æ
        result = analyzer.analyze_layer_mutation_potential(
            model, '2', activations, gradients, targets, current_accuracy
        )
        
        print(f"   âœ… Net2Netåˆ†ææµ‹è¯•é€šè¿‡")
        print(f"      å±‚å: {result['layer_name']}")
        print(f"      å»ºè®®è¡ŒåŠ¨: {result['recommendation']['action']}")
        print(f"      æ”¹è¿›æ½œåŠ›: {result['mutation_prediction']['improvement_potential']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Net2Neté›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"      è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def test_aggressive_morphogenesis_with_net2net():
    """æµ‹è¯•é›†æˆäº†Net2Netçš„æ¿€è¿›å½¢æ€å‘ç”Ÿ"""
    print("\nğŸš€ æµ‹è¯•æ¿€è¿›å½¢æ€å‘ç”Ÿä¸Net2Neté›†æˆ...")
    
    try:
        from neuroexapt.core.enhanced_dnm_framework import EnhancedDNMFramework
        
        # åˆ›å»ºæ¨¡å‹
        class TestModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.conv1 = nn.Conv2d(3, 64, 7)
                self.feature_block1 = nn.Sequential(
                    nn.Conv2d(64, 128, 3),
                    nn.ReLU()
                )
                self.classifier = nn.Sequential(
                    nn.Linear(128, 64),
                    nn.ReLU(),
                    nn.Linear(64, 10)
                )
            
            def forward(self, x):
                x = self.conv1(x)
                x = self.feature_block1(x)
                x = x.mean(dim=(2, 3))  # Global average pooling
                x = self.classifier(x)
                return x
        
        model = TestModel()
        
        # æ¿€è¿›æ¨¡å¼é…ç½®
        config = {
            'enable_aggressive_mode': True,
            'accuracy_plateau_threshold': 0.001,
            'aggressive_trigger_accuracy': 0.7,  # ä½é˜ˆå€¼ä¾¿äºæµ‹è¯•
            'max_concurrent_mutations': 2
        }
        
        dnm_framework = EnhancedDNMFramework(config=config)
        
        # åˆ›å»ºé«˜å‡†ç¡®ç‡åœæ»åœºæ™¯
        performance_history = [0.75, 0.752, 0.751, 0.752, 0.751]  # åœæ»çŠ¶æ€
        
        # æ¨¡æ‹Ÿæ¿€æ´»å’Œæ¢¯åº¦
        activations = {
            'conv1': torch.randn(32, 64, 26, 26),
            'feature_block1.0': torch.randn(32, 128, 24, 24),
            'classifier.0': torch.randn(32, 64),
            'classifier.2': torch.randn(32, 10)
        }
        
        gradients = {
            'conv1': torch.randn(32, 64, 26, 26),
            'feature_block1.0': torch.randn(32, 128, 24, 24),
            'classifier.0': torch.randn(32, 64),
            'classifier.2': torch.randn(32, 10)
        }
        
        targets = torch.randint(0, 10, (32,))
        epoch = 50
        
        # æ‰§è¡Œæ¿€è¿›å½¢æ€å‘ç”Ÿ
        result = dnm_framework.execute_morphogenesis(
            model, activations, gradients, performance_history, epoch, targets
        )
        
        print(f"   âœ… æ¿€è¿›å½¢æ€å‘ç”Ÿæµ‹è¯•é€šè¿‡")
        print(f"      å½¢æ€å‘ç”Ÿç±»å‹: {result['morphogenesis_type']}")
        print(f"      æ¨¡å‹æ˜¯å¦ä¿®æ”¹: {result['model_modified']}")
        print(f"      æ–°å¢å‚æ•°: {result['parameters_added']}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«Net2Netåˆ†æç»“æœ
        if 'aggressive_details' in result:
            details = result['aggressive_details']
            if 'net2net_analyses' in details:
                net2net_count = len(details['net2net_analyses'])
                print(f"      Net2Netåˆ†æå±‚æ•°: {net2net_count}")
            else:
                print(f"      âš ï¸ æœªåŒ…å«Net2Netåˆ†æç»“æœ")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ¿€è¿›å½¢æ€å‘ç”Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"      è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def test_device_consistency():
    """æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§ä¿®å¤"""
    print("\nğŸ–¥ï¸ æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§ä¿®å¤...")
    
    try:
        from neuroexapt.core.performance_guided_division import PerformanceGuidedDivision
        
        # åˆ›å»ºGPUæ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = nn.Linear(10, 5).to(device)
        
        # åˆ›å»ºæ€§èƒ½å¼•å¯¼åˆ†è£‚å™¨
        divider = PerformanceGuidedDivision()
        
        # æ¨¡æ‹Ÿåˆ†è£‚æ“ä½œ
        activations = torch.randn(32, 10).to(device)
        targets = torch.randint(0, 5, (32,)).to(device)
        
        # è¿™åº”è¯¥ä¸ä¼šå› ä¸ºè®¾å¤‡ä¸åŒ¹é…è€Œå¤±è´¥
        result = divider.execute_division(model, model[0], activations, targets)
        
        print(f"   âœ… è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
        print(f"      ä½¿ç”¨è®¾å¤‡: {device}")
        print(f"      åˆ†è£‚æˆåŠŸ: {result.get('success', False)}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§¬ å¢å¼ºDNMæ¡†æ¶ä¿®å¤éªŒè¯æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("æ¥å£å…¼å®¹æ€§", test_interface_compatibility),
        ("Net2Neté›†æˆ", test_net2net_integration),
        ("æ¿€è¿›å½¢æ€å‘ç”Ÿ+Net2Net", test_aggressive_morphogenesis_with_net2net),
        ("è®¾å¤‡ä¸€è‡´æ€§", test_device_consistency)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\nâŒ æµ‹è¯• {test_name} å‡ºç°å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed_count = 0
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if success:
            passed_count += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed_count}/{len(results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed_count == len(results):
        print("ğŸ‰ æ‰€æœ‰ä¿®å¤éªŒè¯æˆåŠŸï¼å¯ä»¥ç»§ç»­è®­ç»ƒã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³æ¨¡å—ã€‚")
    
    return passed_count == len(results)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)