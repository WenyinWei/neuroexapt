#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•é«˜çº§å½¢æ€å‘ç”ŸåŠŸèƒ½
"""

import sys
sys.path.append('/workspace')

import torch
import torch.nn as nn
import torch.nn.functional as F

# å¯¼å…¥å¢å¼ºçš„DNMç»„ä»¶
from neuroexapt.core import (
    AdvancedMorphogenesisExecutor,
    MorphogenesisType,
    MorphogenesisDecision
)

class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 10)
        )
    
    def forward(self, x):
        return self.classifier(x)

def test_morphogenesis_types():
    """æµ‹è¯•æ‰€æœ‰å½¢æ€å‘ç”Ÿç±»å‹"""
    print("ğŸ§¬ å¿«é€Ÿæµ‹è¯•é«˜çº§å½¢æ€å‘ç”ŸåŠŸèƒ½")
    print("=" * 50)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æµ‹è¯•æ¯ç§å½¢æ€å‘ç”Ÿç±»å‹
    morphogenesis_types = [
        MorphogenesisType.WIDTH_EXPANSION,
        MorphogenesisType.SERIAL_DIVISION,
        MorphogenesisType.PARALLEL_DIVISION,
        MorphogenesisType.HYBRID_DIVISION
    ]
    
    results = {}
    
    for morph_type in morphogenesis_types:
        print(f"\nğŸ”¬ æµ‹è¯• {morph_type.value}...")
        
        model = SimpleNet().to(device)
        original_params = sum(p.numel() for p in model.parameters())
        
        # åˆ›å»ºå†³ç­–
        decision = MorphogenesisDecision(
            morphogenesis_type=morph_type,
            target_location='classifier.0',  # ç¬¬ä¸€ä¸ªçº¿æ€§å±‚
            confidence=0.8,
            expected_improvement=0.05,
            complexity_cost=0.3,
            parameters_added=5000,
            reasoning=f"æµ‹è¯•{morph_type.value}"
        )
        
        # æ‰§è¡Œå½¢æ€å‘ç”Ÿ
        executor = AdvancedMorphogenesisExecutor()
        try:
            new_model, params_added = executor.execute_morphogenesis(model, decision)
            new_params = sum(p.numel() for p in new_model.parameters())
            
            # æµ‹è¯•åŠŸèƒ½
            test_input = torch.randn(4, 256).to(device)
            with torch.no_grad():
                output = new_model(test_input)
            
            results[morph_type.value] = {
                'success': True,
                'original_params': original_params,
                'new_params': new_params,
                'params_added': params_added,
                'growth_ratio': (new_params - original_params) / original_params,
                'output_shape': output.shape
            }
            
            print(f"    âœ… æˆåŠŸ")
            print(f"    åŸå§‹å‚æ•°: {original_params:,}")
            print(f"    æ–°å¢å‚æ•°: {params_added:,}")
            print(f"    æ€»å‚æ•°: {new_params:,}")
            print(f"    å¢é•¿ç‡: {results[morph_type.value]['growth_ratio']:.1%}")
            print(f"    è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
        except Exception as e:
            results[morph_type.value] = {
                'success': False,
                'error': str(e)
            }
            print(f"    âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ‰“å°æ€»ç»“
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    successful_types = [t for t, r in results.items() if r.get('success', False)]
    print(f"  æˆåŠŸçš„å½¢æ€å‘ç”Ÿç±»å‹: {len(successful_types)}/4")
    print(f"  æ”¯æŒçš„ç±»å‹: {successful_types}")
    
    if len(successful_types) == 4:
        print("  ğŸ‰ æ‰€æœ‰é«˜çº§å½¢æ€å‘ç”ŸåŠŸèƒ½æ­£å¸¸å·¥ä½œ!")
    else:
        print("  âš ï¸ éƒ¨åˆ†å½¢æ€å‘ç”Ÿéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    return results

if __name__ == "__main__":
    test_morphogenesis_types()