#!/usr/bin/env python3
"""
å†…å­˜å®‰å…¨çš„DNMæ¡†æ¶æµ‹è¯•
ä¿®å¤äº†å†…å­˜çˆ†ç‚¸é—®é¢˜ï¼Œå®‰å…¨åœ°æµ‹è¯•å¢å¼ºDNMæ¡†æ¶
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import gc
import psutil
import os
from collections import defaultdict
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '.'))

from neuroexapt.core.enhanced_dnm_framework import EnhancedDNMFramework

def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    return {
        'rss': memory_info.rss / 1024 / 1024,  # MB
        'vms': memory_info.vms / 1024 / 1024,  # MB
        'percent': process.memory_percent()
    }

def print_memory_info(stage=""):
    """æ‰“å°å†…å­˜ä¿¡æ¯"""
    mem = get_memory_usage()
    gpu_mem = ""
    if torch.cuda.is_available():
        gpu_allocated = torch.cuda.memory_allocated() / 1024 / 1024  # MB
        gpu_cached = torch.cuda.memory_reserved() / 1024 / 1024  # MB
        gpu_mem = f", GPU: {gpu_allocated:.1f}MB allocated, {gpu_cached:.1f}MB cached"
    
    print(f"ğŸ§  {stage} å†…å­˜ä½¿ç”¨: {mem['rss']:.1f}MB ({mem['percent']:.1f}%){gpu_mem}")

def create_simple_model():
    """åˆ›å»ºç®€å•çš„æµ‹è¯•æ¨¡å‹"""
    return nn.Sequential(
        nn.Conv2d(3, 16, 3, padding=1),
        nn.ReLU(),
        nn.Conv2d(16, 32, 3, padding=1),
        nn.ReLU(),
        nn.AdaptiveAvgPool2d((4, 4)),
        nn.Flatten(),
        nn.Linear(32 * 4 * 4, 64),
        nn.ReLU(),
        nn.Linear(64, 10)
    )

def generate_mock_data(batch_size=32, image_size=32):
    """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
    x = torch.randn(batch_size, 3, image_size, image_size)
    y = torch.randint(0, 10, (batch_size,))
    return x, y

def collect_activations_and_gradients_safe(model, x, y, max_layers=10):
    """å®‰å…¨åœ°æ”¶é›†æ¿€æ´»å€¼å’Œæ¢¯åº¦ï¼Œé™åˆ¶å±‚æ•°å’Œå†…å­˜ä½¿ç”¨"""
    activations = {}
    gradients = {}
    
    # æ·»åŠ hookæ¥æ”¶é›†æ¿€æ´»å€¼
    hooks = []
    layer_names = []
    layer_count = 0
    
    def make_activation_hook(name):
        def hook(module, input, output):
            # å†…å­˜ä¼˜åŒ–ï¼šåªä¿å­˜éƒ¨åˆ†æ¿€æ´»å€¼
            if isinstance(output, torch.Tensor):
                # é™åˆ¶æ‰¹æ¬¡å¤§å°å’Œç‰¹å¾ç»´åº¦
                reduced_output = output.detach()
                if reduced_output.numel() > 100000:  # è¶…è¿‡10ä¸‡å…ƒç´ å°±é‡‡æ ·
                    # ä¿æŒå½¢çŠ¶ä½†å‡å°‘å…ƒç´ 
                    if len(reduced_output.shape) == 4:  # Convå±‚
                        reduced_output = reduced_output[:min(16, reduced_output.shape[0])]  # é™åˆ¶æ‰¹æ¬¡
                    elif len(reduced_output.shape) == 2:  # Linearå±‚
                        reduced_output = reduced_output[:min(32, reduced_output.shape[0])]  # é™åˆ¶æ‰¹æ¬¡
                activations[name] = reduced_output
        return hook
    
    # æ³¨å†Œå‰å‘hook - é™åˆ¶å±‚æ•°
    for name, module in model.named_modules():
        if isinstance(module, (nn.Linear, nn.Conv2d)) and layer_count < max_layers:
            layer_names.append(name)
            hooks.append(module.register_forward_hook(make_activation_hook(name)))
            layer_count += 1
    
    print(f"ğŸ“Š æ³¨å†Œäº† {len(hooks)} ä¸ªhook")
    
    # å‰å‘ä¼ æ’­
    model.train()
    output = model(x)
    loss = nn.CrossEntropyLoss()(output, y)
    
    print(f"ğŸ“Š æ”¶é›†åˆ° {len(activations)} å±‚æ¿€æ´»å€¼")
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ”¶é›†æ¢¯åº¦ - åªæ”¶é›†å‚æ•°æ¢¯åº¦ï¼Œä¸æ˜¯æ¿€æ´»å€¼æ¢¯åº¦
    for name, module in model.named_modules():
        if isinstance(module, (nn.Linear, nn.Conv2d)) and name in layer_names:
            if hasattr(module, 'weight') and module.weight.grad is not None:
                # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶æ¢¯åº¦å¤§å°
                grad = module.weight.grad.detach().clone()
                if grad.numel() > 100000:  # è¶…è¿‡10ä¸‡å…ƒç´ å°±é‡‡æ ·
                    # éšæœºé‡‡æ ·æ¢¯åº¦
                    flat_grad = grad.flatten()
                    indices = torch.randperm(len(flat_grad))[:100000]
                    sampled_grad = flat_grad[indices].view(-1, 1)  # é‡å¡‘ä¸º2D
                    gradients[name] = sampled_grad
                else:
                    gradients[name] = grad
    
    print(f"ğŸ“Š æ”¶é›†åˆ° {len(gradients)} å±‚æ¢¯åº¦")
    
    # æ¸…ç†hooks
    for hook in hooks:
        hook.remove()
    
    return activations, gradients, loss.item()

def memory_safe_dnm_test():
    """å†…å­˜å®‰å…¨çš„DNMæµ‹è¯•"""
    print("=" * 80)
    print("ğŸ§¬ å†…å­˜å®‰å…¨çš„å¢å¼ºDNMæ¡†æ¶æµ‹è¯•")
    print("=" * 80)
    
    print_memory_info("åˆå§‹")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ“± åˆ›å»ºæµ‹è¯•æ¨¡å‹...")
    model = create_simple_model().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    print_memory_info("æ¨¡å‹åˆ›å»ºå")
    
    # åˆ›å»ºDNMæ¡†æ¶
    print("\nğŸ§¬ åˆå§‹åŒ–å¢å¼ºDNMæ¡†æ¶...")
    dnm_framework = EnhancedDNMFramework()
    
    # ä¿®æ”¹é…ç½®ä»¥é™ä½å†…å­˜ä½¿ç”¨
    dnm_framework.config['trigger_interval'] = 2  # æ›´é¢‘ç¹è§¦å‘ä»¥æµ‹è¯•
    dnm_framework.config['max_parameter_growth_ratio'] = 0.1  # é™åˆ¶å‚æ•°å¢é•¿
    
    print_memory_info("DNMæ¡†æ¶åˆå§‹åŒ–å")
    
    # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
    print("\nğŸš€ å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒ...")
    max_epochs = 3  # å‡å°‘epochæ•°é‡
    
    for epoch in range(max_epochs):
        print(f"\n" + "="*60)
        print(f"ğŸ“Š Epoch {epoch + 1}/{max_epochs}")
        print("="*60)
        
        print_memory_info(f"Epoch {epoch+1} å¼€å§‹")
        
        # ç”Ÿæˆæ•°æ® - ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡å’Œå›¾åƒ
        x, y = generate_mock_data(batch_size=16, image_size=32)  # å‡å°æ‰¹æ¬¡å¤§å°
        x, y = x.to(device), y.to(device)
        
        # æ”¶é›†æ¿€æ´»å€¼å’Œæ¢¯åº¦
        print(f"\nğŸ” æ”¶é›†æ¿€æ´»å€¼å’Œæ¢¯åº¦...")
        try:
            activations, gradients, loss_value = collect_activations_and_gradients_safe(
                model, x, y, max_layers=8  # é™åˆ¶åˆ†æçš„å±‚æ•°
            )
            
            print(f"ğŸ“Š è®­ç»ƒæŸå¤±: {loss_value:.4f}")
            print_memory_info("æ•°æ®æ”¶é›†å")
            
            # æ›´æ–°æ€§èƒ½å†å²
            accuracy = np.random.uniform(0.75, 0.95)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡
            dnm_framework.update_performance_history(accuracy)
            print(f"ğŸ“Š æ¨¡æ‹Ÿå‡†ç¡®ç‡: {accuracy:.4f}")
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context = {
                'epoch': epoch,
                'activations': activations,
                'gradients': gradients,
                'performance_history': dnm_framework.performance_history,
                'loss': loss_value,
                'accuracy': accuracy
            }
            
            # æ‰§è¡Œå½¢æ€å‘ç”Ÿ
            print(f"\nğŸ§¬ æ‰§è¡Œå½¢æ€å‘ç”Ÿæ£€æŸ¥...")
            results = dnm_framework.execute_morphogenesis(model, context)
            
            print_memory_info("å½¢æ€å‘ç”Ÿå")
            
            # è¾“å‡ºç»“æœ
            print(f"\nğŸ“‹ å½¢æ€å‘ç”Ÿç»“æœ:")
            print(f"  - æ¨¡å‹æ˜¯å¦ä¿®æ”¹: {results['model_modified']}")
            print(f"  - æ–°å¢å‚æ•°: {results['parameters_added']:,}")
            print(f"  - å½¢æ€å‘ç”Ÿç±»å‹: {results['morphogenesis_type']}")
            print(f"  - è§¦å‘åŸå› æ•°é‡: {len(results.get('trigger_reasons', []))}")
            
            if results['model_modified']:
                print(f"  - å†³ç­–ç½®ä¿¡åº¦: {results.get('decision_confidence', 0):.3f}")
                print(f"  - é¢„æœŸæ”¹è¿›: {results.get('expected_improvement', 0):.3f}")
                model = results['new_model']
                print(f"âœ… æ¨¡å‹å·²æ›´æ–°ï¼")
            else:
                print(f"âŒ æœªè§¦å‘å½¢æ€å‘ç”Ÿ")
            
            # ä¼˜åŒ–å™¨æ­¥éª¤
            optimizer.zero_grad()
            
            # å¼ºåˆ¶å†…å­˜æ¸…ç†
            del activations, gradients, x, y
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print_memory_info(f"Epoch {epoch+1} ç»“æŸ")
            
        except Exception as e:
            print(f"\nâŒ Epoch {epoch+1} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # ç´§æ€¥å†…å­˜æ¸…ç†
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            break
        
        print(f"\n" + "-"*50)
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    print(f"\n" + "="*80)
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
    print("="*80)
    
    try:
        summary = dnm_framework.get_morphogenesis_summary()
        print(f"æ€»å½¢æ€å‘ç”Ÿäº‹ä»¶: {summary['total_events']}")
        print(f"æ€»æ–°å¢å‚æ•°: {summary['total_parameters_added']:,}")
        print(f"å½¢æ€å‘ç”Ÿç±»å‹åˆ†å¸ƒ: {summary['morphogenesis_types']}")
        
        if summary['events']:
            print(f"\nè¯¦ç»†äº‹ä»¶åˆ—è¡¨:")
            for i, event in enumerate(summary['events'], 1):
                print(f"  {i}. Epoch {event['epoch']}: {event['type']} "
                      f"(å‚æ•°+{event['parameters_added']:,}, ç½®ä¿¡åº¦{event['confidence']:.3f})")
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡ç”Ÿæˆå¤±è´¥: {e}")
    
    print_memory_info("æœ€ç»ˆ")
    print(f"\nâœ… å†…å­˜å®‰å…¨æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    memory_safe_dnm_test()