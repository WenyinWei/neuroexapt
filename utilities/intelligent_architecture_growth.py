#!/usr/bin/env python3
"""
NeuroExapt - æ™ºèƒ½æ¶æ„ç”Ÿé•¿ç³»ç»Ÿ
æ ¹æ®è¾“å…¥è¾“å‡ºåé¦ˆï¼Œå¿«é€Ÿç”Ÿé•¿åˆ°æœ€é€‚åˆçš„æ¶æ„

ç»“åˆä¿¡æ¯è®ºã€ç¥ç»æ­£åˆ‡æ ¸ç†è®ºã€éå‡¸ä¼˜åŒ–ç­‰å¤šç§ç†è®º
å®ç°çœŸæ­£çš„"ä¸€æ­¥åˆ°ä½"æ¶æ„æ¼”åŒ–
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import numpy as np
from scipy.optimize import differential_evolution
import networkx as nx
from sklearn.decomposition import PCA
import math
import sys
import os

# Add neuroexapt to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from neuroexapt.trainer import Trainer, train_with_neuroexapt


class IntelligentGrowthEngine:
    """æ™ºèƒ½æ¶æ„ç”Ÿé•¿å¼•æ“"""
    
    def __init__(self, input_shape, num_classes, device):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.device = device
        
        # æ¶æ„ç”Ÿé•¿å‚æ•°
        self.min_channels = 16
        self.max_channels = 512
        self.min_layers = 2
        self.max_layers = 20
        
        # æ€§èƒ½è¿½è¸ª
        self.growth_history = []
    
    def analyze_io_requirements(self, train_loader, target_accuracy=0.9):
        """æ·±åº¦åˆ†æè¾“å…¥è¾“å‡ºè¦æ±‚ï¼Œç¡®å®šæœ€ä¼˜æ¶æ„"""
        print("ğŸ” æ·±åº¦åˆ†æè¾“å…¥è¾“å‡ºè¦æ±‚...")
        
        # 1. æ•°æ®å¤æ‚åº¦åˆ†æ
        data_complexity = self._analyze_data_complexity(train_loader)
        print(f"  æ•°æ®å¤æ‚åº¦åˆ†æ: {data_complexity}")
        
        # 2. ä»»åŠ¡éš¾åº¦ä¼°è®¡
        task_difficulty = self._estimate_task_difficulty(train_loader)
        print(f"  ä»»åŠ¡éš¾åº¦ä¼°è®¡: {task_difficulty}")
        
        # 3. ç†è®ºå®¹é‡éœ€æ±‚è®¡ç®—
        capacity_requirement = self._calculate_capacity_requirement(
            data_complexity, task_difficulty, target_accuracy
        )
        print(f"  ç†è®ºå®¹é‡éœ€æ±‚: {capacity_requirement}")
        
        # 4. ç›´æ¥ç”Ÿæˆæœ€ä¼˜æ¶æ„
        optimal_architecture = self._design_optimal_architecture(
            data_complexity, task_difficulty, capacity_requirement
        )
        
        return optimal_architecture
    
    def _analyze_data_complexity(self, train_loader):
        """åˆ†ææ•°æ®å¤æ‚åº¦"""
        # æ”¶é›†æ ·æœ¬æ•°æ®
        samples = []
        labels = []
        
        for batch_idx, (data, target) in enumerate(train_loader):
            samples.append(data)
            labels.append(target)
            if batch_idx >= 10:  # åˆ†æè¶³å¤Ÿçš„æ ·æœ¬
                break
        
        X = torch.cat(samples, dim=0)
        y = torch.cat(labels, dim=0)
        
        # æ•°æ®å¤æ‚åº¦æŒ‡æ ‡
        complexity_metrics = {}
        
        # 1. åƒç´ æ–¹å·®åˆ†æ
        pixel_variance = torch.var(X.view(X.size(0), -1), dim=0).mean().item()
        complexity_metrics['pixel_variance'] = pixel_variance
        
        # 2. é¢‘åŸŸå¤æ‚åº¦
        freq_complexity = self._analyze_frequency_complexity(X)
        complexity_metrics['frequency_complexity'] = freq_complexity
        
        # 3. ç±»åˆ«åˆ†å¸ƒå¤æ‚åº¦
        class_distribution = torch.bincount(y).float()
        class_entropy = -(class_distribution / class_distribution.sum() * 
                         torch.log(class_distribution / class_distribution.sum() + 1e-10)).sum().item()
        complexity_metrics['class_entropy'] = class_entropy
        
        # 4. ç©ºé—´ç›¸å…³æ€§åˆ†æ
        spatial_correlation = self._analyze_spatial_correlation(X)
        complexity_metrics['spatial_correlation'] = spatial_correlation
        
        # ç»¼åˆå¤æ‚åº¦è¯„åˆ†
        overall_complexity = (
            pixel_variance * 0.3 +
            freq_complexity * 0.3 +
            class_entropy * 0.2 +
            (1 - spatial_correlation) * 0.2
        )
        
        complexity_metrics['overall_complexity'] = overall_complexity
        
        return complexity_metrics
    
    def _analyze_frequency_complexity(self, X):
        """åˆ†æé¢‘åŸŸå¤æ‚åº¦"""
        # å–å‡ ä¸ªæ ·æœ¬è¿›è¡ŒFFTåˆ†æ
        sample = X[:4].cpu().numpy()
        
        freq_energies = []
        for img in sample:
            # å¯¹æ¯ä¸ªé€šé“è¿›è¡ŒFFT
            for channel in img:
                fft = np.fft.fft2(channel)
                fft_magnitude = np.abs(fft)
                
                # é«˜é¢‘èƒ½é‡æ¯”ä¾‹
                h, w = fft_magnitude.shape
                high_freq_mask = np.zeros_like(fft_magnitude)
                high_freq_mask[h//4:3*h//4, w//4:3*w//4] = 1
                
                high_freq_energy = np.sum(fft_magnitude * high_freq_mask)
                total_energy = np.sum(fft_magnitude)
                
                freq_energies.append(high_freq_energy / (total_energy + 1e-10))
        
        return np.mean(freq_energies)
    
    def _analyze_spatial_correlation(self, X):
        """åˆ†æç©ºé—´ç›¸å…³æ€§"""
        # å–æ ·æœ¬åˆ†æ
        sample = X[:8].cpu().numpy()
        
        correlations = []
        for img in sample:
            for channel in img:
                # è®¡ç®—ç›¸é‚»åƒç´ çš„ç›¸å…³æ€§
                h_corr = np.corrcoef(channel[:-1, :].flatten(), channel[1:, :].flatten())[0, 1]
                v_corr = np.corrcoef(channel[:, :-1].flatten(), channel[:, 1:].flatten())[0, 1]
                
                if not np.isnan(h_corr):
                    correlations.append(abs(h_corr))
                if not np.isnan(v_corr):
                    correlations.append(abs(v_corr))
        
        return np.mean(correlations) if correlations else 0
    
    def _estimate_task_difficulty(self, train_loader):
        """ä¼°è®¡ä»»åŠ¡éš¾åº¦"""
        # ä½¿ç”¨ç®€å•æ¨¡å‹å¿«é€Ÿè¯„ä¼°ä»»åŠ¡åŸºç¡€éš¾åº¦
        simple_model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(3 * 32 * 32, 128),
            nn.ReLU(),
            nn.Linear(128, self.num_classes)
        ).to(self.device)
        
        # å¿«é€Ÿè®­ç»ƒ
        optimizer = optim.Adam(simple_model.parameters(), lr=0.01)
        criterion = nn.CrossEntropyLoss()
        
        simple_model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            if batch_idx >= 20:  # åªè®­ç»ƒå°‘é‡batch
                break
            
            data, target = data.to(self.device), target.to(self.device)
            optimizer.zero_grad()
            output = simple_model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
        
        # è¯„ä¼°ç®€å•æ¨¡å‹æ€§èƒ½
        simple_model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(train_loader):
                if batch_idx >= 10:
                    break
                
                data, target = data.to(self.device), target.to(self.device)
                output = simple_model(data)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
        
        simple_accuracy = correct / total if total > 0 else 0
        
        # ä»»åŠ¡éš¾åº¦è¯„åˆ†ï¼ˆç®€å•æ¨¡å‹å‡†ç¡®åº¦è¶Šä½ï¼Œä»»åŠ¡è¶Šéš¾ï¼‰
        task_difficulty = 1.0 - simple_accuracy
        
        return {
            'simple_model_accuracy': simple_accuracy,
            'difficulty_score': task_difficulty,
            'requires_complex_features': task_difficulty > 0.7,
            'requires_deep_hierarchy': task_difficulty > 0.8
        }
    
    def _calculate_capacity_requirement(self, data_complexity, task_difficulty, target_accuracy):
        """è®¡ç®—ç†è®ºå®¹é‡éœ€æ±‚"""
        # åŸºäºä¿¡æ¯è®ºå’Œç»Ÿè®¡å­¦ä¹ ç†è®ºè®¡ç®—æ‰€éœ€å®¹é‡
        
        # æ•°æ®å¤æ‚åº¦å› å­
        complexity_factor = data_complexity['overall_complexity']
        
        # ä»»åŠ¡éš¾åº¦å› å­
        difficulty_factor = task_difficulty['difficulty_score']
        
        # ç›®æ ‡å‡†ç¡®åº¦è¦æ±‚
        accuracy_factor = target_accuracy / (1 - target_accuracy + 1e-10)
        
        # ç†è®ºæœ€å°å‚æ•°æ•°é‡ä¼°è®¡
        input_size = np.prod(self.input_shape)
        min_params = input_size * self.num_classes
        
        # å®¹é‡ç¼©æ”¾å› å­
        capacity_multiplier = (1 + complexity_factor) * (1 + difficulty_factor) * (1 + accuracy_factor)
        
        required_capacity = min_params * capacity_multiplier
        
        return {
            'min_parameters': int(required_capacity),
            'complexity_factor': complexity_factor,
            'difficulty_factor': difficulty_factor,
            'accuracy_factor': accuracy_factor,
            'capacity_multiplier': capacity_multiplier
        }
    
    def _design_optimal_architecture(self, data_complexity, task_difficulty, capacity_requirement):
        """è®¾è®¡æœ€ä¼˜æ¶æ„"""
        print("ğŸ—ï¸ è®¾è®¡æœ€ä¼˜æ¶æ„...")
        
        # ç¡®å®šæ¶æ„åŸºæœ¬å‚æ•°
        min_params = capacity_requirement['min_parameters']
        
        # 1. ç¡®å®šç½‘ç»œæ·±åº¦
        if task_difficulty['requires_deep_hierarchy']:
            target_depth = 12  # æ·±å±‚ç½‘ç»œ
        elif task_difficulty['requires_complex_features']:
            target_depth = 8   # ä¸­ç­‰æ·±åº¦
        else:
            target_depth = 5   # æµ…å±‚ç½‘ç»œ
        
        # 2. ç¡®å®šæ¯å±‚å®½åº¦
        # ä½¿ç”¨å€’é‡‘å­—å¡”ç»“æ„ï¼šé€å±‚å‡åŠ
        layer_widths = []
        current_width = min(512, max(64, int((min_params / target_depth) ** 0.5)))
        
        for i in range(target_depth):
            layer_widths.append(current_width)
            # æ¯ä¸¤å±‚å‡åŠï¼Œä½†ä¸ä½äº32
            if i % 2 == 1:
                current_width = max(32, current_width // 2)
        
        # 3. ç¡®å®šæ¶æ„ç‰¹æ€§
        architecture_features = {
            'use_residual': task_difficulty['requires_deep_hierarchy'],
            'use_attention': data_complexity['frequency_complexity'] > 0.3,
            'use_multiscale': data_complexity['spatial_correlation'] < 0.7,
            'use_normalization': True,
            'activation_type': 'gelu' if task_difficulty['difficulty_score'] > 0.6 else 'relu'
        }
        
        # 4. ç”Ÿæˆå®Œæ•´æ¶æ„æè¿°
        optimal_architecture = {
            'depth': target_depth,
            'layer_widths': layer_widths,
            'features': architecture_features,
            'estimated_params': sum(
                layer_widths[i] * layer_widths[i+1] if i < len(layer_widths)-1 
                else layer_widths[i] * self.num_classes
                for i in range(len(layer_widths))
            ),
            'design_rationale': {
                'depth_reason': 'Deep hierarchy needed' if task_difficulty['requires_deep_hierarchy'] else 'Moderate depth sufficient',
                'width_reason': f'Balanced capacity for {min_params} parameter requirement',
                'features_reason': 'Selected based on data complexity analysis'
            }
        }
        
        print(f"  è®¾è®¡æ·±åº¦: {target_depth}")
        print(f"  å±‚å®½åº¦: {layer_widths}")
        print(f"  ä¼°è®¡å‚æ•°: {optimal_architecture['estimated_params']:,}")
        print(f"  ç‰¹æ®Šç‰¹æ€§: {list(architecture_features.keys())}")
        
        return optimal_architecture
    
    def build_optimal_model(self, architecture):
        """æ„å»ºæœ€ä¼˜æ¨¡å‹"""
        print("ğŸ”¨ æ„å»ºæœ€ä¼˜æ¨¡å‹...")
        
        return OptimalArchitectureModel(
            input_channels=self.input_shape[0],
            num_classes=self.num_classes,
            architecture=architecture
        ).to(self.device)


class OptimalArchitectureModel(nn.Module):
    """æ ¹æ®åˆ†æç»“æœæ„å»ºçš„æœ€ä¼˜æ¶æ„æ¨¡å‹"""
    
    def __init__(self, input_channels, num_classes, architecture):
        super().__init__()
        
        self.architecture = architecture
        self.layer_widths = architecture['layer_widths']
        self.features_config = architecture['features']
        
        # æ„å»ºç‰¹å¾æå–å™¨
        self.features = self._build_feature_extractor(input_channels)
        
        # æ„å»ºåˆ†ç±»å™¨
        final_feature_size = self._calculate_final_feature_size()
        self.classifier = self._build_classifier(final_feature_size, num_classes)
        
        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()
    
    def _build_feature_extractor(self, input_channels):
        """æ„å»ºç‰¹å¾æå–å™¨"""
        layers = []
        current_channels = input_channels
        
        for i, width in enumerate(self.layer_widths):
            # å·ç§¯å±‚
            conv_layer = nn.Conv2d(current_channels, width, 3, padding=1, bias=False)
            layers.append(conv_layer)
            
            # æ‰¹å½’ä¸€åŒ–
            if self.features_config['use_normalization']:
                layers.append(nn.BatchNorm2d(width))
            
            # æ¿€æ´»å‡½æ•°
            if self.features_config['activation_type'] == 'gelu':
                layers.append(nn.GELU())
            else:
                layers.append(nn.ReLU(inplace=True))
            
            # æ³¨æ„åŠ›æœºåˆ¶
            if self.features_config['use_attention'] and i % 3 == 2:
                layers.append(ChannelAttention(width))
            
            # æ± åŒ–ï¼ˆæ¯éš”ä¸€å±‚ï¼‰
            if i % 2 == 1 and i < len(self.layer_widths) - 1:
                layers.append(nn.MaxPool2d(2, 2))
            
            # æ®‹å·®è¿æ¥æ”¯æŒ
            if self.features_config['use_residual'] and i > 0 and i % 2 == 1:
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å¤„ç†ç»´åº¦åŒ¹é…
                pass
            
            current_channels = width
        
        # å…¨å±€å¹³å‡æ± åŒ–
        layers.append(nn.AdaptiveAvgPool2d(1))
        
        return nn.Sequential(*layers)
    
    def _build_classifier(self, input_size, num_classes):
        """æ„å»ºåˆ†ç±»å™¨"""
        # ç®€å•ä½†æœ‰æ•ˆçš„åˆ†ç±»å™¨
        return nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(input_size, max(128, num_classes * 8)),
            nn.GELU() if self.features_config['activation_type'] == 'gelu' else nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(max(128, num_classes * 8), num_classes)
        )
    
    def _calculate_final_feature_size(self):
        """è®¡ç®—æœ€ç»ˆç‰¹å¾å¤§å°"""
        return self.layer_widths[-1]
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


class ChannelAttention(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å—"""
    
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)


def rapid_architecture_optimization(train_loader, val_loader, target_accuracy=0.9):
    """å¿«é€Ÿæ¶æ„ä¼˜åŒ–ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¿«é€Ÿæ¶æ„ä¼˜åŒ–...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åˆ›å»ºæ™ºèƒ½ç”Ÿé•¿å¼•æ“
    growth_engine = IntelligentGrowthEngine(
        input_shape=(3, 32, 32),
        num_classes=10,
        device=device
    )
    
    # åˆ†æè¾“å…¥è¾“å‡ºè¦æ±‚å¹¶è®¾è®¡æœ€ä¼˜æ¶æ„
    optimal_architecture = growth_engine.analyze_io_requirements(
        train_loader, target_accuracy
    )
    
    # æ„å»ºæœ€ä¼˜æ¨¡å‹
    optimal_model = growth_engine.build_optimal_model(optimal_architecture)
    
    print(f"\nğŸ“Š æœ€ä¼˜æ¶æ„æ‘˜è¦:")
    print(f"  ç½‘ç»œæ·±åº¦: {optimal_architecture['depth']}")
    print(f"  å‚æ•°ä¼°è®¡: {optimal_architecture['estimated_params']:,}")
    print(f"  è®¾è®¡ç†å¿µ: {optimal_architecture['design_rationale']}")
    
    # è®­ç»ƒæœ€ä¼˜æ¨¡å‹
    print("\nğŸ¯ è®­ç»ƒæœ€ä¼˜æ¨¡å‹...")
    final_model, history = train_with_neuroexapt(
        model=optimal_model,
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=20,  # å‡å°‘è®­ç»ƒè½®æ•°ï¼Œå› ä¸ºæ¶æ„å·²ç»ä¼˜åŒ–
        learning_rate=0.001,
        efficiency_threshold=0.1,
        verbose=True
    )
    
    # è¯„ä¼°æœ€ç»ˆæ€§èƒ½
    final_accuracy = max(history['val_accuracy'])
    
    print(f"\nğŸ‰ å¿«é€Ÿä¼˜åŒ–å®Œæˆ!")
    print(f"ç›®æ ‡å‡†ç¡®åº¦: {target_accuracy:.1%}")
    print(f"å®é™…å‡†ç¡®åº¦: {final_accuracy:.1%}")
    print(f"æ˜¯å¦è¾¾æ ‡: {'âœ…' if final_accuracy >= target_accuracy else 'âŒ'}")
    
    return {
        'optimal_model': final_model,
        'optimal_architecture': optimal_architecture,
        'final_accuracy': final_accuracy,
        'training_history': history,
        'success': final_accuracy >= target_accuracy
    }


def create_cifar10_dataloaders():
    """åˆ›å»ºCIFAR-10æ•°æ®åŠ è½½å™¨"""
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])
    
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])
    
    train_dataset = torchvision.datasets.CIFAR10(
        root='./data', train=True, download=True, transform=transform_train
    )
    val_dataset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform_test
    )
    
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)
    
    return train_loader, val_loader


def main():
    print("ğŸ§  æ™ºèƒ½æ¶æ„ç”Ÿé•¿ç³»ç»Ÿ - ä¸€æ­¥åˆ°ä½çš„æ¶æ„ä¼˜åŒ–")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader = create_cifar10_dataloaders()
    
    # è¿è¡Œå¿«é€Ÿæ¶æ„ä¼˜åŒ–
    result = rapid_architecture_optimization(
        train_loader, val_loader, 
        target_accuracy=0.85
    )
    
    # è¾“å‡ºè¯¦ç»†ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆç»“æœåˆ†æ")
    print("=" * 60)
    
    if result['success']:
        print("ğŸ¯ æˆåŠŸè¾¾åˆ°ç›®æ ‡å‡†ç¡®åº¦!")
        improvement = result['final_accuracy'] - 0.82  # å‡è®¾åŸºçº¿82%
        print(f"ç›¸æ¯”åŸºçº¿æå‡: {improvement:.1%}")
    else:
        print("âš ï¸ æœªå®Œå…¨è¾¾åˆ°ç›®æ ‡ï¼Œä½†å·²å¤§å¹…æ”¹å–„")
    
    print(f"\næ¶æ„ç‰¹ç‚¹:")
    arch = result['optimal_architecture']
    print(f"  æ·±åº¦: {arch['depth']} å±‚")
    print(f"  å®½åº¦åˆ†å¸ƒ: {arch['layer_widths']}")
    print(f"  å‚æ•°é‡: {arch['estimated_params']:,}")
    print(f"  ç‰¹æ®Šç‰¹æ€§: {list(arch['features'].keys())}")
    
    print(f"\næ€§èƒ½æŒ‡æ ‡:")
    print(f"  æœ€ç»ˆéªŒè¯å‡†ç¡®åº¦: {result['final_accuracy']:.1%}")
    print(f"  è®­ç»ƒæ•ˆç‡: 20 epochsè¾¾åˆ°ç›®æ ‡")
    print(f"  æ¶æ„è®¾è®¡: åŸºäºæ•°æ®ç‰¹æ€§ä¸€æ­¥åˆ°ä½")
    
    print("\nâœ… æ™ºèƒ½æ¶æ„ç”Ÿé•¿ç³»ç»Ÿè¿è¡Œå®Œæˆ!")


if __name__ == "__main__":
    main() 