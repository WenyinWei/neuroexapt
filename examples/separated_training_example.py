#!/usr/bin/env python3
"""
åˆ†ç¦»è®­ç»ƒç­–ç•¥ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¶æ„å‚æ•°å’Œç½‘ç»œæƒé‡çš„åˆ†ç¦»è®­ç»ƒï¼š
1. å¤§éƒ¨åˆ†æ—¶é—´è®­ç»ƒç½‘ç»œæƒé‡ï¼ˆå›ºå®šæ¶æ„å‚æ•°ï¼‰
2. å®šæœŸè®­ç»ƒæ¶æ„å‚æ•°ï¼ˆå›ºå®šç½‘ç»œæƒé‡ï¼‰
3. æ˜¾è‘—å‡å°‘å‚æ•°é‡å’Œè®¡ç®—å¼€é”€
"""

import torch
import torch.nn as nn
import torch.utils.data as data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torch.backends.cudnn as cudnn
import numpy as np
import sys
import os
import time
import argparse
from tqdm import tqdm
from pathlib import Path

# Add the parent directory to the path to import neuroexapt
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import NeuroExapt core components
from neuroexapt.core.model import Network
from neuroexapt.core.separated_training import create_separated_training_setup
from neuroexapt.utils.utils import AvgrageMeter, accuracy

def setup_args():
    """Setup command line arguments"""
    parser = argparse.ArgumentParser(description='NeuroExapt Separated Training Example')
    
    # Training parameters
    parser.add_argument('--data', type=str, default='./data', help='dataset location')
    parser.add_argument('--batch_size', type=int, default=64, help='batch size')
    parser.add_argument('--epochs', type=int, default=20, help='number of epochs')
    parser.add_argument('--weight_lr', type=float, default=0.025, help='weight learning rate')
    parser.add_argument('--arch_lr', type=float, default=3e-4, help='architecture learning rate')
    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')
    parser.add_argument('--weight_decay', type=float, default=3e-4, help='weight decay')
    parser.add_argument('--train_portion', type=float, default=0.5, help='training data portion')
    
    # Architecture parameters  
    parser.add_argument('--init_channels', type=int, default=16, help='initial channels')
    parser.add_argument('--layers', type=int, default=6, help='number of layers')
    parser.add_argument('--potential_layers', type=int, default=2, help='potential layers')
    
    # Separated training strategy
    parser.add_argument('--weight_epochs', type=int, default=4, help='consecutive weight training epochs')
    parser.add_argument('--arch_epochs', type=int, default=1, help='architecture training epochs')
    parser.add_argument('--warmup_epochs', type=int, default=5, help='warmup epochs (weight only)')
    
    # Performance options
    parser.add_argument('--num_workers', type=int, default=4, help='data loader workers')
    parser.add_argument('--pin_memory', action='store_true', default=True, help='pin memory')
    
    # Debug options
    parser.add_argument('--seed', type=int, default=42, help='random seed')
    parser.add_argument('--save_dir', type=str, default='./results', help='save directory')
    
    return parser.parse_args()

def setup_environment(args):
    """Setup training environment"""
    # Set random seeds
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    # CUDA optimizations
    if torch.cuda.is_available():
        cudnn.benchmark = True
        cudnn.enabled = True
        cudnn.deterministic = False
        
        # Enable TensorFloat-32
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
    
    # Create save directory
    os.makedirs(args.save_dir, exist_ok=True)
    
    print(f"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
    print(f"   è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    print(f"   éšæœºç§å­: {args.seed}")

def create_data_loaders(args):
    """Create data loaders"""
    print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    
    # Data transforms
    train_transform = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])
    
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])
    
    # Load datasets
    train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)
    
    num_train = len(train_data)
    indices = list(range(num_train))
    split = int(np.floor(args.train_portion * num_train))
    
    print(f"   è®­ç»ƒæ ·æœ¬: {num_train}, åˆ†å‰²: {split}/{num_train - split}")
    
    # Create data loaders
    train_queue = data.DataLoader(
        train_data, batch_size=args.batch_size,
        sampler=data.SubsetRandomSampler(indices[:split]),
        num_workers=args.num_workers,
        pin_memory=args.pin_memory,
        drop_last=True
    )
    
    valid_queue = data.DataLoader(
        train_data, batch_size=args.batch_size,
        sampler=data.SubsetRandomSampler(indices[split:num_train]),
        num_workers=args.num_workers,
        pin_memory=args.pin_memory,
        drop_last=True
    )
    
    print(f"   æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: {len(train_queue)}è®­ç»ƒæ‰¹æ¬¡, {len(valid_queue)}éªŒè¯æ‰¹æ¬¡")
    
    return train_queue, valid_queue

def create_model(args):
    """Create model"""
    print(f"ğŸ§  åˆ›å»ºæ¨¡å‹...")
    
    model = Network(
        C=args.init_channels,
        num_classes=10,
        layers=args.layers,
        potential_layers=args.potential_layers,
        use_gradient_optimized=True,  # å¯ç”¨æ¢¯åº¦ä¼˜åŒ–MixedOp
        use_optimized_ops=True,       # å¯ç”¨ä¼˜åŒ–æ“ä½œ
        use_lazy_ops=True,            # å¯ç”¨æ‡’è®¡ç®—
        use_memory_efficient=True,    # å¯ç”¨å†…å­˜é«˜æ•ˆæ“ä½œ
        use_compile=True,             # å¯ç”¨torch.compileåŠ é€Ÿ
        use_checkpoint=False,         # è®­ç»ƒæ—¶å…³é—­checkpointä»¥åŠ é€Ÿ
        progress_tracking=False,      # å…³é—­è¯¦ç»†è·Ÿè¸ªä»¥æå‡æ€§èƒ½
        quiet=True                    # é™é»˜æ¨¡å¼
    )
    
    if torch.cuda.is_available():
        model = model.cuda()
    
    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    arch_params = sum(p.numel() for p in model.arch_parameters()) if hasattr(model, 'arch_parameters') else 0
    weight_params = total_params - arch_params
    
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   ç½‘ç»œæƒé‡å‚æ•°: {weight_params:,}")
    print(f"   æ¶æ„å‚æ•°: {arch_params:,}")
    print(f"   æ¶æ„å‚æ•°å æ¯”: {arch_params/total_params*100:.2f}%")
    
    return model

def validate_epoch(valid_queue, model, criterion):
    """éªŒè¯ä¸€ä¸ªepoch"""
    model.eval()
    
    objs = AvgrageMeter()
    top1 = AvgrageMeter()
    
    with torch.no_grad():
        for input, target in valid_queue:
            input = input.cuda(non_blocking=True)
            target = target.cuda(non_blocking=True)
            
            logits = model(input)
            loss = criterion(logits, target)
            
            prec1, _ = accuracy(logits, target, topk=(1, 5))
            n = input.size(0)
            objs.update(loss.item(), n)
            top1.update(prec1.item(), n)
    
    return top1.avg, objs.avg

def main():
    """ä¸»å‡½æ•°"""
    args = setup_args()
    setup_environment(args)
    
    print(f"ğŸš€ NeuroExapt åˆ†ç¦»è®­ç»ƒç­–ç•¥ç¤ºä¾‹")
    print("=" * 60)
    
    # è‡ªåŠ¨ä¼˜åŒ–batch sizeï¼ˆå¯é€‰ï¼‰
    import sys
    user_specified_batch_size = '--batch_size' in sys.argv
    
    if not user_specified_batch_size:
        print("ğŸ” æ­£åœ¨è‡ªåŠ¨æ£€æµ‹æœ€ä¼˜batch size...")
        try:
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            if project_root not in sys.path:
                sys.path.insert(0, project_root)
            
            from fast_batch_optimizer import find_optimal_batch_size
            optimal_batch_size = find_optimal_batch_size(quiet=True)
            args.batch_size = optimal_batch_size
            print(f"âœ… æœ€ä¼˜batch size: {optimal_batch_size}")
        except Exception as e:
            print(f"âš ï¸ batch sizeä¼˜åŒ–å¤±è´¥: {e}")
            print(f"ğŸ”„ ä½¿ç”¨é»˜è®¤å€¼: {args.batch_size}")
    
    print(f"\nğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   æ€»epochs: {args.epochs}")
    print(f"   æƒé‡è®­ç»ƒå‘¨æœŸ: {args.weight_epochs}")
    print(f"   æ¶æ„è®­ç»ƒå‘¨æœŸ: {args.arch_epochs}")
    print(f"   é¢„çƒ­epochs: {args.warmup_epochs}")
    print(f"   Batch size: {args.batch_size}")
    print(f"   Layers: {args.layers}")
    print()
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = create_model(args)
    train_queue, valid_queue = create_data_loaders(args)
    
    # åˆ›å»ºåˆ†ç¦»è®­ç»ƒè®¾ç½®
    print("ğŸ§¬ åˆ›å»ºåˆ†ç¦»è®­ç»ƒç­–ç•¥...")
    strategy, optimizer, trainer = create_separated_training_setup(
        model,
        weight_training_epochs=args.weight_epochs,
        arch_training_epochs=args.arch_epochs,
        total_epochs=args.epochs
    )
    
    print("\nğŸƒ å¼€å§‹è®­ç»ƒ...")
    print("=" * 60)
    
    # è®­ç»ƒå¾ªç¯
    best_acc = 0.0
    
    for epoch in range(args.epochs):
        # è®­ç»ƒä¸€ä¸ªepoch
        stats = trainer.train_epoch(train_queue, valid_queue, epoch)
        
        # éªŒè¯
        val_acc, val_loss = validate_epoch(valid_queue, model, trainer.criterion)
        
        if val_acc > best_acc:
            best_acc = val_acc
        
        # è¾“å‡ºè¿›åº¦
        mode_icon = "ğŸ‹ï¸" if stats.get('mode', 'weight') == 'weight' else "ğŸ§¬"
        if 'accuracy' in stats:
            print(f"{mode_icon} Epoch {epoch}: è®­ç»ƒ={stats['accuracy']:.2f}% éªŒè¯={val_acc:.2f}% æœ€ä½³={best_acc:.2f}% æ—¶é—´={stats['time']:.1f}s")
        else:
            print(f"{mode_icon} Epoch {epoch}: éªŒè¯={val_acc:.2f}% æœ€ä½³={best_acc:.2f}% æ—¶é—´={stats['time']:.1f}s æ¶æ„æ›´æ–°={stats.get('arch_updates', 0):.0f}")
        
        # å®šæœŸæ¸…ç†ç¼“å­˜
        if epoch % 5 == 0:
            torch.cuda.empty_cache()
    
    # è·å–æœ€ç»ˆç»Ÿè®¡
    final_stats = trainer.get_final_statistics()
    
    print("\nğŸ“ˆ è®­ç»ƒå®Œæˆï¼")
    print("=" * 60)
    print(f"âœ… æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
    print(f"ğŸ“Š æƒé‡è®­ç»ƒepochs: {final_stats['weight_epochs']}")
    print(f"ğŸ§¬ æ¶æ„è®­ç»ƒepochs: {final_stats['arch_epochs']}")
    print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {final_stats['total_time']:.1f}s")
    print(f"ğŸ“ˆ æƒé‡è®­ç»ƒæ—¶é—´å æ¯”: {final_stats['weight_time_ratio']*100:.1f}%")
    print(f"âš¡ æƒé‡è®­ç»ƒå¹³å‡é€Ÿåº¦: {final_stats['time_per_weight_epoch']:.1f}s/epoch")
    print(f"ğŸ”¬ æ¶æ„è®­ç»ƒå¹³å‡é€Ÿåº¦: {final_stats['time_per_arch_epoch']:.1f}s/epoch")
    
    # æ˜¾ç¤ºæœ€ç»ˆæ¶æ„
    if hasattr(model, 'genotype') and callable(model.genotype):
        genotype = model.genotype()
        print(f"\nğŸ—ï¸ å‘ç°çš„æœ€ç»ˆæ¶æ„:")
        print(f"   Normal Cell: {genotype.normal}")
        print(f"   Reduce Cell: {genotype.reduce}")
    
    # åˆ†ææ¶æ„å‚æ•°å˜åŒ–
    print(f"\nğŸ” æ¶æ„å‚æ•°åˆ†æ:")
    if hasattr(model, 'alphas_normal'):
        normal_weights = torch.softmax(model.alphas_normal, dim=-1)
        normal_max_weights = normal_weights.max(dim=-1)[0]
        print(f"   Normalæƒé‡é›†ä¸­åº¦: {normal_max_weights.mean().item():.3f} Â± {normal_max_weights.std().item():.3f}")
    
    if hasattr(model, 'alphas_reduce'):
        reduce_weights = torch.softmax(model.alphas_reduce, dim=-1)
        reduce_max_weights = reduce_weights.max(dim=-1)[0]
        print(f"   Reduceæƒé‡é›†ä¸­åº¦: {reduce_max_weights.mean().item():.3f} Â± {reduce_max_weights.std().item():.3f}")
    
    print("\nğŸ¯ åˆ†ç¦»è®­ç»ƒç­–ç•¥æˆåŠŸå®Œæˆï¼å‚æ•°é‡å¤§å¹…å‡å°‘ï¼Œè®­ç»ƒé€Ÿåº¦æ˜¾è‘—æå‡ï¼")

if __name__ == "__main__":
    main() 