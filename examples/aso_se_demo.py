#!/usr/bin/env python3
"""
ASO-SEæ¡†æ¶å®Œæ•´æ¼”ç¤º

å±•ç¤ºäº¤æ›¿å¼ç¨³å®šä¼˜åŒ–ä¸éšæœºæ¢ç´¢(ASO-SE)æ¡†æ¶çš„å®Œæ•´ä½¿ç”¨æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. å››é˜¶æ®µè®­ç»ƒæµç¨‹
2. å‡½æ•°ä¿æŒåˆå§‹åŒ–
3. Gumbel-Softmaxå¼•å¯¼å¼æ¢ç´¢
4. æ¶æ„çªå˜ä¸ç¨³å®š
5. æ¸è¿›å¼æ¶æ„ç”Ÿé•¿

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†é‡æ„åçš„ASO-SEæ¡†æ¶å¦‚ä½•è§£å†³å¯å¾®æ¶æ„æœç´¢ä¸­çš„æ ¸å¿ƒçŸ›ç›¾ã€‚
"""

import os
import sys
import argparse
import logging
import time
import numpy as np

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from neuroexapt.core.aso_se_trainer import ASOSETrainer, create_aso_se_trainer
from neuroexapt.core.aso_se_framework import ASOSEConfig
from neuroexapt.core.model import Network as SearchNetwork
from neuroexapt.utils.train_utils import count_parameters_in_MB

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('aso_se_demo.log')
    ]
)
logger = logging.getLogger(__name__)

def get_data_loaders(args):
    """è·å–æ•°æ®åŠ è½½å™¨"""
    logger.info(f"ğŸ“Š Loading {args.dataset} dataset...")
    
    if args.dataset == 'CIFAR10':
        # CIFAR-10æ•°æ®å˜æ¢
        transform_train = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ])
        
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ])
        
        # åŠ è½½æ•°æ®é›†
        trainset = torchvision.datasets.CIFAR10(
            root='./data', train=True, download=True, transform=transform_train
        )
        testset = torchvision.datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform_test
        )
        
        num_classes = 10
        
    elif args.dataset == 'CIFAR100':
        # CIFAR-100æ•°æ®å˜æ¢
        transform_train = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),
        ])
        
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),
        ])
        
        trainset = torchvision.datasets.CIFAR100(
            root='./data', train=True, download=True, transform=transform_train
        )
        testset = torchvision.datasets.CIFAR100(
            root='./data', train=False, download=True, transform=transform_test
        )
        
        num_classes = 100
    else:
        raise ValueError(f"Unsupported dataset: {args.dataset}")
    
    # åˆ†å‰²è®­ç»ƒé›†ä¸ºè®­ç»ƒå’ŒéªŒè¯
    num_train = len(trainset)
    indices = list(range(num_train))
    split = int(np.floor(args.train_portion * num_train))
    
    np.random.shuffle(indices)
    
    train_idx, valid_idx = indices[:split], indices[split:]
    
    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)
    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        trainset, batch_size=args.batch_size, sampler=train_sampler,
        num_workers=args.num_workers, pin_memory=True
    )
    
    valid_loader = DataLoader(
        trainset, batch_size=args.batch_size, sampler=valid_sampler,
        num_workers=args.num_workers, pin_memory=True
    )
    
    test_loader = DataLoader(
        testset, batch_size=args.batch_size, shuffle=False,
        num_workers=args.num_workers, pin_memory=True
    )
    
    logger.info(f"âœ… Dataset loaded: {len(trainset)} total, "
               f"{len(train_idx)} train, {len(valid_idx)} valid, {len(testset)} test")
    
    return train_loader, valid_loader, test_loader, num_classes

def create_demo_trainer(args, num_classes):
    """åˆ›å»ºASO-SEæ¼”ç¤ºè®­ç»ƒå™¨"""
    logger.info("ğŸ—ï¸ Creating ASO-SE trainer with enhanced configuration...")
    
    # æœç´¢æ¨¡å‹å‚æ•°
    search_model_args = {
        'C': args.init_channels,
        'num_classes': num_classes,
        'layers': args.layers,
        'steps': 4,
        'block_multiplier': 4,
        'stem_multiplier': 3
    }
    
    # å¯è¿›åŒ–æ¨¡å‹å‚æ•°
    model_args = {
        'C': args.init_channels,
        'num_classes': num_classes,
        'layers': args.layers
    }
    
    # è®­ç»ƒå‚æ•°ï¼ˆå±•ç¤ºASO-SEæ¡†æ¶çš„å®Œæ•´é…ç½®ï¼‰
    training_args = {
        # å››é˜¶æ®µè®­ç»ƒé…ç½®
        'warmup_epochs': args.warmup_epochs,
        'arch_epochs': args.arch_epochs,
        'weight_epochs': args.weight_epochs,
        'total_cycles': args.total_cycles,
        
        # Gumbel-Softmaxæ¢ç´¢é…ç½®
        'initial_temp': args.initial_temp,
        'min_temp': args.min_temp,
        'temp_annealing_rate': args.anneal_rate,
        'exploration_factor': 1.2,  # å¢å¼ºæ¢ç´¢
        
        # æ¶æ„çªå˜é…ç½®
        'mutation_strength': 0.3,
        'mutation_frequency': 2,  # æ¯2ä¸ªå‘¨æœŸçªå˜ä¸€æ¬¡
        
        # ä¼˜åŒ–å™¨é…ç½®
        'learning_rate': args.learning_rate,
        'arch_learning_rate': 3e-4,
        'momentum': args.momentum,
        'weight_decay': args.weight_decay,
        
        # æ—©åœå’Œç›‘æ§
        'early_stopping_patience': 15,
        'performance_threshold': 0.01
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = create_aso_se_trainer(search_model_args, model_args, training_args)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    logger.info(f"ğŸ“Š Search model parameters: {count_parameters_in_MB(trainer.get_search_model()):.2f}MB")
    
    return trainer

def demonstrate_aso_se_features(trainer):
    """æ¼”ç¤ºASO-SEæ¡†æ¶çš„ç‰¹è‰²åŠŸèƒ½"""
    logger.info("=" * 60)
    logger.info("ğŸ”¬ Demonstrating ASO-SE Framework Features")
    logger.info("=" * 60)
    
    # 1. å±•ç¤ºGumbel-Softmaxæ¢ç´¢
    logger.info("1ï¸âƒ£ Gumbel-Softmax Guided Exploration:")
    explorer = trainer.framework.explorer
    logger.info(f"   ğŸŒ¡ï¸ Initial Temperature: {explorer.initial_temp}")
    logger.info(f"   ğŸ¯ Minimum Temperature: {explorer.min_temp}")
    logger.info(f"   ğŸ“ˆ Annealing Rate: {explorer.anneal_rate}")
    
    # 2. å±•ç¤ºå‡½æ•°ä¿æŒåˆå§‹åŒ–
    logger.info("2ï¸âƒ£ Function-Preserving Initialization:")
    initializer = trainer.framework.initializer
    logger.info(f"   ğŸ›¡ï¸ Preserve Ratio: {initializer.preserve_ratio}")
    logger.info(f"   ğŸ”Š Noise Scale: {initializer.noise_scale}")
    
    # 3. å±•ç¤ºæ¶æ„çªå˜å™¨
    logger.info("3ï¸âƒ£ Architecture Mutator:")
    mutator = trainer.framework.mutator
    logger.info(f"   ğŸ§¬ Mutation Strength: {mutator.mutation_strength}")
    logger.info(f"   âš™ï¸ Function Preservation: {mutator.preserve_function}")
    
    # 4. å±•ç¤ºè®­ç»ƒé…ç½®
    logger.info("4ï¸âƒ£ Four-Stage Training Configuration:")
    config = trainer.framework.config
    logger.info(f"   ğŸ”¥ Warmup Epochs: {config.warmup_epochs}")
    logger.info(f"   ğŸ” Architecture Training Epochs: {config.arch_training_epochs}")
    logger.info(f"   ğŸ”§ Weight Retraining Epochs: {config.weight_training_epochs}")
    logger.info(f"   ğŸ”„ Total Cycles: {config.total_cycles}")
    
    logger.info("=" * 60)

def train_with_monitoring(trainer, train_loader, valid_loader, args):
    """å¸¦ç›‘æ§çš„è®­ç»ƒè¿‡ç¨‹"""
    logger.info("ğŸš€ Starting ASO-SE training with comprehensive monitoring...")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    best_accuracy = 0.0
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(args.epochs):
        epoch_start_time = time.time()
        
        try:
            # æ‰§è¡Œä¸€ä¸ªè®­ç»ƒå‘¨æœŸ
            stats = trainer.train_epoch(train_loader, valid_loader, epoch)
            
            # æå–å…³é”®æŒ‡æ ‡
            phase = stats.get('phase', 'unknown')
            train_acc = stats.get('train_accuracy', 0.0)
            valid_acc = stats.get('valid_accuracy', 0.0)
            
            # æ›´æ–°æœ€ä½³å‡†ç¡®ç‡
            if valid_acc > best_accuracy:
                best_accuracy = valid_acc
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if args.save_dir:
                    os.makedirs(args.save_dir, exist_ok=True)
                    checkpoint_path = os.path.join(args.save_dir, 'best_model.pth')
                    trainer.save_checkpoint(checkpoint_path)
                    logger.info(f"ğŸ’¾ Best model saved: {valid_acc:.2f}%")
            
            # è®¡ç®—epochè€—æ—¶
            epoch_time = time.time() - epoch_start_time
            
            # è¯¦ç»†æ—¥å¿—
            logger.info(f"ğŸ“ˆ Epoch {epoch:3d}/{args.epochs} [{phase:>15s}] "
                       f"Train: {train_acc:5.2f}% Valid: {valid_acc:5.2f}% "
                       f"Best: {best_accuracy:5.2f}% Time: {epoch_time:.1f}s")
            
            # é˜¶æ®µç‰¹å®šçš„ç›‘æ§
            if phase == 'mutation':
                logger.info(f"ğŸ§¬ Architecture mutation completed at epoch {epoch}")
                current_genotype = trainer.get_current_architecture()
                if current_genotype:
                    logger.info(f"   New architecture: {len(current_genotype.normal)} normal ops")
            
            # å®šæœŸæŠ¥å‘Šæ¢ç´¢çŠ¶æ€
            if epoch % 10 == 0:
                exploration_report = trainer.framework.explorer.get_exploration_report()
                if 'current_temperature' in exploration_report:
                    temp = exploration_report['current_temperature']
                    logger.info(f"ğŸŒ¡ï¸ Current exploration temperature: {temp:.3f}")
            
            # æ—©åœæ£€æŸ¥
            if trainer.framework.should_early_stop():
                logger.info(f"ğŸ›‘ Early stopping triggered at epoch {epoch}")
                break
                
        except Exception as e:
            logger.error(f"âŒ Training error at epoch {epoch}: {e}")
            if args.debug:
                import traceback
                traceback.print_exc()
            break
    
    # è®­ç»ƒå®Œæˆç»Ÿè®¡
    total_time = time.time() - start_time
    logger.info("=" * 60)
    logger.info("ğŸ‰ ASO-SE Training Completed!")
    logger.info(f"ğŸ“Š Total Time: {total_time/60:.1f} minutes")
    logger.info(f"ğŸ“ˆ Best Accuracy: {best_accuracy:.2f}%")
    
    # æ¡†æ¶æŠ¥å‘Š
    framework_report = trainer.get_framework_report()
    logger.info(f"ğŸ”¬ Total Cycles: {framework_report['current_cycle']}")
    logger.info(f"ğŸ§¬ Total Mutations: {framework_report['total_mutations']}")
    
    exploration_report = framework_report.get('exploration_report', {})
    if 'average_entropy' in exploration_report:
        logger.info(f"ğŸ” Average Exploration Entropy: {exploration_report['average_entropy']:.3f}")
    
    logger.info("=" * 60)
    
    return best_accuracy, framework_report

def evaluate_final_architecture(trainer, test_loader, args):
    """è¯„ä¼°æœ€ç»ˆæ¶æ„"""
    logger.info("ğŸ“‹ Evaluating final evolved architecture...")
    
    # è·å–æœ€ç»ˆæ¶æ„
    final_genotype = trainer.get_current_architecture()
    if final_genotype is None:
        logger.warning("âš ï¸ No final architecture available")
        return
    
    logger.info(f"ğŸ—ï¸ Final Architecture:")
    logger.info(f"   Normal: {final_genotype.normal}")
    logger.info(f"   Reduce: {final_genotype.reduce}")
    
    # è·å–å¯è¿›åŒ–æ¨¡å‹
    evolvable_model = trainer.get_evolvable_model()
    if evolvable_model is None:
        logger.warning("âš ï¸ No evolvable model available for evaluation")
        return
    
    # è¯„ä¼°æ¨¡å¼
    evolvable_model.eval()
    correct = 0
    total = 0
    test_loss = 0.0
    
    criterion = nn.CrossEntropyLoss()
    
    with torch.no_grad():
        for data, target in test_loader:
            if torch.cuda.is_available():
                data, target = data.cuda(), target.cuda()
            
            output = evolvable_model(data)
            test_loss += criterion(output, target).item()
            
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
    
    test_accuracy = 100. * correct / total
    avg_test_loss = test_loss / len(test_loader)
    
    logger.info(f"ğŸ¯ Final Test Results:")
    logger.info(f"   Accuracy: {test_accuracy:.2f}%")
    logger.info(f"   Loss: {avg_test_loss:.4f}")
    logger.info(f"   Parameters: {count_parameters_in_MB(evolvable_model):.2f}MB")
    
    return test_accuracy

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ASO-SE Framework Demo')
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument('--dataset', type=str, default='CIFAR10', choices=['CIFAR10', 'CIFAR100'])
    parser.add_argument('--batch_size', type=int, default=64, help='æ‰¹å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4, help='æ•°æ®åŠ è½½è¿›ç¨‹æ•°')
    parser.add_argument('--train_portion', type=float, default=0.8, help='è®­ç»ƒé›†æ¯”ä¾‹')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--init_channels', type=int, default=16, help='åˆå§‹é€šé“æ•°')
    parser.add_argument('--layers', type=int, default=8, help='ç½‘ç»œå±‚æ•°')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=50, help='æ€»è®­ç»ƒè½®æ•°')
    parser.add_argument('--warmup_epochs', type=int, default=8, help='é¢„çƒ­è½®æ•°')
    parser.add_argument('--arch_epochs', type=int, default=3, help='æ¶æ„è®­ç»ƒè½®æ•°')
    parser.add_argument('--weight_epochs', type=int, default=6, help='æƒé‡è®­ç»ƒè½®æ•°')
    parser.add_argument('--total_cycles', type=int, default=3, help='æ€»å¾ªç¯æ•°')
    
    # ä¼˜åŒ–å™¨å‚æ•°
    parser.add_argument('--learning_rate', type=float, default=0.025, help='å­¦ä¹ ç‡')
    parser.add_argument('--momentum', type=float, default=0.9, help='åŠ¨é‡')
    parser.add_argument('--weight_decay', type=float, default=3e-4, help='æƒé‡è¡°å‡')
    
    # ASO-SEç‰¹æœ‰å‚æ•°
    parser.add_argument('--initial_temp', type=float, default=5.0, help='åˆå§‹æ¸©åº¦')
    parser.add_argument('--min_temp', type=float, default=0.1, help='æœ€å°æ¸©åº¦')
    parser.add_argument('--anneal_rate', type=float, default=0.98, help='é€€ç«ç‡')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./checkpoints_aso_se', help='ä¿å­˜ç›®å½•')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--gpu', type=int, default=0, help='GPU ID')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    # è®¾ç½®GPU
    if torch.cuda.is_available():
        torch.cuda.set_device(args.gpu)
        logger.info(f"ğŸ”§ Using GPU {args.gpu}: {torch.cuda.get_device_name()}")
    else:
        logger.info("ğŸ”§ Using CPU")
    
    logger.info("ğŸš€ ASO-SE Framework Demo Starting...")
    logger.info(f"ğŸ“Š Configuration: {args}")
    
    try:
        # 1. åŠ è½½æ•°æ®
        train_loader, valid_loader, test_loader, num_classes = get_data_loaders(args)
        
        # 2. åˆ›å»ºè®­ç»ƒå™¨
        trainer = create_demo_trainer(args, num_classes)
        
        # 3. æ¼”ç¤ºæ¡†æ¶ç‰¹æ€§
        demonstrate_aso_se_features(trainer)
        
        # 4. æ‰§è¡Œè®­ç»ƒ
        best_accuracy, framework_report = train_with_monitoring(trainer, train_loader, valid_loader, args)
        
        # 5. è¯„ä¼°æœ€ç»ˆæ¶æ„
        test_accuracy = evaluate_final_architecture(trainer, test_loader, args)
        
        # 6. ä¿å­˜æœ€ç»ˆç»“æœ
        if args.save_dir:
            results = {
                'args': vars(args),
                'best_validation_accuracy': best_accuracy,
                'test_accuracy': test_accuracy,
                'framework_report': framework_report
            }
            
            results_path = os.path.join(args.save_dir, 'final_results.pth')
            torch.save(results, results_path)
            logger.info(f"ğŸ’¾ Results saved to {results_path}")
        
        logger.info("âœ… ASO-SE Demo completed successfully!")
        
    except Exception as e:
        logger.error(f"âŒ Demo failed: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main() 