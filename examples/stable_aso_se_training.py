#!/usr/bin/env python3
"""
é‡æ„åçš„ASO-SEç¥ç»æ¶æ„æœç´¢è®­ç»ƒè„šæœ¬
ä½¿ç”¨å…¨æ–°è®¾è®¡çš„ç¨³å®šæ¶æ„æœç´¢æ¡†æ¶
"""

import os
import sys
import logging
import argparse
import random
import numpy as np
import torch

# æ·»åŠ neuroexaptåˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from neuroexapt.core.aso_se_trainer import StableASO_SETrainer


def set_seed(seed=42):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(message)s',
        datefmt='%H:%M:%S'
    )
    return logging.getLogger()


def create_config():
    """åˆ›å»ºè®­ç»ƒé…ç½®"""
    config = {
        # æ•°æ®é›†é…ç½®
        'dataset': 'CIFAR-10',
        'batch_size': 128,
        
        # è®­ç»ƒé…ç½®
        'num_epochs': 80,  # å‡å°‘æ€»epochæ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        'init_channels': 32,
        'init_depth': 4,
        'max_depth': 7,
        
        # ä¼˜åŒ–å™¨é…ç½®
        'weight_lr': 0.025,
        'arch_lr': 3e-4,
        'momentum': 0.9,
        'weight_decay': 3e-4,
        
        # é˜¶æ®µé…ç½® - è°ƒæ•´ä¸ºæ›´åˆç†çš„æ¯”ä¾‹
        'warmup_epochs': 12,   # æƒé‡é¢„çƒ­
        'search_epochs': 25,   # æ¶æ„æœç´¢
        'growth_epochs': 28,   # ç½‘ç»œç”Ÿé•¿
        'optimize_epochs': 15, # æœ€ç»ˆä¼˜åŒ–
        
        # æœç´¢æ§åˆ¶
        'arch_update_freq': 5,     # æ¯5ä¸ªbatchæ›´æ–°æ¶æ„
        'growth_patience': 6,      # 6ä¸ªepochæ— æ”¹å–„åç”Ÿé•¿
        'growth_threshold': 0.015, # 1.5%æ”¹å–„é˜ˆå€¼
    }
    
    return config


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ç¨³å®šASO-SEè®­ç»ƒ')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--resume', type=str, default=None, help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--save_dir', type=str, default='./checkpoints', help='æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒ
    set_seed(args.seed)
    logger = setup_logging()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    
    print("ğŸ”§ é‡æ„ç‰ˆASO-SE: ç¨³å®šçš„ç¥ç»æ¶æ„æœç´¢")
    print("   ç›®æ ‡: CIFAR-10 é«˜å‡†ç¡®ç‡")
    print("   ç­–ç•¥: å››é˜¶æ®µæ¸è¿›å¼è®­ç»ƒ")
    print("   æ¡†æ¶: å…¨æ–°é‡æ„çš„ç¨³å®šæ¶æ„")
    
    # åˆ›å»ºé…ç½®
    config = create_config()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = StableASO_SETrainer(config)
    
    # å¦‚æœæœ‰æ£€æŸ¥ç‚¹ï¼ŒåŠ è½½å®ƒ
    if args.resume and os.path.exists(args.resume):
        print(f"ğŸ“‚ æ¢å¤è®­ç»ƒ: {args.resume}")
        trainer.load_checkpoint(args.resume)
    
    try:
        # å¼€å§‹è®­ç»ƒ
        training_history, best_accuracy = trainer.train()
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_checkpoint = os.path.join(args.save_dir, 'final_model.pth')
        trainer._save_checkpoint('final')
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³æµ‹è¯•ç²¾åº¦: {best_accuracy:.2f}%")
        print(f"   æ¨¡å‹ä¿å­˜åˆ°: {args.save_dir}")
        
        # æ‰“å°æœ€ç»ˆæ¶æ„
        final_info = trainer.network.get_architecture_info()
        print(f"\nğŸ“‹ æœ€ç»ˆæ¶æ„:")
        print(f"   æ·±åº¦: {final_info['depth']}")
        print(f"   å‚æ•°é‡: {final_info['parameters']:,}")
        print(f"   æ¶æ„: {final_info['architecture']}")
        
        # ç®€å•çš„æ€§èƒ½åˆ†æ
        print(f"\nğŸ“Š è®­ç»ƒæ€»ç»“:")
        phases = ['warmup', 'search', 'growth', 'optimize']
        for phase in phases:
            phase_history = [h for h in training_history if h['phase'] == phase]
            if phase_history:
                best_in_phase = max(phase_history, key=lambda x: x['test_acc'])
                print(f"   {phase:8s}: æœ€ä½³ {best_in_phase['test_acc']:.2f}% (Epoch {best_in_phase['epoch']+1})")
        
        return best_accuracy
        
    except KeyboardInterrupt:
        print(f"\nâ¸ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        # ä¿å­˜ä¸­æ–­æ—¶çš„çŠ¶æ€
        interrupt_checkpoint = os.path.join(args.save_dir, 'interrupted.pth')
        trainer._save_checkpoint('interrupted')
        print(f"   çŠ¶æ€å·²ä¿å­˜åˆ°: {interrupt_checkpoint}")
        return trainer.best_accuracy
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 0.0


if __name__ == '__main__':
    main()