#!/usr/bin/env python3
"""
æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤º - åŸºäºç†è®ºæ¡†æ¶çš„é‡æ„ç‰ˆæœ¬
Intelligent Architecture Evolution Demo - Theoretical Framework Refactored Version

ğŸ¯ æ ¸å¿ƒç›®æ ‡ï¼š
1. åœ¨CIFAR-10ä¸Šè¾¾åˆ°95%+çš„å‡†ç¡®ç‡
2. ä½¿ç”¨æ— å‚æ•°ç»“æ„è¯„ä¼°æŠ€æœ¯
3. å®ç°å¤šå˜å¼‚ç±»å‹æ”¶ç›ŠæœŸæœ›å»ºæ¨¡
4. åº”ç”¨è´å¶æ–¯å†³ç­–æ¡†æ¶è¿›è¡Œæ™ºèƒ½å˜å¼‚
5. é€šè¿‡è½»é‡çº§æŠ½æ ·éªŒè¯æ ¡å‡†æ”¶ç›ŠæœŸæœ›

ğŸ§¬ æ ¸å¿ƒç†è®ºå®ç°ï¼š
åŸºäºç”¨æˆ·æä¾›çš„ç†è®ºæ¡†æ¶ï¼š
- æœ‰æ•ˆä¿¡æ¯(EI): EI(S) = max_{p(x)} [I(X; Y) - I(X; Y|S)]
- ç§¯åˆ†ä¿¡æ¯(Î¦): Î¦ â‰ˆ Î£_{i,j} MI(H_i; H_j) - Î£_i MI(H_i; H_i)
- ç»“æ„å†—ä½™åº¦(SR): SR = rank(1/N Î£_n W_n^T W_n)
- å˜å¼‚ä¼˜å…ˆçº§: Score(S, M) = Î±Â·Î”I + Î²Â·Î¦(S) - Î³Â·SR(S) - Î´Â·Cost(M)
- æœŸæœ›æ•ˆç”¨: E[U(Î”I)] = E[1 - exp(-Î»Â·Î”I)]

ğŸ”§ æŠ€æœ¯æ ˆï¼š
- Enhanced ResNet with advanced architectures
- Parameter-free structural evaluation
- Multi-mutation type benefit modeling
- Lightweight sampling validation
- Bayesian decision framework

ğŸ“‹ ä½¿ç”¨æ–¹å¼ï¼š
1. åŸºç¡€æ¼”ç¤ºï¼špython examples/intelligent_evolution_demo.py
2. é«˜çº§æ¼”ç¤ºï¼špython examples/intelligent_evolution_demo.py --enhanced
3. åŸºå‡†å¯¹æ¯”ï¼špython examples/intelligent_evolution_demo.py --baseline
"""

import argparse
import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import time
import logging
from typing import Dict, List, Tuple, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ–°çš„ç†è®ºæ¡†æ¶ç»„ä»¶
from neuroexapt.core import (
    UnifiedIntelligentEvolutionEngine,
    NewEvolutionConfig as EvolutionConfig,
    ParameterFreeStructuralEvaluator,
    MultiMutationTypeEvaluator,
    LightweightSamplingValidator
)

# å¯¼å…¥ç»Ÿä¸€æ¼”ç¤ºå·¥å…·
from demo_utils import (
    DemoConfiguration,
    DemoLogger,
    DeviceManager,
    load_cifar10_data,
    create_enhanced_resnet,
    AdvancedTrainer,
    ResultFormatter
)


# åˆ é™¤é‡å¤çš„ç±»å®šä¹‰ï¼Œä½¿ç”¨demo_utilsä¸­çš„ç»Ÿä¸€å®ç°


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤º - ç†è®ºæ¡†æ¶ç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s                    # è¿è¡Œæ ‡å‡†æ¼”ç¤º
  %(prog)s --enhanced         # è¿è¡Œå¢å¼ºç‰ˆæ¼”ç¤º (95%ç›®æ ‡)
  %(prog)s --baseline         # è¿è¡ŒåŸºå‡†å¯¹æ¯”
  %(prog)s --quick            # å¿«é€Ÿæ¼”ç¤º (å‡å°‘è®­ç»ƒè½®æ•°)
  %(prog)s --target 90        # è®¾ç½®ç›®æ ‡å‡†ç¡®ç‡ä¸º90%
        """
    )
    
    parser.add_argument('--enhanced', action='store_true',
                       help='ä½¿ç”¨å¢å¼ºç‰ˆæ¶æ„å’Œè®­ç»ƒæŠ€æœ¯')
    parser.add_argument('--baseline', action='store_true', 
                       help='è¿è¡ŒåŸºå‡†å¯¹æ¯” (ä¸ä½¿ç”¨è¿›åŒ–)')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ (å‡å°‘è®­ç»ƒè½®æ•°)')
    parser.add_argument('--target', type=float, default=95.0,
                       help='ç›®æ ‡å‡†ç¡®ç‡ (é»˜è®¤: 95.0)')
    parser.add_argument('--epochs', type=int, default=15,
                       help='åˆå§‹è®­ç»ƒè½®æ•° (é»˜è®¤: 15)')
    parser.add_argument('--evolution-rounds', type=int, default=3,
                       help='è¿›åŒ–è½®æ•° (é»˜è®¤: 3)')
    parser.add_argument('--device', choices=['auto', 'cuda', 'cpu'], default='auto',
                       help='è®¡ç®—è®¾å¤‡ (é»˜è®¤: auto)')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--verbose', action='store_true', default=True,
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    parser.add_argument('--quiet', action='store_true',
                       help='å®‰é™æ¨¡å¼ (è¦†ç›–verbose)')
    
    return parser.parse_args()


# ç§»é™¤é‡å¤çš„è®¾å¤‡è®¾ç½®å‡½æ•°ï¼Œä½¿ç”¨DeviceManager


def run_baseline_demo(args):
    """è¿è¡ŒåŸºå‡†æ¼”ç¤ºï¼ˆæ— è¿›åŒ–ï¼‰"""
    # åˆå§‹åŒ–æ—¥å¿—å™¨å’Œé…ç½®
    logger = DemoLogger('baseline_demo', level='INFO', verbose=args.verbose and not args.quiet)
    
    logger.info("="*60)
    logger.info("ğŸ“Š åŸºå‡†å¯¹æ¯”æ¼”ç¤º - æ— æ¶æ„è¿›åŒ–")
    logger.info(f"ğŸ¯ ç›®æ ‡ï¼šCIFAR-10ä¸Š{args.target}%å‡†ç¡®ç‡")
    logger.info("="*60)
    
    # åˆ›å»ºé…ç½®
    config = DemoConfiguration(
        device_type=args.device,
        seed=args.seed,
        enhanced_augmentation=args.enhanced,
        model_type='enhanced_resnet34' if args.enhanced else 'enhanced_resnet18',
        verbose=args.verbose and not args.quiet
    )
    
    # è®¾ç½®ç¯å¢ƒ
    device = DeviceManager.setup_environment(args.seed)
    device_info = DeviceManager.get_device_info(device)
    logger.info(f"è®¾å¤‡ä¿¡æ¯:\n{ResultFormatter.format_device_info(device_info)}")
    
    # æ•°æ®ç®¡ç†
    data_manager = CIFAR10DataManager(config)
    train_loader, test_loader = data_manager.create_data_loaders()
    
    # åˆ›å»ºåŸºç¡€æ¨¡å‹
    model = ModelManager.create_model(config)
    model_info = ModelManager.get_model_info(model)
    logger.info(f"æ¨¡å‹ä¿¡æ¯:\n{ResultFormatter.format_model_info(model_info)}")
    
    # è®­ç»ƒæ¨¡å‹
    trainer = AdvancedTrainer(model, device, config, logger)
    epochs = args.epochs if not args.quick else max(5, args.epochs // 3)
    
    logger.progress(f"å¼€å§‹åŸºå‡†è®­ç»ƒ ({epochs} epochs)")
    final_accuracy = trainer.train_model(train_loader, test_loader, epochs=epochs)
    
    # ç»“æœæ‘˜è¦
    logger.info(f"\nğŸ åŸºå‡†æ¼”ç¤ºå®Œæˆ")
    logger.info(f"æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.2f}%")
    
    if final_accuracy >= args.target:
        logger.success(f"åŸºå‡†æ¨¡å‹è¾¾åˆ°{args.target}%å‡†ç¡®ç‡ç›®æ ‡ï¼")
    else:
        logger.warning(f"åŸºå‡†æ¨¡å‹è·ç¦»{args.target}%ç›®æ ‡è¿˜å·®: {args.target - final_accuracy:.2f}%")
    
    return {
        'baseline_accuracy': final_accuracy,
        'target_reached': final_accuracy >= args.target,
        'model_type': config.model_type
    }


def run_intelligent_evolution_experiment(args):
    """è¿è¡Œæ™ºèƒ½è¿›åŒ–å®éªŒ"""
    # åˆå§‹åŒ–æ—¥å¿—å™¨
    logger = DemoLogger('evolution_demo', level='INFO', verbose=args.verbose and not args.quiet)
    logger.info("ğŸ”¬ å¼€å§‹æ™ºèƒ½è¿›åŒ–å®éªŒ")
    logger.info("="*60)
    logger.info("ğŸ§¬ 80-Epochæ··åˆè®­ç»ƒï¼ˆå¸¸è§„è®­ç»ƒ+é—´æ­‡è¿›åŒ–ï¼‰")
    logger.info(f"ğŸ¯ ç›®æ ‡ï¼šCIFAR-10ä¸Š{args.target}%å‡†ç¡®ç‡")
    logger.info("="*60)
    
    # è®¾å¤‡å’Œæ•°æ®åŠ è½½
    device = DeviceManager.setup_device()
    train_loader, test_loader = load_cifar10_data(args.batch_size, args.num_workers)
    config = {
        'lr': args.lr,
        'weight_decay': args.weight_decay,
        'epochs': args.epochs,
        'label_smoothing': 0.1,
        'device': device
    }
    
    # åˆå§‹æ¨¡å‹å’Œè®­ç»ƒ
    logger.info("ğŸ—ï¸ åˆ›å»ºåˆå§‹æ¨¡å‹")
    initial_model = create_enhanced_resnet(num_classes=10, dropout_rate=0.1).to(device)
    
    # åˆå§‹è®­ç»ƒ - å»ºç«‹åŸºçº¿
    logger.info("ğŸ“š è¿›è¡Œåˆå§‹åŸºçº¿è®­ç»ƒ")
    trainer = AdvancedTrainer(initial_model, device, config, logger)
    
    start_time = time.time()
    
    # === 80-Epoch è®­ç»ƒ + é—´æ­‡æ€§è¿›åŒ– ===
    logger.info("ğŸ”„ å¼€å§‹80-epochæ··åˆè®­ç»ƒï¼ˆè®­ç»ƒ+é—´æ­‡è¿›åŒ–ï¼‰")
    
    model = initial_model
    total_epochs = 80
    evolution_epochs = [10, 20, 35, 50, 65]  # åœ¨è¿™äº›epochè¿›è¡Œè¿›åŒ–
    criterion = nn.CrossEntropyLoss()
    
    def optimizer_factory(params):
        return optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=5e-4)
    
    # ç®€åŒ–çš„è¿›åŒ–é…ç½® - æ¯æ¬¡åªåš1è½®å¿«é€Ÿè¿›åŒ–
    evolution_config = EvolutionConfig(
        max_evolution_rounds=1,  # æ¯æ¬¡è¿›åŒ–åªåš1è½®
        target_accuracy=args.target,
        max_mutations_per_round=1,  # æ¯æ¬¡åªå°è¯•1ä¸ªå˜å¼‚
        enable_sampling_validation=True,
        validation_sample_ratio=0.05,  # æ›´å¿«çš„éªŒè¯
        quick_validation_epochs=2,     # æ›´å¿«çš„éªŒè¯
        min_benefit_threshold=-0.01,
        confidence_threshold=0.05,
    )
    
    # è®°å½•è¿›åŒ–å†å²
    accuracy_history = []
    evolution_attempts = []
    successful_evolutions = 0
    
    # åˆå§‹å‡†ç¡®ç‡
    current_accuracy = trainer.evaluate_model(test_loader)
    accuracy_history.append(current_accuracy)
    logger.info(f"åˆå§‹å‡†ç¡®ç‡: {current_accuracy:.2f}%")
    
    # 80-epoch ä¸»å¾ªç¯
    for epoch in range(1, total_epochs + 1):
        logger.info(f"\n=== Epoch {epoch}/{total_epochs} ===")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¿›åŒ–epoch
        if epoch in evolution_epochs:
            logger.info(f"ğŸ§¬ è¿›åŒ–Epoch {epoch} - å°è¯•æ¶æ„è¿›åŒ–")
            
            # åˆ›å»ºè¿›åŒ–å¼•æ“
            evolution_engine = UnifiedIntelligentEvolutionEngine(
                config=evolution_config,
                device=device
            )
            
            try:
                # å•è½®è¿›åŒ–å°è¯•
                evolved_model, evolution_state = evolution_engine.evolve_architecture(
                    model=model,
                    train_loader=train_loader,
                    test_loader=test_loader,
                    criterion=criterion,
                    optimizer_factory=optimizer_factory
                )
                
                # æ£€æŸ¥è¿›åŒ–æ˜¯å¦æˆåŠŸ
                if evolution_state.successful_mutations > 0:
                    model = evolved_model
                    successful_evolutions += 1
                    improvement = evolution_state.best_accuracy - current_accuracy
                    logger.success(f"è¿›åŒ–æˆåŠŸï¼æ”¹è¿›: {improvement:.2f}%")
                    current_accuracy = evolution_state.best_accuracy
                else:
                    logger.info("è¿›åŒ–æœªäº§ç”Ÿæ”¹è¿›ï¼Œç»§ç»­å¸¸è§„è®­ç»ƒ")
                
                evolution_attempts.append({
                    'epoch': epoch,
                    'successful': evolution_state.successful_mutations > 0,
                    'improvement': evolution_state.best_accuracy - current_accuracy if evolution_state.successful_mutations > 0 else 0
                })
                
            except Exception as e:
                logger.warning(f"è¿›åŒ–å°è¯•å¤±è´¥: {e}")
                evolution_attempts.append({
                    'epoch': epoch,
                    'successful': False,
                    'improvement': 0
                })
        
        else:
            # å¸¸è§„è®­ç»ƒepoch
            logger.info(f"ğŸ“š å¸¸è§„è®­ç»ƒEpoch {epoch}")
            
            # å•epochè®­ç»ƒ
            trainer.model = model  # æ›´æ–°trainerçš„æ¨¡å‹å¼•ç”¨
            
            # è®­ç»ƒä¸€ä¸ªepoch
            model.train()
            optimizer = optimizer_factory(model.parameters())
            
            # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
            if epoch > 40:
                for param_group in optimizer.param_groups:
                    param_group['lr'] = 0.001
            elif epoch > 60:
                for param_group in optimizer.param_groups:
                    param_group['lr'] = 0.0001
            
            epoch_loss = 0.0
            batches_processed = 0
            
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                batches_processed += 1
            
            # è¯„ä¼°å½“å‰å‡†ç¡®ç‡
            current_accuracy = trainer.evaluate_model(test_loader)
            avg_loss = epoch_loss / max(batches_processed, 1)
            logger.info(f"Epoch {epoch} - æŸå¤±: {avg_loss:.4f}, å‡†ç¡®ç‡: {current_accuracy:.2f}%")
        
        # è®°å½•å‡†ç¡®ç‡å†å²
        accuracy_history.append(current_accuracy)
        
        # æ£€æŸ¥ç›®æ ‡è¾¾æˆ
        if current_accuracy >= args.target:
            logger.success(f"ğŸ¯ åœ¨Epoch {epoch}è¾¾åˆ°{args.target}%ç›®æ ‡å‡†ç¡®ç‡ï¼")
            break
    
    total_time = time.time() - start_time
    
    # æœ€ç»ˆè¯„ä¼°å’Œç»“æœ
    final_accuracy = trainer.evaluate_model(test_loader)
    total_improvement = final_accuracy - accuracy_history[0]
    
    logger.success(f"80-Epochæ··åˆè®­ç»ƒå®Œæˆï¼(ç”¨æ—¶: {total_time:.1f}s)")
    logger.info(f"åˆå§‹å‡†ç¡®ç‡: {accuracy_history[0]:.2f}%")
    logger.info(f"æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.2f}%")
    logger.info(f"æ€»æ”¹è¿›: {total_improvement:.2f}%")
    logger.info(f"æˆåŠŸè¿›åŒ–æ¬¡æ•°: {successful_evolutions}/{len(evolution_epochs)}")
    
    # æ˜¾ç¤ºè¿›åŒ–å†å²
    logger.info("è¿›åŒ–å°è¯•å†å²:")
    for attempt in evolution_attempts:
        status = "âœ…" if attempt['successful'] else "âŒ"
        logger.info(f"  Epoch {attempt['epoch']}: {status} æ”¹è¿› {attempt['improvement']:.2f}%")
    
    if final_accuracy >= args.target:
        logger.success(f"ğŸ‰ æˆåŠŸè¾¾åˆ°{args.target}%å‡†ç¡®ç‡ç›®æ ‡ï¼")
    else:
        logger.warning(f"è·ç¦»{args.target}%ç›®æ ‡è¿˜å·®: {args.target - final_accuracy:.2f}%")
    
    return {
        'initial_accuracy': accuracy_history[0],
        'final_accuracy': final_accuracy,
        'total_improvement': total_improvement,
        'target_reached': final_accuracy >= args.target,
        'successful_evolutions': successful_evolutions,
        'evolution_attempts': evolution_attempts,
        'accuracy_history': accuracy_history,
        'total_time': total_time
    }


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è§£æå‚æ•°
        args = parse_arguments()
        
        # åˆå§‹åŒ–ä¸»æ—¥å¿—å™¨
        logger = DemoLogger('main', level='INFO', verbose=args.verbose and not args.quiet)
        
        logger.info("ğŸš€ æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤ºå¯åŠ¨")
        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # è¿è¡Œå¯¹åº”çš„æ¼”ç¤º
        if args.baseline:
            results = run_baseline_demo(args)
        else:
            results = run_intelligent_evolution_experiment(args)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœæ‘˜è¦
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ˆ æ¼”ç¤ºç»“æœæ‘˜è¦")
        logger.info("="*60)
        
        if 'baseline_accuracy' in results:
            logger.info(f"åŸºå‡†å‡†ç¡®ç‡: {results['baseline_accuracy']:.2f}%")
        else:
            logger.info(f"åˆå§‹å‡†ç¡®ç‡: {results['initial_accuracy']:.2f}%")
            logger.info(f"æœ€ç»ˆå‡†ç¡®ç‡: {results['final_accuracy']:.2f}%")
            logger.info(f"æ€»ä½“æ”¹è¿›: {results['total_improvement']:.2f}%")
            logger.info(f"è¿›åŒ–æ—¶é—´: {results['evolution_time']:.1f}ç§’")
        
        status = "âœ… æ˜¯" if results['target_reached'] else "âŒ å¦"
        logger.info(f"ç›®æ ‡è¾¾æˆ: {status}")
        logger.info("="*60)
        
        # ç‰¹åˆ«åº†ç¥95%æˆå°±
        final_acc = results.get('final_accuracy', results.get('baseline_accuracy', 0))
        if args.enhanced and final_acc >= 95.0:
            logger.success("\nğŸŠğŸŠğŸŠ æ­å–œï¼æˆåŠŸè¾¾æˆ95%å‡†ç¡®ç‡æŒ‘æˆ˜ï¼ğŸŠğŸŠğŸŠ")
            logger.success("ğŸ† ç†è®ºæ¡†æ¶éªŒè¯æˆåŠŸï¼")
            
    except KeyboardInterrupt:
        logger.warning("\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        
    except Exception as e:
        logger.error(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
        import traceback
        if args.verbose:
            traceback.print_exc()
        return 1
        
    return 0


if __name__ == "__main__":
    exit(main())