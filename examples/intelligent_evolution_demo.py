#!/usr/bin/env python3
"""
æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤º - åŸºäºç†è®ºæ¡†æ¶çš„é‡æ„ç‰ˆæœ¬
Intelligent Architecture Evolution Demo - Theoretical Framework Refactored Version

ğŸ¯ æ ¸å¿ƒç›®æ ‡ï¼š
1. åœ¨CIFAR-10ä¸Šè¾¾åˆ°95%+çš„å‡†ç¡®ç‡
2. ä½¿ç”¨æ— å‚æ•°ç»“æ„è¯„ä¼°æŠ€æœ¯
3. å®ç°å¤šå˜å¼‚ç±»å‹æ”¶ç›ŠæœŸæœ›å»ºæ¨¡
4. åº”ç”¨è´å¶æ–¯å†³ç­–æ¡†æ¶è¿›è¡Œæ™ºèƒ½å˜å¼‚
5. é€šè¿‡è½»é‡çº§æŠ½æ ·éªŒè¯æ ¡å‡†æ”¶ç›ŠæœŸæœ›

ğŸ§¬ æ ¸å¿ƒç†è®ºå®ç°ï¼š
åŸºäºç”¨æˆ·æä¾›çš„ç†è®ºæ¡†æ¶ï¼š
- æœ‰æ•ˆä¿¡æ¯(EI): EI(S) = max_{p(x)} [I(X; Y) - I(X; Y|S)]
- ç§¯åˆ†ä¿¡æ¯(Î¦): Î¦ â‰ˆ Î£_{i,j} MI(H_i; H_j) - Î£_i MI(H_i; H_i)
- ç»“æ„å†—ä½™åº¦(SR): SR = rank(1/N Î£_n W_n^T W_n)
- å˜å¼‚ä¼˜å…ˆçº§: Score(S, M) = Î±Â·Î”I + Î²Â·Î¦(S) - Î³Â·SR(S) - Î´Â·Cost(M)
- æœŸæœ›æ•ˆç”¨: E[U(Î”I)] = E[1 - exp(-Î»Â·Î”I)]

ğŸ”§ æŠ€æœ¯æ ˆï¼š
- Enhanced ResNet with advanced architectures
- Parameter-free structural evaluation
- Multi-mutation type benefit modeling
- Lightweight sampling validation
- Bayesian decision framework

ğŸ“‹ ä½¿ç”¨æ–¹å¼ï¼š
1. åŸºç¡€æ¼”ç¤ºï¼špython examples/intelligent_evolution_demo.py
2. é«˜çº§æ¼”ç¤ºï¼špython examples/intelligent_evolution_demo.py --enhanced
3. åŸºå‡†å¯¹æ¯”ï¼špython examples/intelligent_evolution_demo.py --baseline
"""

import argparse
import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import time
import logging
from typing import Dict, List, Tuple, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ–°çš„ç†è®ºæ¡†æ¶ç»„ä»¶
from neuroexapt.core import (
    UnifiedIntelligentEvolutionEngine,
    NewEvolutionConfig as EvolutionConfig,
    ParameterFreeStructuralEvaluator,
    MultiMutationTypeEvaluator,
    LightweightSamplingValidator
)

# å¯¼å…¥æ¨¡å‹ç»„ä»¶
try:
    from neuroexapt.models import create_enhanced_model
except ImportError:
    # å¦‚æœæ²¡æœ‰å¢å¼ºæ¨¡å‹ï¼Œä½¿ç”¨åŸºç¡€ResNet
    from torchvision.models import resnet18, resnet34
    def create_enhanced_model(model_type='resnet18', num_classes=10, **kwargs):
        if model_type == 'resnet18':
            model = resnet18(num_classes=num_classes)
        elif model_type == 'resnet34':
            model = resnet34(num_classes=num_classes)
        else:
            model = resnet18(num_classes=num_classes)
        
        # CIFAR-10é€‚é…
        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        model.maxpool = nn.Identity()
        return model

logger = logging.getLogger(__name__)


class CIFAR10DataManager:
    """CIFAR-10æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, data_root='./data', batch_size=128, num_workers=4):
        self.data_root = data_root
        self.batch_size = batch_size
        self.num_workers = num_workers
        
    def get_data_loaders(self, enhanced_augmentation=True):
        """è·å–æ•°æ®åŠ è½½å™¨"""
        if enhanced_augmentation:
            # å¢å¼ºæ•°æ®å¢å¹¿
            train_transform = transforms.Compose([
                transforms.RandomCrop(32, padding=4),
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.ToTensor(),
                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
                transforms.RandomErasing(p=0.1)
            ])
        else:
            # åŸºç¡€æ•°æ®å¢å¹¿
            train_transform = transforms.Compose([
                transforms.RandomCrop(32, padding=4),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
            ])
        
        test_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        
        # åŠ è½½æ•°æ®é›†
        train_dataset = torchvision.datasets.CIFAR10(
            root=self.data_root, train=True, download=True, transform=train_transform
        )
        test_dataset = torchvision.datasets.CIFAR10(
            root=self.data_root, train=False, download=True, transform=test_transform
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset, batch_size=self.batch_size, shuffle=True,
            num_workers=self.num_workers, pin_memory=True
        )
        test_loader = DataLoader(
            test_dataset, batch_size=self.batch_size, shuffle=False,
            num_workers=self.num_workers, pin_memory=True
        )
        
        return train_loader, test_loader


class AdvancedTrainer:
    """é«˜çº§è®­ç»ƒå™¨"""
    
    def __init__(self, model, device, criterion=None):
        self.model = model.to(device)
        self.device = device
        self.criterion = criterion or nn.CrossEntropyLoss()
        
    def train_model(self, train_loader, test_loader, epochs=15, 
                   learning_rate=0.1, weight_decay=5e-4):
        """è®­ç»ƒæ¨¡å‹"""
        # ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
        optimizer = optim.SGD(
            self.model.parameters(),
            lr=learning_rate,
            momentum=0.9,
            weight_decay=weight_decay
        )
        
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        
        best_accuracy = 0.0
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.to(self.device), target.to(self.device)
                
                optimizer.zero_grad()
                output = self.model(data)
                loss = self.criterion(output, target)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                pred = output.argmax(dim=1)
                train_correct += pred.eq(target).sum().item()
                train_total += target.size(0)
            
            # æµ‹è¯•é˜¶æ®µ
            test_accuracy = self.evaluate_model(test_loader)
            train_accuracy = 100.0 * train_correct / train_total
            
            if test_accuracy > best_accuracy:
                best_accuracy = test_accuracy
            
            scheduler.step()
            
            # æ‰“å°è¿›åº¦
            if epoch % 5 == 0 or epoch == epochs - 1:
                print(f"Epoch {epoch+1}/{epochs}: "
                      f"Train Acc={train_accuracy:.2f}%, "
                      f"Test Acc={test_accuracy:.2f}%, "
                      f"Best={best_accuracy:.2f}%")
        
        return best_accuracy
    
    def evaluate_model(self, test_loader):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
        
        accuracy = 100.0 * correct / total
        return accuracy


def setup_logging(verbose=True):
    """è®¾ç½®æ—¥å¿—"""
    level = logging.INFO if verbose else logging.WARNING
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤º - ç†è®ºæ¡†æ¶ç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s                    # è¿è¡Œæ ‡å‡†æ¼”ç¤º
  %(prog)s --enhanced         # è¿è¡Œå¢å¼ºç‰ˆæ¼”ç¤º (95%ç›®æ ‡)
  %(prog)s --baseline         # è¿è¡ŒåŸºå‡†å¯¹æ¯”
  %(prog)s --quick            # å¿«é€Ÿæ¼”ç¤º (å‡å°‘è®­ç»ƒè½®æ•°)
  %(prog)s --target 90        # è®¾ç½®ç›®æ ‡å‡†ç¡®ç‡ä¸º90%
        """
    )
    
    parser.add_argument('--enhanced', action='store_true',
                       help='ä½¿ç”¨å¢å¼ºç‰ˆæ¶æ„å’Œè®­ç»ƒæŠ€æœ¯')
    parser.add_argument('--baseline', action='store_true', 
                       help='è¿è¡ŒåŸºå‡†å¯¹æ¯” (ä¸ä½¿ç”¨è¿›åŒ–)')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ (å‡å°‘è®­ç»ƒè½®æ•°)')
    parser.add_argument('--target', type=float, default=95.0,
                       help='ç›®æ ‡å‡†ç¡®ç‡ (é»˜è®¤: 95.0)')
    parser.add_argument('--epochs', type=int, default=15,
                       help='åˆå§‹è®­ç»ƒè½®æ•° (é»˜è®¤: 15)')
    parser.add_argument('--evolution-rounds', type=int, default=3,
                       help='è¿›åŒ–è½®æ•° (é»˜è®¤: 3)')
    parser.add_argument('--device', choices=['auto', 'cuda', 'cpu'], default='auto',
                       help='è®¡ç®—è®¾å¤‡ (é»˜è®¤: auto)')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--verbose', action='store_true', default=True,
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    parser.add_argument('--quiet', action='store_true',
                       help='å®‰é™æ¨¡å¼ (è¦†ç›–verbose)')
    
    return parser.parse_args()


def setup_device(device_arg='auto'):
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    if device_arg == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(device_arg)
    
    if device.type == 'cuda':
        print(f"ğŸš€ ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("ğŸ–¥ï¸ ä½¿ç”¨CPU")
    
    return device


def run_baseline_demo(args):
    """è¿è¡ŒåŸºå‡†æ¼”ç¤ºï¼ˆæ— è¿›åŒ–ï¼‰"""
    print("="*60)
    print("ğŸ“Š åŸºå‡†å¯¹æ¯”æ¼”ç¤º - æ— æ¶æ„è¿›åŒ–")
    print(f"ğŸ¯ ç›®æ ‡ï¼šCIFAR-10ä¸Š{args.target}%å‡†ç¡®ç‡")
    print("="*60)
    
    # è®¾ç½®ç¯å¢ƒ
    device = setup_device(args.device)
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # æ•°æ®ç®¡ç†
    data_manager = CIFAR10DataManager()
    train_loader, test_loader = data_manager.get_data_loaders(enhanced_augmentation=args.enhanced)
    
    # åˆ›å»ºåŸºç¡€æ¨¡å‹
    model_type = 'resnet34' if args.enhanced else 'resnet18'
    model = create_enhanced_model(model_type=model_type, num_classes=10)
    
    print(f"åŸºå‡†æ¨¡å‹: {model_type}")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # è®­ç»ƒæ¨¡å‹
    trainer = AdvancedTrainer(model, device)
    epochs = args.epochs if not args.quick else max(5, args.epochs // 3)
    
    print(f"\nğŸ“š å¼€å§‹åŸºå‡†è®­ç»ƒ ({epochs} epochs)...")
    final_accuracy = trainer.train_model(train_loader, test_loader, epochs=epochs)
    
    # ç»“æœæ‘˜è¦
    print(f"\nğŸ åŸºå‡†æ¼”ç¤ºå®Œæˆ")
    print(f"æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.2f}%")
    
    if final_accuracy >= args.target:
        print(f"ğŸ‰ åŸºå‡†æ¨¡å‹è¾¾åˆ°{args.target}%å‡†ç¡®ç‡ç›®æ ‡ï¼")
    else:
        print(f"ğŸ“Š åŸºå‡†æ¨¡å‹è·ç¦»{args.target}%ç›®æ ‡è¿˜å·®: {args.target - final_accuracy:.2f}%")
    
    return {
        'baseline_accuracy': final_accuracy,
        'target_reached': final_accuracy >= args.target,
        'model_type': model_type
    }


def run_intelligent_evolution_demo(args):
    """è¿è¡Œæ™ºèƒ½è¿›åŒ–æ¼”ç¤º"""
    print("="*60)
    print("ğŸ§¬ æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤º - ç†è®ºæ¡†æ¶ç‰ˆæœ¬")
    print(f"ğŸ¯ ç›®æ ‡ï¼šCIFAR-10ä¸Š{args.target}%å‡†ç¡®ç‡")
    print("="*60)
    
    # è®¾ç½®ç¯å¢ƒ
    device = setup_device(args.device)
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # æ•°æ®ç®¡ç†
    data_manager = CIFAR10DataManager()
    train_loader, test_loader = data_manager.get_data_loaders(enhanced_augmentation=args.enhanced)
    
    # åˆ›å»ºåˆå§‹æ¨¡å‹
    model_type = 'resnet34' if args.enhanced else 'resnet18'
    initial_model = create_enhanced_model(model_type=model_type, num_classes=10)
    
    print(f"åˆå§‹æ¨¡å‹: {model_type}")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in initial_model.parameters()):,}")
    
    # åˆå§‹è®­ç»ƒ
    trainer = AdvancedTrainer(initial_model, device)
    epochs = args.epochs if not args.quick else max(5, args.epochs // 3)
    
    print(f"\nğŸ“š åˆå§‹è®­ç»ƒ ({epochs} epochs)...")
    initial_accuracy = trainer.train_model(train_loader, test_loader, epochs=epochs)
    print(f"åˆå§‹å‡†ç¡®ç‡: {initial_accuracy:.2f}%")
    
    # é…ç½®è¿›åŒ–å¼•æ“
    evolution_config = EvolutionConfig(
        max_evolution_rounds=args.evolution_rounds if not args.quick else 2,
        target_accuracy=args.target,
        max_mutations_per_round=2 if args.quick else 3,
        enable_sampling_validation=not args.quick,  # å¿«é€Ÿæ¨¡å¼ç¦ç”¨æŠ½æ ·éªŒè¯
        validation_sample_ratio=0.05 if args.quick else 0.1,
        quick_validation_epochs=2 if args.quick else 3
    )
    
    # åˆ›å»ºè¿›åŒ–å¼•æ“
    evolution_engine = UnifiedIntelligentEvolutionEngine(
        config=evolution_config,
        device=device
    )
    
    print(f"\nğŸ§¬ å¼€å§‹æ™ºèƒ½æ¶æ„è¿›åŒ–...")
    print(f"è¿›åŒ–é…ç½®: {evolution_config.max_evolution_rounds}è½®, "
          f"ç›®æ ‡{evolution_config.target_accuracy}%")
    
    # æ‰§è¡Œè¿›åŒ–
    start_time = time.time()
    
    def optimizer_factory(params):
        return optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=5e-4)
    
    evolved_model, evolution_state = evolution_engine.evolve_architecture(
        model=initial_model,
        train_loader=train_loader,
        test_loader=test_loader,
        criterion=nn.CrossEntropyLoss(),
        optimizer_factory=optimizer_factory
    )
    
    evolution_time = time.time() - start_time
    
    # è·å–è¿›åŒ–æ‘˜è¦
    summary = evolution_engine.get_evolution_summary()
    
    # æœ€ç»ˆè¯„ä¼°
    final_trainer = AdvancedTrainer(evolved_model, device)
    final_accuracy = final_trainer.evaluate_model(test_loader)
    
    # ç»“æœå±•ç¤º
    print(f"\nğŸŠ æ™ºèƒ½è¿›åŒ–å®Œæˆï¼")
    print(f"è¿›åŒ–æ—¶é—´: {evolution_time:.1f} ç§’")
    print(f"åˆå§‹å‡†ç¡®ç‡: {initial_accuracy:.2f}%")
    print(f"æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.2f}%")
    print(f"æ€»ä½“æ”¹è¿›: {final_accuracy - initial_accuracy:.2f}%")
    print(f"è¿›åŒ–è½®æ•°: {summary['rounds_completed']}")
    print(f"æˆåŠŸå˜å¼‚: {summary['successful_mutations']}")
    print(f"å¤±è´¥å˜å¼‚: {summary['failed_mutations']}")
    
    if final_accuracy >= args.target:
        print(f"ğŸ‰ æˆåŠŸè¾¾åˆ°{args.target}%å‡†ç¡®ç‡ç›®æ ‡ï¼")
    else:
        print(f"ğŸ“ˆ è·ç¦»{args.target}%ç›®æ ‡è¿˜å·®: {args.target - final_accuracy:.2f}%")
    
    return {
        'initial_accuracy': initial_accuracy,
        'final_accuracy': final_accuracy,
        'total_improvement': final_accuracy - initial_accuracy,
        'target_reached': final_accuracy >= args.target,
        'evolution_summary': summary,
        'evolution_time': evolution_time
    }


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è§£æå‚æ•°
        args = parse_arguments()
        
        # è®¾ç½®æ—¥å¿—
        setup_logging(args.verbose and not args.quiet)
        
        print("ğŸš€ æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤ºå¯åŠ¨")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # è¿è¡Œå¯¹åº”çš„æ¼”ç¤º
        if args.baseline:
            results = run_baseline_demo(args)
        else:
            results = run_intelligent_evolution_demo(args)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“ˆ æ¼”ç¤ºç»“æœæ‘˜è¦")
        print("="*60)
        
        if 'baseline_accuracy' in results:
            print(f"åŸºå‡†å‡†ç¡®ç‡: {results['baseline_accuracy']:.2f}%")
        else:
            print(f"åˆå§‹å‡†ç¡®ç‡: {results['initial_accuracy']:.2f}%")
            print(f"æœ€ç»ˆå‡†ç¡®ç‡: {results['final_accuracy']:.2f}%")
            print(f"æ€»ä½“æ”¹è¿›: {results['total_improvement']:.2f}%")
            print(f"è¿›åŒ–æ—¶é—´: {results['evolution_time']:.1f}ç§’")
        
        print(f"ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if results['target_reached'] else 'âŒ å¦'}")
        print("="*60)
        
        # ç‰¹åˆ«åº†ç¥95%æˆå°±
        if (args.enhanced and results.get('final_accuracy', 
            results.get('baseline_accuracy', 0)) >= 95.0):
            print("\nğŸŠğŸŠğŸŠ æ­å–œï¼æˆåŠŸè¾¾æˆ95%å‡†ç¡®ç‡æŒ‘æˆ˜ï¼ğŸŠğŸŠğŸŠ")
            print("ğŸ† ç†è®ºæ¡†æ¶éªŒè¯æˆåŠŸï¼")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        logger.info("æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
        import traceback
        if args.verbose:
            traceback.print_exc()
        return 1
        
    return 0


if __name__ == "__main__":
    exit(main())