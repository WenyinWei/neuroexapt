"""
æ¼”ç¤ºå·¥å…·æ¨¡å—
Demo Utilities Module

æä¾›ç»Ÿä¸€çš„æ¼”ç¤ºè¾…åŠ©åŠŸèƒ½ï¼Œå‡å°‘ä»£ç é‡å¤ï¼Œæé«˜å¯è¯»æ€§ï¼š
1. è®¾å¤‡é…ç½®å’Œç¯å¢ƒè®¾ç½®
2. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
3. è®­ç»ƒå™¨åˆ›å»ºå’Œé…ç½®
4. æ—¥å¿—ç³»ç»Ÿé…ç½®
5. ç»“æœå±•ç¤ºå’Œæ ¼å¼åŒ–
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import logging
import time
import sys
import os
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from neuroexapt.models import create_enhanced_model


@dataclass
class DemoConfiguration:
    """æ¼”ç¤ºé…ç½®"""
    # è®¾å¤‡é…ç½®
    device_type: str = 'auto'
    seed: int = 42
    
    # æ•°æ®é…ç½®
    data_root: str = './data'
    batch_size: int = 128
    num_workers: int = 4
    enhanced_augmentation: bool = True
    
    # æ¨¡å‹é…ç½®
    model_type: str = 'enhanced_resnet34'
    num_classes: int = 10
    
    # è®­ç»ƒé…ç½®
    learning_rate: float = 0.1
    weight_decay: float = 5e-4
    momentum: float = 0.9
    
    # æ—¥å¿—é…ç½®
    log_level: str = 'INFO'
    verbose: bool = True


class DemoLogger:
    """ç»Ÿä¸€çš„æ¼”ç¤ºæ—¥å¿—ç³»ç»Ÿ"""
    
    def __init__(self, name: str = 'demo', level: str = 'INFO', verbose: bool = True):
        """
        åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        
        Args:
            name: æ—¥å¿—å™¨åç§°
            level: æ—¥å¿—çº§åˆ«
            verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        """
        self.logger = logging.getLogger(name)
        self.verbose = verbose
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        level_map = {
            'DEBUG': logging.DEBUG,
            'INFO': logging.INFO,
            'WARNING': logging.WARNING,
            'ERROR': logging.ERROR
        }
        self.logger.setLevel(level_map.get(level.upper(), logging.INFO))
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(self.logger.level)
        
        # è®¾ç½®æ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%H:%M:%S'
        )
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(console_handler)
        self.logger.propagate = False
    
    def info(self, message: str):
        """ä¿¡æ¯æ—¥å¿—"""
        if self.verbose:
            print(f"ğŸ“‹ {message}")
        self.logger.info(message)
    
    def success(self, message: str):
        """æˆåŠŸæ—¥å¿—"""
        if self.verbose:
            print(f"âœ… {message}")
        self.logger.info(f"SUCCESS: {message}")
    
    def warning(self, message: str):
        """è­¦å‘Šæ—¥å¿—"""
        if self.verbose:
            print(f"âš ï¸ {message}")
        self.logger.warning(message)
    
    def error(self, message: str):
        """é”™è¯¯æ—¥å¿—"""
        if self.verbose:
            print(f"âŒ {message}")
        self.logger.error(message)
    
    def progress(self, message: str):
        """è¿›åº¦æ—¥å¿—"""
        if self.verbose:
            print(f"ğŸ”„ {message}")
        self.logger.info(f"PROGRESS: {message}")


class DeviceManager:
    """è®¾å¤‡ç®¡ç†å™¨"""
    
    @staticmethod
    def setup_device(device_type: str = 'auto') -> torch.device:
        """
        è®¾ç½®è®¡ç®—è®¾å¤‡
        
        Args:
            device_type: è®¾å¤‡ç±»å‹ ('auto', 'cuda', 'cpu')
            
        Returns:
            torch.device: é…ç½®å¥½çš„è®¾å¤‡
        """
        if device_type == 'auto':
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            device = torch.device(device_type)
        
        return device
    
    @staticmethod
    def setup_environment(seed: int = 42, device: torch.device = None) -> torch.device:
        """
        è®¾ç½®ç¯å¢ƒå’Œéšæœºç§å­
        
        Args:
            seed: éšæœºç§å­
            device: è®¡ç®—è®¾å¤‡
            
        Returns:
            torch.device: é…ç½®å¥½çš„è®¾å¤‡
        """
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(seed)
        np.random.seed(seed)
        
        if device is None:
            device = DeviceManager.setup_device()
        
        # CUDAç›¸å…³è®¾ç½®
        if device.type == 'cuda':
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
        
        return device
    
    @staticmethod
    def get_device_info(device: torch.device) -> Dict[str, Any]:
        """
        è·å–è®¾å¤‡ä¿¡æ¯
        
        Args:
            device: è®¾å¤‡å¯¹è±¡
            
        Returns:
            Dict: è®¾å¤‡ä¿¡æ¯
        """
        info = {
            'device_type': device.type,
            'device_name': str(device)
        }
        
        if device.type == 'cuda':
            info.update({
                'gpu_name': torch.cuda.get_device_name(),
                'gpu_memory_total': torch.cuda.get_device_properties(0).total_memory / 1e9,
                'gpu_memory_allocated': torch.cuda.memory_allocated() / 1e9,
                'gpu_memory_cached': torch.cuda.memory_reserved() / 1e9
            })
        
        return info


class CIFAR10DataManager:
    """CIFAR-10æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, config: DemoConfiguration):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            config: æ¼”ç¤ºé…ç½®
        """
        self.config = config
        
    def get_transforms(self) -> Tuple[transforms.Compose, transforms.Compose]:
        """
        è·å–æ•°æ®å˜æ¢
        
        Returns:
            Tuple: (è®­ç»ƒå˜æ¢, æµ‹è¯•å˜æ¢)
        """
        if self.config.enhanced_augmentation:
            # å¢å¼ºæ•°æ®å¢å¹¿
            train_transform = transforms.Compose([
                transforms.RandomCrop(32, padding=4),
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.ToTensor(),
                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
                transforms.RandomErasing(p=0.1)
            ])
        else:
            # åŸºç¡€æ•°æ®å¢å¹¿
            train_transform = transforms.Compose([
                transforms.RandomCrop(32, padding=4),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
            ])
        
        test_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        
        return train_transform, test_transform
    
    def create_data_loaders(self) -> Tuple[DataLoader, DataLoader]:
        """
        åˆ›å»ºæ•°æ®åŠ è½½å™¨
        
        Returns:
            Tuple: (è®­ç»ƒåŠ è½½å™¨, æµ‹è¯•åŠ è½½å™¨)
        """
        train_transform, test_transform = self.get_transforms()
        
        # åŠ è½½æ•°æ®é›†
        train_dataset = torchvision.datasets.CIFAR10(
            root=self.config.data_root, train=True, download=True, transform=train_transform
        )
        test_dataset = torchvision.datasets.CIFAR10(
            root=self.config.data_root, train=False, download=True, transform=test_transform
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config.batch_size, 
            shuffle=True,
            num_workers=self.config.num_workers, 
            pin_memory=True
        )
        test_loader = DataLoader(
            test_dataset, 
            batch_size=self.config.batch_size, 
            shuffle=False,
            num_workers=self.config.num_workers, 
            pin_memory=True
        )
        
        return train_loader, test_loader


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨"""
    
    @staticmethod
    def create_model(config: DemoConfiguration) -> nn.Module:
        """
        åˆ›å»ºæ¨¡å‹
        
        Args:
            config: æ¼”ç¤ºé…ç½®
            
        Returns:
            nn.Module: åˆ›å»ºçš„æ¨¡å‹
        """
        try:
            model = create_enhanced_model(
                model_type=config.model_type,
                num_classes=config.num_classes
            )
        except Exception:
            # å¦‚æœå¢å¼ºæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹
            from torchvision.models import resnet18, resnet34
            
            if 'resnet34' in config.model_type.lower():
                model = resnet34(num_classes=config.num_classes)
            else:
                model = resnet18(num_classes=config.num_classes)
            
            # CIFAR-10é€‚é…
            model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
            model.maxpool = nn.Identity()
        
        return model
    
    @staticmethod
    def get_model_info(model: nn.Module) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Args:
            model: æ¨¡å‹å¯¹è±¡
            
        Returns:
            Dict: æ¨¡å‹ä¿¡æ¯
        """
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        # è®¡ç®—æ¨¡å‹å¤§å°ï¼ˆMBï¼‰
        param_size = sum(p.numel() * p.element_size() for p in model.parameters())
        buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())
        model_size_mb = (param_size + buffer_size) / (1024 ** 2)
        
        return {
            'model_name': type(model).__name__,
            'total_params': total_params,
            'trainable_params': trainable_params,
            'model_size_mb': model_size_mb,
            'param_size_mb': param_size / (1024 ** 2),
            'buffer_size_mb': buffer_size / (1024 ** 2)
        }


class AdvancedTrainer:
    """é«˜çº§è®­ç»ƒå™¨"""
    
    def __init__(self, model: nn.Module, device: torch.device, config: DemoConfiguration, 
                 logger: DemoLogger = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: æ¨¡å‹
            device: è®¾å¤‡
            config: é…ç½®
            logger: æ—¥å¿—å™¨
        """
        self.model = model.to(device)
        self.device = device
        self.config = config
        self.logger = logger or DemoLogger()
        self.criterion = nn.CrossEntropyLoss()
        
    def create_optimizer(self) -> optim.Optimizer:
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        return optim.SGD(
            self.model.parameters(),
            lr=self.config.learning_rate,
            momentum=self.config.momentum,
            weight_decay=self.config.weight_decay
        )
    
    def create_scheduler(self, optimizer: optim.Optimizer, epochs: int) -> optim.lr_scheduler._LRScheduler:
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    def train_model(self, train_loader: DataLoader, test_loader: DataLoader, 
                   epochs: int = 15) -> float:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            epochs: è®­ç»ƒè½®æ•°
            
        Returns:
            float: æœ€ä½³å‡†ç¡®ç‡
        """
        optimizer = self.create_optimizer()
        scheduler = self.create_scheduler(optimizer, epochs)
        
        best_accuracy = 0.0
        start_time = time.time()
        
        self.logger.progress(f"å¼€å§‹è®­ç»ƒ ({epochs} epochs)")
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.to(self.device), target.to(self.device)
                
                optimizer.zero_grad()
                output = self.model(data)
                loss = self.criterion(output, target)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                pred = output.argmax(dim=1)
                train_correct += pred.eq(target).sum().item()
                train_total += target.size(0)
            
            # æµ‹è¯•é˜¶æ®µ
            test_accuracy = self.evaluate_model(test_loader)
            train_accuracy = 100.0 * train_correct / train_total
            
            if test_accuracy > best_accuracy:
                best_accuracy = test_accuracy
            
            scheduler.step()
            
            # æ‰“å°è¿›åº¦
            if epoch % 5 == 0 or epoch == epochs - 1:
                elapsed_time = time.time() - start_time
                self.logger.info(f"Epoch {epoch+1}/{epochs}: "
                               f"Train={train_accuracy:.2f}%, Test={test_accuracy:.2f}%, "
                               f"Best={best_accuracy:.2f}%, Time={elapsed_time:.1f}s")
        
        total_time = time.time() - start_time
        self.logger.success(f"è®­ç»ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%, ç”¨æ—¶: {total_time:.1f}s")
        
        return best_accuracy
    
    def evaluate_model(self, test_loader: DataLoader) -> float:
        """
        è¯„ä¼°æ¨¡å‹
        
        Args:
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            
        Returns:
            float: å‡†ç¡®ç‡
        """
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
        
        accuracy = 100.0 * correct / total
        return accuracy


class ResultFormatter:
    """ç»“æœæ ¼å¼åŒ–å™¨"""
    
    @staticmethod
    def format_device_info(device_info: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è®¾å¤‡ä¿¡æ¯"""
        lines = [f"è®¾å¤‡ç±»å‹: {device_info['device_type'].upper()}"]
        
        if device_info['device_type'] == 'cuda':
            lines.extend([
                f"GPUåç§°: {device_info['gpu_name']}",
                f"GPUå†…å­˜: {device_info['gpu_memory_total']:.1f} GB",
                f"å·²åˆ†é…: {device_info['gpu_memory_allocated']:.2f} GB",
                f"å·²ç¼“å­˜: {device_info['gpu_memory_cached']:.2f} GB"
            ])
        
        return "\n".join(lines)
    
    @staticmethod
    def format_model_info(model_info: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ¨¡å‹ä¿¡æ¯"""
        return (f"æ¨¡å‹: {model_info['model_name']}\n"
                f"å‚æ•°é‡: {model_info['total_params']:,}\n"
                f"å¯è®­ç»ƒå‚æ•°: {model_info['trainable_params']:,}\n"
                f"æ¨¡å‹å¤§å°: {model_info['model_size_mb']:.2f} MB")
    
    @staticmethod
    def format_evolution_summary(summary: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è¿›åŒ–æ‘˜è¦"""
        lines = [
            f"è¿›åŒ–è½®æ•°: {summary['rounds_completed']}",
            f"åˆå§‹å‡†ç¡®ç‡: {summary['initial_accuracy']:.2f}%",
            f"æœ€ç»ˆå‡†ç¡®ç‡: {summary['final_accuracy']:.2f}%",
            f"æ€»ä½“æ”¹è¿›: {summary['total_improvement']:.2f}%",
            f"æˆåŠŸå˜å¼‚: {summary['successful_mutations']}",
            f"å¤±è´¥å˜å¼‚: {summary['failed_mutations']}",
            f"ç›®æ ‡è¾¾æˆ: {'âœ…' if summary['target_reached'] else 'âŒ'}"
        ]
        
        if 'total_parameter_increase' in summary:
            lines.extend([
                f"å‚æ•°å¢é•¿: {summary['total_parameter_increase']:.3f}",
                f"è®¡ç®—å¢é•¿: {summary['total_computation_increase']:.3f}"
            ])
        
        return "\n".join(lines)


# å¯¼å‡ºä¸»è¦ç±»å’Œå‡½æ•°
__all__ = [
    'DemoConfiguration',
    'DemoLogger', 
    'DeviceManager',
    'CIFAR10DataManager',
    'ModelManager',
    'AdvancedTrainer',
    'ResultFormatter'
]