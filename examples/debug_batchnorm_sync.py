#!/usr/bin/env python3
"""
ğŸ”§ BatchNormåŒæ­¥è°ƒè¯•è„šæœ¬
ä¸“é—¨ç”¨äºæµ‹è¯•å’Œä¿®å¤DNMæ¡†æ¶ä¸­çš„BatchNormåŒæ­¥é—®é¢˜
"""

import torch
import torch.nn as nn
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from neuroexapt.core.dnm_neuron_division import DNMNeuronDivisionManager

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

class SimpleTestNet(nn.Module):
    """ç®€å•çš„æµ‹è¯•ç½‘ç»œï¼Œæ¨¡æ‹ŸResNetç»“æ„"""
    
    def __init__(self):
        super().__init__()
        
        # ç®€å•çš„stemç»“æ„ (ç±»ä¼¼ResNet)
        self.stem = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),  # stem.0
            nn.BatchNorm2d(64),                                       # stem.1
            nn.ReLU(inplace=True)                                     # stem.2
        )
        
        # ç®€å•çš„å±‚ç»“æ„
        self.conv1 = nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(128)
        
        # åµŒå¥—ç»“æ„ (ç±»ä¼¼BasicBlock)
        self.block = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),  # block.0
            nn.BatchNorm2d(256),                                        # block.1
            nn.ReLU(inplace=True)                                       # block.2
        )
        
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(256, 10)
    
    def forward(self, x):
        x = self.stem(x)
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.block(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

def debug_batchnorm_finding():
    """è°ƒè¯•BatchNormæŸ¥æ‰¾é€»è¾‘"""
    
    print("ğŸ”§ Debug BatchNorm Finding Logic")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    model = SimpleTestNet()
    
    # æ‰“å°æ¨¡å‹ç»“æ„
    print("\nğŸ“‹ Model Structure:")
    for name, module in model.named_modules():
        if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):
            print(f"  {name}: {type(module).__name__}")
    
    # åˆ›å»ºDNMç®¡ç†å™¨
    dnm_config = {
        'monitoring': {
            'target_layers': ['conv'],
            'min_epoch_before_split': 0,
            'analysis_frequency': 1
        }
    }
    
    division_manager = DNMNeuronDivisionManager(config=dnm_config)
    
    # æµ‹è¯•BatchNormæŸ¥æ‰¾
    test_conv_layers = [
        'stem.0',      # Sequentialä¸­çš„Conv
        'conv1',       # é¡¶çº§Conv  
        'block.0'      # åµŒå¥—Sequentialä¸­çš„Conv
    ]
    
    print(f"\nğŸ” Testing BatchNorm Finding:")
    for conv_name in test_conv_layers:
        bn_name = division_manager.splitter._find_corresponding_batchnorm(model, conv_name)
        status = "âœ… Found" if bn_name else "âŒ Not Found"
        print(f"  {conv_name} -> {bn_name} ({status})")

def test_manual_split():
    """æµ‹è¯•æ‰‹åŠ¨åˆ†è£‚å¹¶éªŒè¯BatchNormåŒæ­¥"""
    
    print("\nğŸ§¬ Testing Manual Conv Split with BatchNorm Sync")
    print("=" * 50)
    
    model = SimpleTestNet()
    
    # è·å–åŸå§‹çš„stemæ¨¡å—
    stem_conv = model.stem[0]  # stem.0
    stem_bn = model.stem[1]    # stem.1
    
    print(f"\nğŸ“Š Before Split:")
    print(f"  Conv channels: {stem_conv.out_channels}")
    print(f"  BatchNorm features: {stem_bn.num_features}")
    
    # åˆ›å»ºDNMç®¡ç†å™¨å¹¶ç›´æ¥è°ƒç”¨åˆ†è£‚æ–¹æ³•
    dnm_config = {
        'monitoring': {
            'target_layers': ['conv'],
            'min_epoch_before_split': 0,
            'analysis_frequency': 1
        }
    }
    
    division_manager = DNMNeuronDivisionManager(config=dnm_config)
    
    try:
        # æ‰§è¡Œåˆ†è£‚: stem.0ä»64é€šé“åˆ†è£‚3ä¸ªé€šé“
        split_decisions = {
            'stem.0': [10, 20, 30]  # åˆ†è£‚ç¬¬10, 20, 30ä¸ªé€šé“
        }
        
        total_splits = division_manager._execute_splits(model, split_decisions)
        
        # æ£€æŸ¥åˆ†è£‚åçš„çŠ¶æ€
        new_stem_conv = model.stem[0]
        new_stem_bn = model.stem[1]
        
        print(f"\nğŸ“ˆ After Split:")
        print(f"  Conv channels: {new_stem_conv.out_channels}")
        print(f"  BatchNorm features: {new_stem_bn.num_features}")
        print(f"  Total splits executed: {total_splits}")
        
        # éªŒè¯æ¨¡å‹å¯ä»¥æ­£å¸¸å‰å‘ä¼ æ’­
        test_input = torch.randn(1, 3, 32, 32)
        
        with torch.no_grad():
            output = model(test_input)
            print(f"  Forward pass successful: {output.shape}")
            print(f"  âœ… BatchNorm sync successful!")
        
    except Exception as e:
        print(f"  âŒ Split failed: {e}")
        import traceback
        traceback.print_exc()

def stress_test_multiple_splits():
    """å‹åŠ›æµ‹è¯•ï¼šå¤šæ¬¡åˆ†è£‚"""
    
    print("\nğŸ’ª Stress Test: Multiple Splits")
    print("=" * 50)
    
    model = SimpleTestNet()
    
    dnm_config = {
        'monitoring': {
            'target_layers': ['conv'],
            'min_epoch_before_split': 0,
            'analysis_frequency': 1
        }
    }
    
    division_manager = DNMNeuronDivisionManager(config=dnm_config)
    
    initial_params = sum(p.numel() for p in model.parameters())
    print(f"Initial parameters: {initial_params:,}")
    
    # æ‰§è¡Œå¤šè½®åˆ†è£‚
    for round_num in range(3):
        print(f"\nğŸ”„ Split Round {round_num + 1}:")
        
        try:
            # æ¨¡æ‹Ÿä¸åŒçš„åˆ†è£‚å†³ç­–
            if round_num == 0:
                split_decisions = {'stem.0': [5, 15, 25]}
            elif round_num == 1:
                split_decisions = {'conv1': [10, 30, 50]}
            else:
                split_decisions = {'block.0': [20, 40, 60]}
            
            total_splits = division_manager._execute_splits(model, split_decisions)
            
            # éªŒè¯æ¨¡å‹
            test_input = torch.randn(2, 3, 32, 32)
            with torch.no_grad():
                output = model(test_input)
            
            current_params = sum(p.numel() for p in model.parameters())
            param_growth = (current_params - initial_params) / initial_params * 100
            
            print(f"  âœ… Round {round_num + 1} successful!")
            print(f"  Splits: {total_splits}, Params: {current_params:,} (+{param_growth:.1f}%)")
            
        except Exception as e:
            print(f"  âŒ Round {round_num + 1} failed: {e}")
            break

if __name__ == "__main__":
    print("ğŸ”§ DNM BatchNorm Synchronization Debug Suite")
    print("=" * 60)
    
    # 1. è°ƒè¯•BatchNormæŸ¥æ‰¾é€»è¾‘
    debug_batchnorm_finding()
    
    # 2. æµ‹è¯•æ‰‹åŠ¨åˆ†è£‚
    test_manual_split()
    
    # 3. å‹åŠ›æµ‹è¯•
    stress_test_multiple_splits()
    
    print("\nğŸ‰ Debug completed!")