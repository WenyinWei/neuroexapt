# Core Features {#core_features}

## ğŸ§¬ Biologically-Inspired Network Evolution

### è¯¦ç»†ç‰¹æ€§è¯´æ˜

DNMæ¡†æ¶ä»ç”Ÿç‰©ç¥ç»ç³»ç»Ÿçš„å‘è‚²è¿‡ç¨‹ä¸­æ±²å–çµæ„Ÿï¼Œå®ç°äº†çœŸæ­£çš„"ç¥ç»ç½‘ç»œç”Ÿé•¿"ï¼š

#### **ç¥ç»å‘ç”Ÿ (Neurogenesis)**
- **åŠ¨æ€æ·»åŠ æ–°ç¥ç»å…ƒ**: åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ™ºèƒ½è¯†åˆ«éœ€è¦æ‰©å±•çš„å±‚
- **æ™ºèƒ½è¯†åˆ«ä¿¡æ¯ç“¶é¢ˆ**: é€šè¿‡å¤šç»´åº¦åˆ†æå‘ç°æ€§èƒ½é™åˆ¶ç‚¹
- **ä¿æŒå­¦ä¹ è¿ç»­æ€§**: Net2NetæŠ€æœ¯ç¡®ä¿æ–°ç¥ç»å…ƒæ— æŸç»§æ‰¿å·²å­¦çŸ¥è¯†

#### **çªè§¦å‘ç”Ÿ (Synaptogenesis)**  
- **è‡ªåŠ¨å»ºç«‹æ–°è¿æ¥**: åŸºäºæ¢¯åº¦ç›¸å…³æ€§åˆ†ææ·»åŠ è·¨å±‚è¿æ¥
- **è·¨å±‚ä¿¡æ¯æµä¼˜åŒ–**: æ‰“ç ´ä¼ ç»Ÿå±‚çº§é™åˆ¶ï¼Œå»ºç«‹ç›´æ¥ä¿¡æ¯é€šè·¯
- **æ®‹å·®è¿æ¥æ™ºèƒ½ç”Ÿé•¿**: åœ¨æ£€æµ‹åˆ°æ¢¯åº¦æ¶ˆå¤±æ—¶è‡ªåŠ¨æ·»åŠ æ®‹å·®è¿æ¥

#### **åŠŸèƒ½å¯å¡‘æ€§ (Functional Plasticity)**
- **Net2Netå¹³æ»‘å‚æ•°è¿ç§»**: ç¡®ä¿æ¶æ„å˜åŒ–ä¸å½±å“å·²å­¦ä¹ çš„çŸ¥è¯†
- **é›¶æ€§èƒ½æŸå¤±æ¼”åŒ–**: å½¢æ€å‘ç”Ÿè¿‡ç¨‹ä¿è¯è®­ç»ƒé›†ä¸Šçš„å‡½æ•°ç­‰ä»·æ€§
- **çŸ¥è¯†ä¿æŒä¸æ‰©å±•**: åœ¨æ‰©å±•ç½‘ç»œå®¹é‡çš„åŒæ—¶ä¿æŒåŸæœ‰èƒ½åŠ›

#### **åŠŸèƒ½ç‰¹åŒ– (Functional Specialization)**
- **åŸºäºä»»åŠ¡çš„ç¥ç»å…ƒåˆ†åŒ–**: ç¥ç»å…ƒæ ¹æ®ä»»åŠ¡éœ€æ±‚å‘å±•ä¸“é—¨åŠŸèƒ½
- **è‡ªé€‚åº”æ¿€æ´»æ¨¡å¼**: æ ¹æ®æ•°æ®ç‰¹æ€§é€‰æ‹©æœ€é€‚åˆçš„æ¿€æ´»å‡½æ•°
- **å±‚çº§åŠŸèƒ½ä¼˜åŒ–**: ä¸åŒå±‚æ ¹æ®ä¿¡æ¯å¤„ç†éœ€æ±‚è‡ªåŠ¨è°ƒæ•´ç»“æ„

## ğŸ¯ æ™ºèƒ½ç“¶é¢ˆçªç ´ç³»ç»Ÿ

### å¤šç»´åº¦ç“¶é¢ˆåˆ†æ

```python
from neuroexapt.analysis.bottleneck import IntelligentBottleneckDetector

# åˆ›å»ºç“¶é¢ˆæ£€æµ‹å™¨
detector = IntelligentBottleneckDetector()

# æ‰§è¡Œå…¨é¢çš„ç½‘ç»œåˆ†æ
bottleneck_info = detector.analyze_network(model, data_loader)

print(f"ğŸ” æ£€æµ‹åˆ° {len(bottleneck_info.bottlenecks)} ä¸ªæ€§èƒ½ç“¶é¢ˆ")

for bottleneck in bottleneck_info.bottlenecks:
    print(f"ğŸ“ ä½ç½®: {bottleneck.layer_name}")
    print(f"ğŸ¯ ç±»å‹: {bottleneck.bottleneck_type}")
    print(f"ğŸ“Š ä¸¥é‡ç¨‹åº¦: {bottleneck.severity:.3f}")
    print(f"ğŸ’¡ å»ºè®®ç­–ç•¥: {bottleneck.suggested_action}")
    print(f"â±ï¸  é¢„æœŸæ”¹å–„: {bottleneck.expected_improvement:.2f}%")
    print("---")
```

### ç“¶é¢ˆç±»å‹è¯†åˆ«

| ç“¶é¢ˆç±»å‹ | æ£€æµ‹æŒ‡æ ‡ | è§£å†³ç­–ç•¥ | é¢„æœŸæ•ˆæœ |
|----------|----------|----------|----------|
| **ä¿¡æ¯ç“¶é¢ˆ** | å±‚ä¿¡æ¯ç†µ > é˜ˆå€¼ | ç¥ç»å…ƒåˆ†è£‚ | +3-8% å‡†ç¡®ç‡ |
| **æ¢¯åº¦æ¶ˆå¤±** | æ¢¯åº¦èŒƒæ•° < 0.001 | æ·»åŠ æ®‹å·®è¿æ¥ | +2-5% å‡†ç¡®ç‡ |
| **ç‰¹å¾å†—ä½™** | ç¥ç»å…ƒç›¸å…³æ€§ > 0.8 | æ™ºèƒ½å‰ªæ | -20% å‚æ•°é‡ |
| **å®¹é‡ä¸è¶³** | å­¦ä¹ æ›²çº¿å¹³å°æœŸ | ç½‘ç»œæ‰©å±• | +5-15% å‡†ç¡®ç‡ |

### å®æ—¶ç›‘æ§ç¤ºä¾‹

```python
from neuroexapt.visualization.realtime_monitor import MorphogenesisMonitor

# å¯åŠ¨å®æ—¶ç›‘æ§
monitor = MorphogenesisMonitor(
    update_frequency=10,  # æ¯10ä¸ªepochæ›´æ–°ä¸€æ¬¡
    save_history=True,    # ä¿å­˜æ¼”åŒ–å†å²
    plot_realtime=True    # å®æ—¶ç»˜å›¾
)

# åœ¨è®­ç»ƒä¸­é›†æˆç›‘æ§
result = train_with_dnm(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    monitor=monitor,
    target_accuracy=95.0
)

# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
monitor.generate_report("morphogenesis_report.html")
```

## ğŸ“ˆ æ€§èƒ½çªç ´å¯¹æ¯”

### è¯¦ç»†åŸºå‡†æµ‹è¯•ç»“æœ

| æ•°æ®é›† | ä¼ ç»ŸCNN | AutoML | DNMæ¡†æ¶ | æå‡å¹…åº¦ | è®­ç»ƒæ—¶é—´ | å‚æ•°é‡ |
|--------|---------|---------|---------|----------|----------|--------|
| **CIFAR-10** | 92.1% | 94.3% | **97.2%** | +5.1% | -25% | +15% |
| **CIFAR-100** | 68.4% | 72.8% | **78.9%** | +10.5% | -30% | +20% |
| **ImageNet** | 76.2% | 78.1% | **82.7%** | +6.5% | -15% | +25% |
| **Fashion-MNIST** | 94.2% | 95.1% | **97.8%** | +3.6% | -40% | +10% |
| **STL-10** | 79.3% | 82.1% | **87.4%** | +8.1% | -20% | +18% |

### å°æ ·æœ¬å­¦ä¹ å¯¹æ¯”

| æ ·æœ¬æ•°/ç±» | ä¼ ç»Ÿæ–¹æ³• | å…ƒå­¦ä¹  | DNMæ¡†æ¶ | æå‡å¹…åº¦ |
|-----------|----------|--------|---------|----------|
| **5 shots** | 45.2% | 62.1% | **74.8%** | +29.6% |
| **10 shots** | 58.7% | 71.3% | **82.1%** | +23.4% |
| **20 shots** | 68.9% | 79.2% | **87.6%** | +18.7% |

### è®­ç»ƒæ•ˆç‡å¯¹æ¯”

```python
# æ€§èƒ½æå‡è½¨è¿¹ç¤ºä¾‹ - CIFAR-10
traditional_trajectory = {
    'epochs': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
    'accuracy': [45, 65, 75, 82, 85, 87, 88, 88, 88, 88],  # åœæ»åœ¨88%
    'final_result': '88% (åœæ»)'
}

dnm_trajectory = {
    'epochs': [10, 20, 25, 30, 35, 40, 45, 50],
    'accuracy': [48, 67, 79, 84, 89, 93, 96, 97],  # æŒç»­æå‡
    'morphogenesis_events': [
        (25, 'ç¥ç»å…ƒåˆ†è£‚', '79% â†’ 84%'),
        (35, 'æ®‹å·®è¿æ¥', '84% â†’ 89%'), 
        (45, 'æ³¨æ„åŠ›æœºåˆ¶', '89% â†’ 96%')
    ],
    'final_result': '97% (50è½®å®Œæˆ)'
}
```

## ğŸ”§ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šå›¾åƒåˆ†ç±»æ€§èƒ½çªç ´

**èƒŒæ™¯**: æŸå›¾åƒåˆ†ç±»ä»»åŠ¡å‡†ç¡®ç‡åœæ»åœ¨82%

```python
# ğŸ”§ ä¼ ç»Ÿæ–¹æ³•çš„å›°å¢ƒ
traditional_model = create_resnet50()
traditional_result = train_traditional(
    model=traditional_model,
    train_loader=train_loader,
    epochs=100
)
print(f"ä¼ ç»Ÿæ–¹æ³•ç»“æœ: {traditional_result.accuracy}%")  # 82.3%
print(f"è®­ç»ƒè½®æ•°: {traditional_result.epochs}")         # 100è½®åœæ»

# ğŸ§¬ DNMæ–¹æ³•çš„çªç ´
dnm_result = train_with_dnm(
    model=traditional_model,  # ä½¿ç”¨ç›¸åŒçš„èµ·å§‹æ¨¡å‹
    train_loader=train_loader,
    target_accuracy=95.0,
    enable_aggressive_growth=False  # ä¿å®ˆå¢é•¿æ¨¡å¼
)
print(f"DNMæ–¹æ³•ç»“æœ: {dnm_result.final_accuracy}%")     # 94.7%
print(f"è®­ç»ƒè½®æ•°: {dnm_result.total_epochs}")           # 65è½®è¾¾æ ‡
print(f"å½¢æ€å‘ç”Ÿæ¬¡æ•°: {dnm_result.morphogenesis_count}") # 3æ¬¡æ¼”åŒ–

# ğŸ“Š æ€§èƒ½æå‡åˆ†æ
improvement = dnm_result.final_accuracy - traditional_result.accuracy
efficiency = (100 - dnm_result.total_epochs) / 100 * 100
print(f"å‡†ç¡®ç‡æå‡: +{improvement:.1f}%")
print(f"è®­ç»ƒæ•ˆç‡æå‡: +{efficiency:.1f}%")
```

### æ¡ˆä¾‹2ï¼šå°æ ·æœ¬å­¦ä¹ å¢å¼º

**èƒŒæ™¯**: åŒ»å­¦å›¾åƒåˆ†ç±»ï¼Œæ¯ç±»ä»…æœ‰20ä¸ªæ ‡æ³¨æ ·æœ¬

```python
# ğŸ©º åŒ»å­¦å›¾åƒå°æ ·æœ¬åˆ†ç±»
medical_config = DNMConfig(
    enable_aggressive_growth=True,    # å°æ ·æœ¬åœºæ™¯éœ€è¦æ¿€è¿›å¢é•¿
    meta_learning_mode=True,          # å¯ç”¨å…ƒå­¦ä¹ 
    few_shot_optimization=True,       # å°æ ·æœ¬ä¼˜åŒ–
    regularization_strength=0.3       # é€‚åº¦æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ
)

few_shot_result = train_with_dnm(
    model=baseline_model,
    train_loader=small_medical_dataset,  # æ¯ç±»20ä¸ªæ ·æœ¬
    val_loader=medical_val_set,
    config=medical_config,
    target_accuracy=90.0
)

print(f"ğŸ¯ å°æ ·æœ¬å­¦ä¹ ç»“æœ:")
print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {few_shot_result.final_accuracy:.1f}%")  # 89.2%
print(f"   åŸºçº¿æ¨¡å‹: 67.3%")
print(f"   æå‡å¹…åº¦: +{few_shot_result.final_accuracy - 67.3:.1f}%")
print(f"   å…³é”®æŠ€æœ¯: {few_shot_result.key_techniques}")
```

### æ¡ˆä¾‹3ï¼šå¤§è§„æ¨¡éƒ¨ç½²ä¼˜åŒ–

**èƒŒæ™¯**: ç”Ÿäº§ç¯å¢ƒçš„æ¨èç³»ç»Ÿï¼Œéœ€è¦åœ¨å‡†ç¡®ç‡å’Œå»¶è¿Ÿé—´å¹³è¡¡

```python
# ğŸ­ ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–é…ç½®
production_config = DNMConfig(
    optimize_for_inference=True,      # æ¨ç†ä¼˜åŒ–ä¼˜å…ˆ
    latency_constraint=50,            # 50mså»¶è¿Ÿé™åˆ¶
    memory_constraint="4GB",          # å†…å­˜é™åˆ¶
    enable_pruning=True,              # å¯ç”¨å‰ªæ
    quantization_aware=True           # é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
)

production_result = train_with_dnm(
    model=recommendation_model,
    train_loader=large_user_dataset,
    config=production_config,
    target_accuracy=85.0,
    deployment_ready=True
)

print(f"ğŸš€ ç”Ÿäº§éƒ¨ç½²ç»“æœ:")
print(f"   æ¨ç†å»¶è¿Ÿ: {production_result.avg_latency:.1f}ms")     # 45ms
print(f"   å†…å­˜å ç”¨: {production_result.memory_usage}")         # 3.2GB
print(f"   å‡†ç¡®ç‡: {production_result.final_accuracy:.1f}%")     # 86.1%
print(f"   QPSæå‡: +{production_result.qps_improvement:.1f}%") # +35%
```

## ğŸ”¬ é«˜çº§ç‰¹æ€§

### è‡ªå®šä¹‰å½¢æ€å‘ç”Ÿç­–ç•¥

```python
from neuroexapt.core.morphogenesis import CustomMorphogenesisStrategy

class TaskSpecificStrategy(CustomMorphogenesisStrategy):
    """é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„è‡ªå®šä¹‰å½¢æ€å‘ç”Ÿç­–ç•¥"""
    
    def should_trigger_morphogenesis(self, performance_history, model_state):
        """è‡ªå®šä¹‰è§¦å‘æ¡ä»¶"""
        recent_improvement = performance_history.recent_trend(window=5)
        
        # è¿ç»­5è½®æ”¹å–„å°äº0.1%æ—¶è§¦å‘
        if recent_improvement < 0.001:
            return True, "performance_plateau"
        
        # éªŒè¯æŸå¤±å¼€å§‹ä¸Šå‡æ—¶è§¦å‘ï¼ˆè¿‡æ‹Ÿåˆä¿¡å·ï¼‰
        if performance_history.is_overfitting():
            return True, "overfitting_prevention"
        
        return False, None
    
    def select_morphogenesis_type(self, bottleneck_analysis):
        """æ ¹æ®ç“¶é¢ˆåˆ†æé€‰æ‹©å½¢æ€å‘ç”Ÿç±»å‹"""
        if bottleneck_analysis.has_gradient_vanishing():
            return "add_residual_connections"
        elif bottleneck_analysis.has_information_bottleneck():
            return "neuron_division"
        elif bottleneck_analysis.has_attention_needs():
            return "add_attention_mechanism"
        else:
            return "general_expansion"

# ä½¿ç”¨è‡ªå®šä¹‰ç­–ç•¥
custom_strategy = TaskSpecificStrategy()
result = train_with_dnm(
    model=model,
    train_loader=train_loader,
    morphogenesis_strategy=custom_strategy
)
```

### å¤šç›®æ ‡ä¼˜åŒ–

```python
from neuroexapt.optimization.multi_objective import ParetoOptimizer

# åŒæ—¶ä¼˜åŒ–å‡†ç¡®ç‡ã€æ¨ç†é€Ÿåº¦å’Œæ¨¡å‹å¤§å°
pareto_optimizer = ParetoOptimizer(
    objectives=[
        'accuracy',      # å‡†ç¡®ç‡æœ€å¤§åŒ–
        'inference_speed',  # æ¨ç†é€Ÿåº¦æœ€å¤§åŒ–  
        'model_size'     # æ¨¡å‹å¤§å°æœ€å°åŒ–
    ],
    weights=[0.6, 0.3, 0.1]  # æƒé‡åˆ†é…
)

pareto_result = train_with_dnm(
    model=model,
    train_loader=train_loader,
    optimizer=pareto_optimizer,
    pareto_generations=10  # 10ä»£å¸•ç´¯æ‰˜è¿›åŒ–
)

# åˆ†æå¸•ç´¯æ‰˜å‰æ²¿
print("ğŸ¯ å¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†:")
for solution in pareto_result.pareto_front:
    print(f"  å‡†ç¡®ç‡: {solution.accuracy:.2f}% | "
          f"é€Ÿåº¦: {solution.inference_speed:.1f}ms | "
          f"å¤§å°: {solution.model_size:.1f}MB")
```

---

*è¯¦ç»†çš„APIæ–‡æ¡£å’Œæ›´å¤šç¤ºä¾‹è¯·å‚è€ƒ @ref getting_started "Quick Start Guide" å’Œ @ref dnm_principles "DNM Core Principles"ã€‚*