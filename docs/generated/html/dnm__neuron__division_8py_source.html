<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta name="description" content="NeuroExapt - Advanced Neural Architecture Search and Dynamic Morphogenesis Framework">
    <meta name="keywords" content="neural architecture search, dynamic morphogenesis, deep learning, AI, PyTorch">
    <meta name="author" content="NeuroExapt Team">
    <meta property="og:title" content="NeuroExapt Documentation">
    <meta property="og:description" content="Advanced Neural Architecture Search Framework">
    <meta property="og:type" content="website">

<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuroExapt: neuroexapt/core/dnm_neuron_division.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="custom.css" rel="stylesheet" type="text/css"/>
<!-- NeuroExapt Custom Styles -->
<style>
/* Enhanced header styling */
.header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px 0;
    text-align: center;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}
.header h1 {
    margin: 0;
    font-size: 2.5em;
    font-weight: 300;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
}
.header .subtitle {
    font-size: 1.2em;
    opacity: 0.9;
    margin-top: 10px;
}
/* Enhanced navigation */
.tablist {
    background: #f8f9fa;
    border-bottom: 2px solid #e9ecef;
}
.tablist li.current a {
    background: #667eea;
    color: white;
}
/* Improved content layout */
.contents {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}
/* Code highlighting */
.fragment {
    background: #f8f9fa;
    border-left: 4px solid #667eea;
    padding: 15px;
    margin: 15px 0;
    border-radius: 0 8px 8px 0;
}
/* Enhanced tables */
table.memberdecls {
    border-collapse: collapse;
    width: 100%;
    margin: 20px 0;
}
table.memberdecls td {
    border: 1px solid #e9ecef;
    padding: 12px;
}
/* Better typography */
body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    line-height: 1.6;
    color: #343a40;
}
h1, h2, h3, h4, h5, h6 {
    color: #495057;
    font-weight: 500;
}
/* Responsive design */
@media (max-width: 768px) {
    .header h1 {
        font-size: 2em;
    }
    .contents {
        padding: 15px;
    }
}
/* Dark mode support */
@media (prefers-color-scheme: dark) {
    body {
        background-color: #1a1a1a;
        color: #e9ecef;
    }
    .header {
        background: linear-gradient(135deg, #4a5568 0%, #2d3748 100%);
    }
    .fragment {
        background: #2d3748;
        color: #e9ecef;
    }
}
</style>
<!-- Analytics (if needed) -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<!--
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_TRACKING_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'GA_TRACKING_ID');
</script>
-->
</head>
<body>
<!-- Custom Header -->
<div class="header">
    <h1>🧠 NeuroExapt</h1>
    <div class="subtitle">Advanced Neural Architecture Search and Dynamic Morphogenesis Framework</div>
    <div style="margin-top: 15px; font-size: 0.9em;">
        <span style="background: rgba(255,255,255,0.2); padding: 5px 10px; border-radius: 15px; margin: 0 5px;">
            🚀 Dynamic Neural Morphogenesis
        </span>
        <span style="background: rgba(255,255,255,0.2); padding: 5px 10px; border-radius: 15px; margin: 0 5px;">
            🔬 Advanced Architecture Search
        </span>
        <span style="background: rgba(255,255,255,0.2); padding: 5px 10px; border-radius: 15px; margin: 0 5px;">
            ⚡ High-Performance Computing
        </span>
    </div>
</div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! --><!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('dnm__neuron__division_8py_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">dnm_neuron_division.py</div></div>
</div><!--header-->
<div class="contents">
<a href="dnm__neuron__division_8py.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno"><a class="line" href="namespaceneuroexapt_1_1core_1_1dnm__neuron__division.html">    1</a></span><span class="comment">#!/usr/bin/env python3</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span>\defgroup group_dnm_neuron_division Dnm Neuron Division</div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span>\ingroup core</div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span>Dnm Neuron Division module <span class="keywordflow">for</span> NeuroExapt framework.</div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="stringliteral">DNM Neuron Division Module - 神经元分裂专用模块</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="stringliteral">🧬 核心功能：</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="stringliteral">1. 智能识别分裂时机</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="stringliteral">2. 执行不同类型的神经元分裂</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="stringliteral">3. 保持网络功能性</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="stringliteral">4. 优化参数初始化</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="stringliteral">🎯 目标：实现真正有效的神经元增长和网络扩展</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="keyword">import</span> torch</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="keyword">import</span> logging</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="keyword">from</span> typing <span class="keyword">import</span> Dict, List, Tuple, Optional, Any</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="keyword">import</span> copy</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="keyword">import</span> math</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span> </div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno"><a class="line" href="namespaceneuroexapt_1_1core_1_1dnm__neuron__division.html#ae88e1ba50eacf83f9305be2c00e71e1e">   31</a></span>logger = logging.getLogger(__name__)</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span> </div>
<div class="foldopen" id="foldopen00033" data-start="" data-end="">
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html">   33</a></span><span class="keyword">class </span><a class="code hl_class" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html">NeuronDivisionStrategies</a>:</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>    <span class="stringliteral">&quot;&quot;&quot;神经元分裂策略集合&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>    </div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>    <span class="preprocessor">@staticmethod</span></div>
<div class="foldopen" id="foldopen00037" data-start="" data-end="">
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#a67f8f3a023f7b536b38e57d19029895c">   37</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#a67f8f3a023f7b536b38e57d19029895c">symmetric_division</a>(original_weights: torch.Tensor, division_ratio: float = 0.5) -&gt; Tuple[torch.Tensor, torch.Tensor]:</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>        <span class="stringliteral">&quot;&quot;&quot;对称分裂：将一个神经元分裂为两个相似的神经元&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>        device = original_weights.device</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>        dtype = original_weights.dtype</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>        noise_scale = torch.std(original_weights) * 0.1</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>        </div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>        <span class="comment"># 第一个神经元：保持大部分原始权重</span></div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>        neuron1 = original_weights + torch.normal(0, noise_scale, size=original_weights.shape, device=device, dtype=dtype)</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>        </div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>        <span class="comment"># 第二个神经元：稍微不同的权重</span></div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>        neuron2 = original_weights * division_ratio + torch.normal(0, noise_scale, size=original_weights.shape, device=device, dtype=dtype)</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>        </div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>        <span class="keywordflow">return</span> neuron1, neuron2</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    </div>
</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>    <span class="preprocessor">@staticmethod</span></div>
<div class="foldopen" id="foldopen00052" data-start="" data-end="">
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#abd8c770a9890fc69efe6c5c397331c12">   52</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#abd8c770a9890fc69efe6c5c397331c12">asymmetric_division</a>(original_weights: torch.Tensor, specialization_factor: float = 0.3) -&gt; Tuple[torch.Tensor, torch.Tensor]:</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>        <span class="stringliteral">&quot;&quot;&quot;非对称分裂：创建专门化的神经元&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>        std_dev = torch.std(original_weights)</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>        </div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>        <span class="comment"># 主神经元：保持大部分功能</span></div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>        main_neuron = original_weights * (1.0 + specialization_factor)</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>        </div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>        <span class="comment"># 专门化神经元：关注特定模式</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>        specialized_weights = torch.zeros_like(original_weights)</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>        <span class="comment"># 只保留最重要的连接</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>        threshold = torch.quantile(torch.abs(original_weights), 0.7)</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>        mask = torch.abs(original_weights) &gt; threshold</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>        specialized_weights[mask] = original_weights[mask] * (1.0 + specialization_factor)</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>        </div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>        <span class="keywordflow">return</span> main_neuron, specialized_weights</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>    </div>
</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>    <span class="preprocessor">@staticmethod</span></div>
<div class="foldopen" id="foldopen00069" data-start="" data-end="">
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#a0ecdf68b5438c003aeac21f35817a597">   69</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#a0ecdf68b5438c003aeac21f35817a597">functional_division</a>(original_weights: torch.Tensor, activation_pattern: Optional[torch.Tensor] = <span class="keywordtype">None</span>) -&gt; Tuple[torch.Tensor, torch.Tensor]:</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>        <span class="stringliteral">&quot;&quot;&quot;功能分裂：基于激活模式进行分裂&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        <span class="keywordflow">if</span> activation_pattern <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>            <span class="comment"># 基于激活模式分割权重</span></div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>            high_activation_mask = activation_pattern &gt; torch.median(activation_pattern)</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>            </div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>            <span class="comment"># 高激活神经元</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>            high_act_neuron = original_weights.clone()</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>            high_act_neuron[~high_activation_mask] *= 0.3</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>            </div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>            <span class="comment"># 低激活神经元  </span></div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>            low_act_neuron = original_weights.clone()</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>            low_act_neuron[high_activation_mask] *= 0.3</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>            </div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>            <span class="keywordflow">return</span> high_act_neuron, low_act_neuron</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>            <span class="comment"># 随机功能分割</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>            mask = torch.rand_like(original_weights) &gt; 0.5</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>            neuron1 = original_weights.clone()</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>            neuron2 = original_weights.clone()</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>            </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>            neuron1[~mask] *= 0.2</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>            neuron2[mask] *= 0.2</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>            </div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>            <span class="keywordflow">return</span> neuron1, neuron2</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00095" data-start="" data-end="">
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html">   95</a></span><span class="keyword">class </span><a class="code hl_class" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html">AdaptiveNeuronDivision</a>:</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    <span class="stringliteral">&quot;&quot;&quot;自适应神经元分裂器&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>    </div>
<div class="foldopen" id="foldopen00098" data-start="" data-end="">
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a97067cf5d162473cde419ba77ea38d52">   98</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a97067cf5d162473cde419ba77ea38d52">__init__</a>(self):</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">   99</a></span>        self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a> = defaultdict(list)</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a861deca5cdda66da984f8b7704f455da">  100</a></span>        self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a861deca5cdda66da984f8b7704f455da">performance_tracker</a> = {}</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>        </div>
</div>
<div class="foldopen" id="foldopen00102" data-start="" data-end="">
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#abb34f44e89dd00f1ad80f278a6b5e4ba">  102</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#abb34f44e89dd00f1ad80f278a6b5e4ba">execute_division</a>(self, model: nn.Module, layer_name: str, </div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>                        division_strategy: str = <span class="stringliteral">&#39;adaptive&#39;</span>,</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>                        target_expansion: float = 0.2) -&gt; Tuple[nn.Module, int]:</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>        <span class="stringliteral">&quot;&quot;&quot;执行神经元分裂&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>        </div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>        <span class="comment"># 获取原始设备</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>        original_device = next(model.parameters()).device</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>        </div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>        <span class="comment"># 深拷贝模型并确保在正确设备上</span></div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>        new_model = copy.deepcopy(model).to(original_device)</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>        </div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>        <span class="comment"># 找到目标层</span></div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>        target_layer = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a0ce571671e26b5731993f032beb11b2e">_find_layer</a>(new_model, layer_name)</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>        <span class="keywordflow">if</span> target_layer <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>            logger.warning(f<span class="stringliteral">&quot;未找到层: {layer_name}&quot;</span>)</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>            <span class="keywordflow">return</span> model, 0</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>            </div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>        <span class="comment"># 根据层类型执行分裂</span></div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>        <span class="keywordflow">if</span> isinstance(target_layer, nn.Linear):</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>            <span class="keywordflow">return</span> self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab40735b7a8cee3a01fe8b61b028c753d">_divide_linear_layer</a>(new_model, layer_name, target_layer, </div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>                                           division_strategy, target_expansion)</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>        <span class="keywordflow">elif</span> isinstance(target_layer, nn.Conv2d):</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>            <span class="keywordflow">return</span> self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab877e0ea873ace2e0dc4d9b0e63cc39e">_divide_conv_layer</a>(new_model, layer_name, target_layer,</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>                                         division_strategy, target_expansion)</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>            logger.warning(f<span class="stringliteral">&quot;不支持的层类型: {type(target_layer)}&quot;</span>)</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>            <span class="keywordflow">return</span> model, 0</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    </div>
</div>
<div class="foldopen" id="foldopen00130" data-start="" data-end="">
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a0ce571671e26b5731993f032beb11b2e">  130</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a0ce571671e26b5731993f032beb11b2e">_find_layer</a>(self, model: nn.Module, layer_name: str) -&gt; Optional[nn.Module]:</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>        <span class="stringliteral">&quot;&quot;&quot;查找指定层&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>        <span class="keywordflow">for</span> name, module <span class="keywordflow">in</span> model.named_modules():</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>            <span class="keywordflow">if</span> name == layer_name:</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>                <span class="keywordflow">return</span> module</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>        <span class="keywordflow">return</span> <span class="keywordtype">None</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>    </div>
</div>
<div class="foldopen" id="foldopen00137" data-start="" data-end="">
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab40735b7a8cee3a01fe8b61b028c753d">  137</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab40735b7a8cee3a01fe8b61b028c753d">_divide_linear_layer</a>(self, model: nn.Module, layer_name: str, layer: nn.Linear,</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>                           division_strategy: str, target_expansion: float) -&gt; Tuple[nn.Module, int]:</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>        <span class="stringliteral">&quot;&quot;&quot;分裂全连接层&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>        </div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        original_out_features = layer.out_features</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>        expansion_size = max(1, int(original_out_features * target_expansion))</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>        new_out_features = original_out_features + expansion_size</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>        </div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>        <span class="comment"># 获取原始设备和数据类型</span></div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>        device = layer.weight.device</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>        dtype = layer.weight.dtype</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>        </div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>        <span class="comment"># 创建新的权重和偏置张量（确保在正确的设备上）</span></div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>        new_weight = torch.zeros(new_out_features, layer.in_features, dtype=dtype, device=device)</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>        new_bias = torch.zeros(new_out_features, dtype=dtype, device=device) <span class="keywordflow">if</span> layer.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> <span class="keywordtype">None</span></div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>        </div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>        <span class="comment"># 复制原始权重</span></div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>        new_weight[:original_out_features] = layer.weight.data</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>        <span class="keywordflow">if</span> new_bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>            new_bias[:original_out_features] = layer.bias.data</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>            </div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>        <span class="comment"># 选择分裂策略</span></div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>        strategy_func = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a56710ecab3865a6d35b0f98db9c897ae">_get_division_strategy</a>(division_strategy)</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>        </div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>        <span class="comment"># 执行神经元分裂</span></div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>        neurons_to_divide = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a5dad69cdb25b82f3720d2e86206929d5">_select_neurons_for_division</a>(layer, expansion_size)</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>        </div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>        <span class="keywordflow">for</span> i, neuron_idx <span class="keywordflow">in</span> enumerate(neurons_to_divide):</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>            <span class="keywordflow">if</span> i &gt;= expansion_size:</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>                <span class="keywordflow">break</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>                </div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>            original_weights = layer.weight.data[neuron_idx]</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>            original_bias = layer.bias.data[neuron_idx] <span class="keywordflow">if</span> layer.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> torch.tensor(0.0, device=device)</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>            </div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>            <span class="comment"># 执行分裂</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>            <span class="keywordflow">if</span> division_strategy == <span class="stringliteral">&#39;symmetric&#39;</span>:</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>                new_weights, _ = strategy_func(original_weights)</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>                new_weight[original_out_features + i] = new_weights</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>            <span class="keywordflow">elif</span> division_strategy == <span class="stringliteral">&#39;asymmetric&#39;</span>:</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>                _, specialized_weights = strategy_func(original_weights)</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>                new_weight[original_out_features + i] = specialized_weights</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>            <span class="keywordflow">else</span>:  <span class="comment"># adaptive</span></div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>                new_weights, _ = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a6743d9621dddc203cac9c67cadee4608">_adaptive_division</a>(original_weights, layer_name, neuron_idx)</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>                new_weight[original_out_features + i] = new_weights</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>                </div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>            <span class="comment"># 设置偏置</span></div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>            <span class="keywordflow">if</span> new_bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>                new_bias[original_out_features + i] = original_bias * 0.9</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        </div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        <span class="comment"># 更新层参数（确保在正确设备上）</span></div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>        layer.out_features = new_out_features</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>        <span class="comment"># 确保参数在正确设备上并且requires_grad=True</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>        new_weight_param = nn.Parameter(new_weight.to(device).detach().requires_grad_(<span class="keyword">True</span>))</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>        layer.weight = new_weight_param</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>        <span class="keywordflow">if</span> layer.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>            new_bias_param = nn.Parameter(new_bias.to(device).detach().requires_grad_(<span class="keyword">True</span>))</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>            layer.bias = new_bias_param</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>            </div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>        <span class="comment"># 更新下一层的输入维度（如果存在且不是最后一层）</span></div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#aada437ba0291690b6a33ee2e02d1ffd1">_is_final_layer</a>(model, layer_name):</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>            self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#adbaf5a7533be542f987b045d4de10808">_update_next_layer_input</a>(model, layer_name, expansion_size)</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>        </div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        <span class="comment"># 记录分裂历史</span></div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>        self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a>[layer_name].append({</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>            <span class="stringliteral">&#39;expansion_size&#39;</span>: expansion_size,</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>            <span class="stringliteral">&#39;strategy&#39;</span>: division_strategy,</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>            <span class="stringliteral">&#39;neurons_divided&#39;</span>: neurons_to_divide</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>        })</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>        </div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>        logger.info(f<span class="stringliteral">&quot;Linear层分裂完成: {layer_name}, 新增神经元: {expansion_size}&quot;</span>)</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>        <span class="keywordflow">return</span> model, expansion_size * (layer.in_features + 1)</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>    </div>
</div>
<div class="foldopen" id="foldopen00209" data-start="" data-end="">
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab877e0ea873ace2e0dc4d9b0e63cc39e">  209</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab877e0ea873ace2e0dc4d9b0e63cc39e">_divide_conv_layer</a>(self, model: nn.Module, layer_name: str, layer: nn.Conv2d,</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>                          division_strategy: str, target_expansion: float) -&gt; Tuple[nn.Module, int]:</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>        <span class="stringliteral">&quot;&quot;&quot;分裂卷积层&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        </div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>        original_out_channels = layer.out_channels</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>        expansion_size = max(1, int(original_out_channels * target_expansion))</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>        new_out_channels = original_out_channels + expansion_size</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>        </div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>        <span class="comment"># 获取原始设备</span></div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>        device = layer.weight.device</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>        </div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <span class="comment"># 创建新的卷积层</span></div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>        new_conv = nn.Conv2d(</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>            layer.in_channels,</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>            new_out_channels,</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>            layer.kernel_size,</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>            layer.stride,</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>            layer.padding,</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>            layer.dilation,</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>            layer.groups,</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>            layer.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>,</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>            layer.padding_mode</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>        ).to(device)  <span class="comment"># 确保在正确的设备上</span></div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>        </div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>        <span class="comment"># 复制原始权重</span></div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>        <span class="keyword">with</span> torch.no_grad():</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>            new_conv.weight.data[:original_out_channels] = layer.weight.data</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>            <span class="keywordflow">if</span> layer.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>                new_conv.bias.data[:original_out_channels] = layer.bias.data</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>        </div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>        <span class="comment"># 执行通道分裂</span></div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>        channels_to_divide = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#af43b8135ca9200dcc8b41b98974a5240">_select_channels_for_division</a>(layer, expansion_size)</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>        strategy_func = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a56710ecab3865a6d35b0f98db9c897ae">_get_division_strategy</a>(division_strategy)</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>        </div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        <span class="keywordflow">for</span> i, channel_idx <span class="keywordflow">in</span> enumerate(channels_to_divide):</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>            <span class="keywordflow">if</span> i &gt;= expansion_size:</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>                <span class="keywordflow">break</span></div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>                </div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>            original_kernel = layer.weight.data[channel_idx]</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>            original_bias = layer.bias.data[channel_idx] <span class="keywordflow">if</span> layer.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> torch.tensor(0.0, device=device)</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>            </div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>            <span class="comment"># 分裂卷积核</span></div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>            <span class="keywordflow">if</span> division_strategy == <span class="stringliteral">&#39;symmetric&#39;</span>:</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>                new_kernel, _ = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ae63351e423eb10a6d373d9db54d5fb45">_divide_conv_kernel</a>(original_kernel, <span class="stringliteral">&#39;symmetric&#39;</span>)</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>            <span class="keywordflow">elif</span> division_strategy == <span class="stringliteral">&#39;asymmetric&#39;</span>:</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>                _, new_kernel = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ae63351e423eb10a6d373d9db54d5fb45">_divide_conv_kernel</a>(original_kernel, <span class="stringliteral">&#39;asymmetric&#39;</span>)</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>            <span class="keywordflow">else</span>:  <span class="comment"># adaptive</span></div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>                new_kernel, _ = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a71eef0078695d9b11f9facec133ea464">_adaptive_conv_division</a>(original_kernel, layer_name, channel_idx)</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>                </div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>            new_conv.weight.data[original_out_channels + i] = new_kernel</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>            <span class="keywordflow">if</span> new_conv.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>                new_conv.bias.data[original_out_channels + i] = original_bias * 0.9</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>        </div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>        <span class="comment"># 替换层</span></div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>        self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ada7200ad44b7657949a35870c7bf9037">_replace_layer</a>(model, layer_name, new_conv)</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>        </div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>        <span class="comment"># 更新下一层的输入通道数（如果不是最后一层）</span></div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#aada437ba0291690b6a33ee2e02d1ffd1">_is_final_layer</a>(model, layer_name):</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>            self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a46c95e7a18a0096e16e9b3425b4fcd27">_update_next_conv_layer_input</a>(model, layer_name, expansion_size)</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>        </div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>        <span class="comment"># 记录分裂历史</span></div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>        self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a>[layer_name].append({</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>            <span class="stringliteral">&#39;expansion_size&#39;</span>: expansion_size,</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>            <span class="stringliteral">&#39;strategy&#39;</span>: division_strategy,</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>            <span class="stringliteral">&#39;channels_divided&#39;</span>: channels_to_divide</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>        })</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>        </div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>        param_increase = expansion_size * layer.in_channels * layer.kernel_size[0] * layer.kernel_size[1]</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>        logger.info(f<span class="stringliteral">&quot;Conv层分裂完成: {layer_name}, 新增通道: {expansion_size}&quot;</span>)</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>        <span class="keywordflow">return</span> model, param_increase</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>    </div>
</div>
<div class="foldopen" id="foldopen00280" data-start="" data-end="">
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a56710ecab3865a6d35b0f98db9c897ae">  280</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a56710ecab3865a6d35b0f98db9c897ae">_get_division_strategy</a>(self, strategy_name: str):</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>        <span class="stringliteral">&quot;&quot;&quot;获取分裂策略函数&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>        strategies = {</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>            <span class="stringliteral">&#39;symmetric&#39;</span>: NeuronDivisionStrategies.symmetric_division,</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>            <span class="stringliteral">&#39;asymmetric&#39;</span>: NeuronDivisionStrategies.asymmetric_division,</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>            <span class="stringliteral">&#39;functional&#39;</span>: NeuronDivisionStrategies.functional_division</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>        }</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>        <span class="keywordflow">return</span> strategies.get(strategy_name, NeuronDivisionStrategies.symmetric_division)</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>    </div>
</div>
<div class="foldopen" id="foldopen00289" data-start="" data-end="">
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a5dad69cdb25b82f3720d2e86206929d5">  289</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a5dad69cdb25b82f3720d2e86206929d5">_select_neurons_for_division</a>(self, layer: nn.Linear, num_divisions: int) -&gt; List[int]:</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>        <span class="stringliteral">&quot;&quot;&quot;选择要分裂的神经元&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>        weights = layer.weight.data</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>        </div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>        <span class="comment"># 计算每个神经元的重要性分数</span></div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>        importance_scores = []</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(weights.size(0)):</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>            neuron_weights = weights[i]</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>            </div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>            <span class="comment"># 综合多个指标</span></div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>            weight_variance = torch.var(neuron_weights).item()</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>            weight_norm = torch.norm(neuron_weights).item()</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>            weight_sparsity = (torch.abs(neuron_weights) &lt; 0.01).float().mean().item()</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>            </div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>            <span class="comment"># 高方差、适中范数、低稀疏性的神经元适合分裂</span></div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>            score = weight_variance * (1.0 - weight_sparsity) * min(weight_norm, 1.0)</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>            importance_scores.append((i, score))</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>        </div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>        <span class="comment"># 选择得分最高的神经元</span></div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>        importance_scores.sort(key=<span class="keyword">lambda</span> x: x[1], reverse=<span class="keyword">True</span>)</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>        <span class="keywordflow">return</span> [idx <span class="keywordflow">for</span> idx, _ <span class="keywordflow">in</span> importance_scores[:num_divisions]]</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>    </div>
</div>
<div class="foldopen" id="foldopen00311" data-start="" data-end="">
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#af43b8135ca9200dcc8b41b98974a5240">  311</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#af43b8135ca9200dcc8b41b98974a5240">_select_channels_for_division</a>(self, layer: nn.Conv2d, num_divisions: int) -&gt; List[int]:</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>        <span class="stringliteral">&quot;&quot;&quot;选择要分裂的卷积通道&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>        weights = layer.weight.data</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>        </div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>        importance_scores = []</div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(weights.size(0)):</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>            channel_weights = weights[i]</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>            </div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>            <span class="comment"># 计算通道重要性</span></div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>            weight_energy = torch.sum(channel_weights ** 2).item()</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>            weight_diversity = torch.std(channel_weights).item()</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>            </div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>            score = weight_energy * weight_diversity</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>            importance_scores.append((i, score))</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>        </div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>        importance_scores.sort(key=<span class="keyword">lambda</span> x: x[1], reverse=<span class="keyword">True</span>)</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>        <span class="keywordflow">return</span> [idx <span class="keywordflow">for</span> idx, _ <span class="keywordflow">in</span> importance_scores[:num_divisions]]</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>    </div>
</div>
<div class="foldopen" id="foldopen00329" data-start="" data-end="">
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a6743d9621dddc203cac9c67cadee4608">  329</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a6743d9621dddc203cac9c67cadee4608">_adaptive_division</a>(self, original_weights: torch.Tensor, layer_name: str, neuron_idx: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>        <span class="stringliteral">&quot;&quot;&quot;自适应分裂策略&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>        <span class="comment"># 根据历史表现选择最佳策略</span></div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>        history = self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a>.get(layer_name, [])</div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>        </div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>        <span class="keywordflow">if</span> len(history) &lt; 3:</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>            <span class="comment"># 初期使用对称分裂</span></div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>            <span class="keywordflow">return</span> NeuronDivisionStrategies.symmetric_division(original_weights)</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>            <span class="comment"># 基于历史表现选择策略</span></div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>            <span class="comment"># 这里简化为随机选择，实际应该基于性能反馈</span></div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span>            strategy = np.random.choice([<span class="stringliteral">&#39;symmetric&#39;</span>, <span class="stringliteral">&#39;asymmetric&#39;</span>, <span class="stringliteral">&#39;functional&#39;</span>])</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>            func = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a56710ecab3865a6d35b0f98db9c897ae">_get_division_strategy</a>(strategy)</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>            <span class="keywordflow">return</span> func(original_weights)</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>    </div>
</div>
<div class="foldopen" id="foldopen00344" data-start="" data-end="">
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a71eef0078695d9b11f9facec133ea464">  344</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a71eef0078695d9b11f9facec133ea464">_adaptive_conv_division</a>(self, original_kernel: torch.Tensor, layer_name: str, channel_idx: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>        <span class="stringliteral">&quot;&quot;&quot;自适应卷积分裂&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>        <span class="keywordflow">return</span> self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ae63351e423eb10a6d373d9db54d5fb45">_divide_conv_kernel</a>(original_kernel, <span class="stringliteral">&#39;symmetric&#39;</span>)</div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>    </div>
</div>
<div class="foldopen" id="foldopen00348" data-start="" data-end="">
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ae63351e423eb10a6d373d9db54d5fb45">  348</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ae63351e423eb10a6d373d9db54d5fb45">_divide_conv_kernel</a>(self, kernel: torch.Tensor, strategy: str) -&gt; Tuple[torch.Tensor, torch.Tensor]:</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>        <span class="stringliteral">&quot;&quot;&quot;分裂卷积核&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>        device = kernel.device</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>        dtype = kernel.dtype</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>        </div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>        <span class="keywordflow">if</span> strategy == <span class="stringliteral">&#39;symmetric&#39;</span>:</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>            noise = torch.normal(0, torch.std(kernel) * 0.1, size=kernel.shape, device=device, dtype=dtype)</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>            kernel1 = kernel + noise</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>            kernel2 = kernel - noise</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>            <span class="keywordflow">return</span> kernel1, kernel2</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>        <span class="keywordflow">elif</span> strategy == <span class="stringliteral">&#39;asymmetric&#39;</span>:</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>            <span class="comment"># 创建专门化的核</span></div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>            kernel1 = kernel * 1.1</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>            kernel2 = kernel * 0.5</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>            <span class="comment"># 在kernel2中增强边缘检测</span></div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>            <span class="keywordflow">if</span> kernel.size(-1) &gt;= 3 <span class="keywordflow">and</span> kernel.size(-2) &gt;= 3:</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>                edge_kernel = torch.tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], </div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>                                         dtype=dtype, device=device)</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>                kernel2[:, :, :3, :3] += edge_kernel.unsqueeze(0).unsqueeze(0) * 0.1</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>            <span class="keywordflow">return</span> kernel1, kernel2</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>            flattened = kernel.view(-1)</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>            result1, result2 = NeuronDivisionStrategies.symmetric_division(flattened)</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>            <span class="keywordflow">return</span> result1.view(kernel.shape), result2.view(kernel.shape)</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>    </div>
</div>
<div class="foldopen" id="foldopen00373" data-start="" data-end="">
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#adbaf5a7533be542f987b045d4de10808">  373</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#adbaf5a7533be542f987b045d4de10808">_update_next_layer_input</a>(self, model: nn.Module, current_layer_name: str, expansion_size: int):</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>        <span class="stringliteral">&quot;&quot;&quot;更新下一层的输入维度&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>        layer_names = [name <span class="keywordflow">for</span> name, _ <span class="keywordflow">in</span> model.named_modules()]</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>        </div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span>            current_idx = layer_names.index(current_layer_name)</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>            <span class="keywordflow">if</span> current_idx + 1 &lt; len(layer_names):</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>                next_layer_name = layer_names[current_idx + 1]</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>                next_layer = self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a0ce571671e26b5731993f032beb11b2e">_find_layer</a>(model, next_layer_name)</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>                </div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>                <span class="keywordflow">if</span> isinstance(next_layer, nn.Linear):</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>                    old_in_features = next_layer.in_features</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>                    new_in_features = old_in_features + expansion_size</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>                    </div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>                    <span class="comment"># 获取设备信息</span></div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>                    device = next_layer.weight.device</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>                    dtype = next_layer.weight.dtype</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>                    </div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>                    <span class="comment"># 创建新的权重矩阵</span></div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>                    new_weight = torch.zeros(next_layer.out_features, new_in_features, dtype=dtype, device=device)</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>                    new_weight[:, :old_in_features] = next_layer.weight.data</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>                    </div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>                    <span class="comment"># 初始化新的连接权重</span></div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>                    <span class="keyword">with</span> torch.no_grad():</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>                        nn.init.normal_(new_weight[:, old_in_features:], mean=0, std=0.01)</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>                    </div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>                    next_layer.in_features = new_in_features</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>                    next_layer.weight = nn.Parameter(new_weight)</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>                    </div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>                    logger.info(f<span class="stringliteral">&quot;更新下一层输入维度: {next_layer_name}, {old_in_features} -&gt; {new_in_features}&quot;</span>)</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>                    </div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>        <span class="keywordflow">except</span> (ValueError, IndexError):</div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>            logger.warning(f<span class="stringliteral">&quot;无法找到层 {current_layer_name} 的下一层&quot;</span>)</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>    </div>
</div>
<div class="foldopen" id="foldopen00407" data-start="" data-end="">
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a46c95e7a18a0096e16e9b3425b4fcd27">  407</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a46c95e7a18a0096e16e9b3425b4fcd27">_update_next_conv_layer_input</a>(self, model: nn.Module, current_layer_name: str, expansion_size: int):</div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>        <span class="stringliteral">&quot;&quot;&quot;更新下一个卷积层的输入通道数&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>        <span class="comment"># 寻找下一个线性层或卷积层</span></div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>        found_current = <span class="keyword">False</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>        </div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>        <span class="keywordflow">for</span> name, module <span class="keywordflow">in</span> model.named_modules():</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>            <span class="keywordflow">if</span> found_current <span class="keywordflow">and</span> isinstance(module, (nn.Linear, nn.Conv2d)):</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>                <span class="keywordflow">if</span> isinstance(module, nn.Conv2d):</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>                    <span class="comment"># 更新卷积层输入通道</span></div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>                    old_in_channels = module.in_channels</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>                    new_in_channels = old_in_channels + expansion_size</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>                    </div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>                    <span class="comment"># 获取设备信息</span></div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>                    device = module.weight.device</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>                    </div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>                    new_conv = nn.Conv2d(</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>                        new_in_channels,</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>                        module.out_channels,</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>                        module.kernel_size,</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>                        module.stride,</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>                        module.padding,</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>                        module.dilation,</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>                        module.groups,</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>                        module.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>,</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>                        module.padding_mode</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>                    ).to(device)  <span class="comment"># 确保在正确的设备上</span></div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>                    </div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>                    <span class="comment"># 复制权重并扩展</span></div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>                    <span class="keyword">with</span> torch.no_grad():</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>                        new_conv.weight.data[:, :old_in_channels] = module.weight.data</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>                        <span class="keywordflow">if</span> module.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>                            new_conv.bias.data = module.bias.data</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>                            </div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>                        <span class="comment"># 初始化新的输入通道</span></div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>                        nn.init.kaiming_normal_(new_conv.weight.data[:, old_in_channels:])</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>                    </div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>                    self.<a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ada7200ad44b7657949a35870c7bf9037">_replace_layer</a>(model, name, new_conv)</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>                    logger.info(f<span class="stringliteral">&quot;更新Conv层输入通道: {name}, {old_in_channels} -&gt; {new_in_channels}&quot;</span>)</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>                <span class="keywordflow">break</span></div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>                </div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>            <span class="keywordflow">if</span> name == current_layer_name:</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>                found_current = <span class="keyword">True</span></div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>    </div>
</div>
<div class="foldopen" id="foldopen00450" data-start="" data-end="">
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#aada437ba0291690b6a33ee2e02d1ffd1">  450</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#aada437ba0291690b6a33ee2e02d1ffd1">_is_final_layer</a>(self, model: nn.Module, layer_name: str) -&gt; bool:</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>        <span class="stringliteral">&quot;&quot;&quot;检查是否为最后一层&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>        layer_names = [name <span class="keywordflow">for</span> name, module <span class="keywordflow">in</span> model.named_modules() </div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>                      <span class="keywordflow">if</span> isinstance(module, (nn.Linear, nn.Conv2d)) <span class="keywordflow">and</span> name != <span class="stringliteral">&#39;&#39;</span>]</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>        </div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> layer_names:</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>            <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>            </div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>        <span class="comment"># 特殊处理：如果是分类器的输出层，则认为是最后一层</span></div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>        <span class="keywordflow">if</span> <span class="stringliteral">&#39;classifier&#39;</span> <span class="keywordflow">in</span> layer_name:</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>            <span class="comment"># 检查是否是分类器中的最后一个Linear层</span></div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>            parts = layer_name.split(<span class="stringliteral">&#39;.&#39;</span>)</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>            <span class="keywordflow">if</span> len(parts) &gt;= 2:</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>                <span class="keywordflow">try</span>:</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>                    layer_idx = int(parts[-1])</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>                    <span class="comment"># 对于我们的分类器结构，第6层（索引6）是最后的Linear层</span></div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>                    <span class="keywordflow">if</span> layer_idx == 6:</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>                        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>                <span class="keywordflow">except</span> ValueError:</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>                    <span class="keywordflow">pass</span></div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>            </div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>        <span class="comment"># 找到当前层在列表中的位置</span></div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>            current_idx = layer_names.index(layer_name)</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>            <span class="keywordflow">return</span> current_idx == len(layer_names) - 1</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>        <span class="keywordflow">except</span> ValueError:</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>            <span class="keywordflow">return</span> <span class="keyword">True</span>  <span class="comment"># 如果找不到，假设是最后一层</span></div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>    </div>
</div>
<div class="foldopen" id="foldopen00478" data-start="" data-end="">
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ada7200ad44b7657949a35870c7bf9037">  478</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ada7200ad44b7657949a35870c7bf9037">_replace_layer</a>(self, model: nn.Module, layer_name: str, new_layer: nn.Module):</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>        <span class="stringliteral">&quot;&quot;&quot;替换模型中的层&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>        parts = layer_name.split(<span class="stringliteral">&#39;.&#39;</span>)</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>        </div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>        <span class="keywordflow">if</span> len(parts) == 1:</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>            setattr(model, layer_name, new_layer)</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>            parent = model</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>            <span class="keywordflow">for</span> part <span class="keywordflow">in</span> parts[:-1]:</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>                parent = getattr(parent, part)</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>            setattr(parent, parts[-1], new_layer)</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>    </div>
</div>
<div class="foldopen" id="foldopen00490" data-start="" data-end="">
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno"><a class="line" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a751981827f0b4170186a270e7c19d0d1">  490</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a751981827f0b4170186a270e7c19d0d1">get_division_statistics</a>(self) -&gt; Dict[str, Any]:</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>        <span class="stringliteral">&quot;&quot;&quot;获取分裂统计信息&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>        total_divisions = sum(len(history) <span class="keywordflow">for</span> history <span class="keywordflow">in</span> self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a>.values())</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>        </div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>        strategy_counts = defaultdict(int)</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>        total_expansions = 0</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>        </div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>        <span class="keywordflow">for</span> layer_name, history <span class="keywordflow">in</span> self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a>.items():</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>            <span class="keywordflow">for</span> event <span class="keywordflow">in</span> history:</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>                strategy_counts[event[<span class="stringliteral">&#39;strategy&#39;</span>]] += 1</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>                total_expansions += event[<span class="stringliteral">&#39;expansion_size&#39;</span>]</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>        </div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>        <span class="keywordflow">return</span> {</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>            <span class="stringliteral">&#39;total_division_events&#39;</span>: total_divisions,</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>            <span class="stringliteral">&#39;total_neurons_added&#39;</span>: total_expansions,</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>            <span class="stringliteral">&#39;strategy_usage&#39;</span>: dict(strategy_counts),</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>            <span class="stringliteral">&#39;layers_modified&#39;</span>: list(self.<a class="code hl_variable" href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">division_history</a>.keys())</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>        }</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span> </div>
</div>
</div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision</a></div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00095">dnm_neuron_division.py:95</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a0ce571671e26b5731993f032beb11b2e"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a0ce571671e26b5731993f032beb11b2e">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._find_layer</a></div><div class="ttdeci">Optional[nn.Module] _find_layer(self, nn.Module model, str layer_name)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00130">dnm_neuron_division.py:130</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a27749982bf58772dd0b72c58fac2b3c0"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a27749982bf58772dd0b72c58fac2b3c0">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision.division_history</a></div><div class="ttdeci">division_history</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00099">dnm_neuron_division.py:99</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a46c95e7a18a0096e16e9b3425b4fcd27"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a46c95e7a18a0096e16e9b3425b4fcd27">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._update_next_conv_layer_input</a></div><div class="ttdeci">_update_next_conv_layer_input(self, nn.Module model, str current_layer_name, int expansion_size)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00407">dnm_neuron_division.py:407</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a56710ecab3865a6d35b0f98db9c897ae"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a56710ecab3865a6d35b0f98db9c897ae">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._get_division_strategy</a></div><div class="ttdeci">_get_division_strategy(self, str strategy_name)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00280">dnm_neuron_division.py:280</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a5dad69cdb25b82f3720d2e86206929d5"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a5dad69cdb25b82f3720d2e86206929d5">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._select_neurons_for_division</a></div><div class="ttdeci">List[int] _select_neurons_for_division(self, nn.Linear layer, int num_divisions)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00289">dnm_neuron_division.py:289</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a6743d9621dddc203cac9c67cadee4608"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a6743d9621dddc203cac9c67cadee4608">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._adaptive_division</a></div><div class="ttdeci">Tuple[torch.Tensor, torch.Tensor] _adaptive_division(self, torch.Tensor original_weights, str layer_name, int neuron_idx)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00329">dnm_neuron_division.py:329</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a71eef0078695d9b11f9facec133ea464"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a71eef0078695d9b11f9facec133ea464">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._adaptive_conv_division</a></div><div class="ttdeci">Tuple[torch.Tensor, torch.Tensor] _adaptive_conv_division(self, torch.Tensor original_kernel, str layer_name, int channel_idx)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00344">dnm_neuron_division.py:344</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a751981827f0b4170186a270e7c19d0d1"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a751981827f0b4170186a270e7c19d0d1">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision.get_division_statistics</a></div><div class="ttdeci">Dict[str, Any] get_division_statistics(self)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00490">dnm_neuron_division.py:490</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a861deca5cdda66da984f8b7704f455da"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a861deca5cdda66da984f8b7704f455da">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision.performance_tracker</a></div><div class="ttdeci">performance_tracker</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00100">dnm_neuron_division.py:100</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_a97067cf5d162473cde419ba77ea38d52"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#a97067cf5d162473cde419ba77ea38d52">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision.__init__</a></div><div class="ttdeci">__init__(self)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00098">dnm_neuron_division.py:98</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_aada437ba0291690b6a33ee2e02d1ffd1"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#aada437ba0291690b6a33ee2e02d1ffd1">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._is_final_layer</a></div><div class="ttdeci">bool _is_final_layer(self, nn.Module model, str layer_name)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00450">dnm_neuron_division.py:450</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_ab40735b7a8cee3a01fe8b61b028c753d"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab40735b7a8cee3a01fe8b61b028c753d">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._divide_linear_layer</a></div><div class="ttdeci">Tuple[nn.Module, int] _divide_linear_layer(self, nn.Module model, str layer_name, nn.Linear layer, str division_strategy, float target_expansion)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00137">dnm_neuron_division.py:138</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_ab877e0ea873ace2e0dc4d9b0e63cc39e"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ab877e0ea873ace2e0dc4d9b0e63cc39e">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._divide_conv_layer</a></div><div class="ttdeci">Tuple[nn.Module, int] _divide_conv_layer(self, nn.Module model, str layer_name, nn.Conv2d layer, str division_strategy, float target_expansion)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00209">dnm_neuron_division.py:210</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_abb34f44e89dd00f1ad80f278a6b5e4ba"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#abb34f44e89dd00f1ad80f278a6b5e4ba">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision.execute_division</a></div><div class="ttdeci">Tuple[nn.Module, int] execute_division(self, nn.Module model, str layer_name, str division_strategy='adaptive', float target_expansion=0.2)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00102">dnm_neuron_division.py:104</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_ada7200ad44b7657949a35870c7bf9037"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ada7200ad44b7657949a35870c7bf9037">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._replace_layer</a></div><div class="ttdeci">_replace_layer(self, nn.Module model, str layer_name, nn.Module new_layer)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00478">dnm_neuron_division.py:478</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_adbaf5a7533be542f987b045d4de10808"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#adbaf5a7533be542f987b045d4de10808">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._update_next_layer_input</a></div><div class="ttdeci">_update_next_layer_input(self, nn.Module model, str current_layer_name, int expansion_size)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00373">dnm_neuron_division.py:373</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_ae63351e423eb10a6d373d9db54d5fb45"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#ae63351e423eb10a6d373d9db54d5fb45">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._divide_conv_kernel</a></div><div class="ttdeci">Tuple[torch.Tensor, torch.Tensor] _divide_conv_kernel(self, torch.Tensor kernel, str strategy)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00348">dnm_neuron_division.py:348</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision_html_af43b8135ca9200dcc8b41b98974a5240"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1AdaptiveNeuronDivision.html#af43b8135ca9200dcc8b41b98974a5240">neuroexapt.core.dnm_neuron_division.AdaptiveNeuronDivision._select_channels_for_division</a></div><div class="ttdeci">List[int] _select_channels_for_division(self, nn.Conv2d layer, int num_divisions)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00311">dnm_neuron_division.py:311</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies_html"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html">neuroexapt.core.dnm_neuron_division.NeuronDivisionStrategies</a></div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00033">dnm_neuron_division.py:33</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies_html_a0ecdf68b5438c003aeac21f35817a597"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#a0ecdf68b5438c003aeac21f35817a597">neuroexapt.core.dnm_neuron_division.NeuronDivisionStrategies.functional_division</a></div><div class="ttdeci">Tuple[torch.Tensor, torch.Tensor] functional_division(torch.Tensor original_weights, Optional[torch.Tensor] activation_pattern=None)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00069">dnm_neuron_division.py:69</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies_html_a67f8f3a023f7b536b38e57d19029895c"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#a67f8f3a023f7b536b38e57d19029895c">neuroexapt.core.dnm_neuron_division.NeuronDivisionStrategies.symmetric_division</a></div><div class="ttdeci">Tuple[torch.Tensor, torch.Tensor] symmetric_division(torch.Tensor original_weights, float division_ratio=0.5)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00037">dnm_neuron_division.py:37</a></div></div>
<div class="ttc" id="aclassneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies_html_abd8c770a9890fc69efe6c5c397331c12"><div class="ttname"><a href="classneuroexapt_1_1core_1_1dnm__neuron__division_1_1NeuronDivisionStrategies.html#abd8c770a9890fc69efe6c5c397331c12">neuroexapt.core.dnm_neuron_division.NeuronDivisionStrategies.asymmetric_division</a></div><div class="ttdeci">Tuple[torch.Tensor, torch.Tensor] asymmetric_division(torch.Tensor original_weights, float specialization_factor=0.3)</div><div class="ttdef"><b>Definition</b> <a href="dnm__neuron__division_8py_source.html#l00052">dnm_neuron_division.py:52</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- do not remove this div, it is closed by doxygen! -->
</div>
<!-- Custom Footer -->
<div style="background: #f8f9fa; border-top: 1px solid #e9ecef; margin-top: 50px; padding: 30px 0; text-align: center;">
    <div style="max-width: 1200px; margin: 0 auto; padding: 0 20px;">
        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 30px; margin-bottom: 20px;">
            <!-- Project Info -->
            <div>
                <h4 style="color: #495057; margin-bottom: 15px;">🧠 NeuroExapt</h4>
                <p style="color: #6c757d; margin: 0; font-size: 0.9em;">
                    Advanced Neural Architecture Search and Dynamic Morphogenesis Framework for next-generation AI research.
                </p>
            </div>
            <!-- Quick Links -->
            <div>
                <h4 style="color: #495057; margin-bottom: 15px;">📚 Quick Links</h4>
                <div style="text-align: left;">
                    <a href="index.html" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">🏠 Home</a>
                    <a href="modules.html" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">📦 Modules</a>
                    <a href="examples.html" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">💡 Examples</a>
                    <a href="files.html" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">📁 Files</a>
                </div>
            </div>
            <!-- Resources -->
            <div>
                <h4 style="color: #495057; margin-bottom: 15px;">🔗 Resources</h4>
                <div style="text-align: left;">
                    <a href="https://github.com/your-username/neuroexapt" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">💻 GitHub Repository</a>
                    <a href="https://github.com/your-username/neuroexapt/issues" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">🐛 Issue Tracker</a>
                    <a href="https://github.com/your-username/neuroexapt/wiki" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">📖 Wiki</a>
                    <a href="https://github.com/your-username/neuroexapt/releases" style="display: block; color: #667eea; text-decoration: none; margin: 5px 0;">🚀 Releases</a>
                </div>
            </div>
        </div>
        <hr style="border: 0; height: 1px; background: #e9ecef; margin: 20px 0;">
        <div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 15px;">
            <div style="color: #6c757d; font-size: 0.9em;">
                © 2024 NeuroExapt Project. Generated with 
                <a href="https://www.doxygen.nl/index.html" style="color: #667eea; text-decoration: none;">Doxygen 1.9.8</a>
            </div>
            <div style="display: flex; gap: 15px; align-items: center;">
                <span style="font-size: 0.9em; color: #6c757d;">Built with ❤️ for AI Research</span>
                <div style="display: flex; gap: 10px;">
                    <span style="background: #28a745; color: white; padding: 2px 8px; border-radius: 12px; font-size: 0.8em;">🟢 Active</span>
                    <span style="background: #17a2b8; color: white; padding: 2px 8px; border-radius: 12px; font-size: 0.8em;">v3.0</span>
                </div>
            </div>
        </div>
        <!-- Technology Stack -->
        <div style="margin-top: 20px; padding-top: 15px; border-top: 1px solid #e9ecef;">
            <div style="font-size: 0.8em; color: #868e96; text-align: center;">
                <strong>Built with:</strong>
                <span style="margin: 0 5px;">🐍 Python</span>
                <span style="margin: 0 5px;">🔥 PyTorch</span>
                <span style="margin: 0 5px;">⚡ CUDA</span>
                <span style="margin: 0 5px;">🧮 NumPy</span>
                <span style="margin: 0 5px;">📊 Matplotlib</span>
                <span style="margin: 0 5px;">🚀 Triton</span>
            </div>
        </div>
    </div>
</div>
<!-- Back to top button -->
<div id="back-to-top" style="position: fixed; bottom: 20px; right: 20px; display: none; z-index: 1000;">
    <button onclick="window.scrollTo({top: 0, behavior: 'smooth'})" 
            style="background: #667eea; color: white; border: none; padding: 10px 15px; border-radius: 50%; cursor: pointer; box-shadow: 0 2px 10px rgba(0,0,0,0.2); font-size: 16px;">
        ⬆️
    </button>
</div>
<script>
// Back to top button functionality
window.addEventListener('scroll', function() {
    const backToTop = document.getElementById('back-to-top');
    if (window.pageYOffset > 300) {
        backToTop.style.display = 'block';
    } else {
        backToTop.style.display = 'none';
    }
});
// Enhanced search functionality
document.addEventListener('DOMContentLoaded', function() {
    // Add search enhancement if search box exists
    const searchBox = document.getElementById('MSearchField');
    if (searchBox) {
        searchBox.placeholder = 'Search documentation... 🔍';
        searchBox.style.borderRadius = '20px';
        searchBox.style.padding = '8px 15px';
    }
    // Add copy code button to code blocks
    const codeBlocks = document.querySelectorAll('.fragment');
    codeBlocks.forEach(function(block) {
        const copyBtn = document.createElement('button');
        copyBtn.innerHTML = '📋';
        copyBtn.title = 'Copy code';
        copyBtn.style.cssText = 'position: absolute; top: 10px; right: 10px; background: #667eea; color: white; border: none; padding: 5px; border-radius: 3px; cursor: pointer; font-size: 12px;';
        block.style.position = 'relative';
        block.appendChild(copyBtn);
        copyBtn.addEventListener('click', function() {
            const text = block.textContent;
            navigator.clipboard.writeText(text).then(function() {
                copyBtn.innerHTML = '✅';
                setTimeout(function() {
                    copyBtn.innerHTML = '📋';
                }, 2000);
            });
        });
    });
});
// Dark mode toggle (optional)
function toggleDarkMode() {
    document.body.classList.toggle('dark-mode');
    localStorage.setItem('darkMode', document.body.classList.contains('dark-mode'));
}
// Load saved dark mode preference
if (localStorage.getItem('darkMode') === 'true') {
    document.body.classList.add('dark-mode');
}
</script>
</body>
</html>