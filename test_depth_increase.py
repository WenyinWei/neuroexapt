"""
æµ‹è¯•æ·±åº¦å¢åŠ æ“ä½œ - éªŒè¯æ˜¯å¦æœ‰å¼ é‡å½¢çŠ¶ä¸åŒ¹é…å’Œå†…å­˜æ³„éœ²é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import sys
import os
import gc
import psutil
import time

# Add the current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from neuroexapt.core.depth_expansion_operators import DepthExpansionOperator, get_depth_expansion_operators

class TestCNN(nn.Module):
    """ç”¨äºæµ‹è¯•æ·±åº¦å¢åŠ çš„ç®€å•CNN"""
    def __init__(self):
        super(TestCNN, self).__init__()
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            # Block 2
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            # Block 3
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(64, 10)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

def load_test_data(batch_size=32):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    
    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    
    # åªä½¿ç”¨å‰500ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    indices = list(range(500))
    subset = torch.utils.data.Subset(dataset, indices)
    
    dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)
    return dataloader

def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    return memory_info.rss / 1024 / 1024  # MB

def evaluate_model(model, dataloader, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    correct = 0
    total = 0
    total_loss = 0
    criterion = nn.CrossEntropyLoss()
    
    with torch.no_grad():
        for data, targets in dataloader:
            data, targets = data.to(device), targets.to(device)
            try:
                outputs = model(data)
                loss = criterion(outputs, targets)
                total_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()
            except Exception as e:
                print(f"âŒ Forward pass failed: {e}")
                return None, None
    
    accuracy = 100.0 * correct / total if total > 0 else 0.0
    avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0.0
    
    model.train()
    return accuracy, avg_loss

def test_tensor_shape_compatibility(model, dataloader, device):
    """æµ‹è¯•å¼ é‡å½¢çŠ¶å…¼å®¹æ€§"""
    print("\nğŸ” Testing tensor shape compatibility...")
    
    model.eval()
    with torch.no_grad():
        for i, (data, targets) in enumerate(dataloader):
            data, targets = data.to(device), targets.to(device)
            
            try:
                outputs = model(data)
                print(f"   Batch {i+1}: Input {tuple(data.shape)} â†’ Output {tuple(outputs.shape)} âœ…")
                
                if i >= 5:  # æµ‹è¯•å‰5ä¸ªbatch
                    break
                    
            except Exception as e:
                print(f"   Batch {i+1}: FAILED - {e} âŒ")
                return False
    
    print("   âœ… All tensor shapes compatible!")
    return True

def test_memory_leaks(model, dataloader, device, num_iterations=10):
    """æµ‹è¯•å†…å­˜æ³„éœ²"""
    print(f"\nğŸ§  Testing memory leaks ({num_iterations} iterations)...")
    
    initial_memory = get_memory_usage()
    print(f"   Initial memory: {initial_memory:.1f} MB")
    
    memory_readings = [initial_memory]
    
    model.train()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    for iteration in range(num_iterations):
        for batch_idx, (data, targets) in enumerate(dataloader):
            data, targets = data.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            if batch_idx >= 3:  # åªåšå‡ ä¸ªbatch
                break
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        current_memory = get_memory_usage()
        memory_readings.append(current_memory)
        print(f"   Iteration {iteration+1}: {current_memory:.1f} MB")
    
    final_memory = get_memory_usage()
    memory_increase = final_memory - initial_memory
    
    print(f"   Final memory: {final_memory:.1f} MB")
    print(f"   Memory increase: {memory_increase:.1f} MB")
    
    # åˆ¤æ–­æ˜¯å¦æœ‰ä¸¥é‡çš„å†…å­˜æ³„éœ²
    if memory_increase > 100:  # è¶…è¿‡100MBè®¤ä¸ºæœ‰é—®é¢˜
        print(f"   âš ï¸ Potential memory leak detected!")
        return False
    else:
        print(f"   âœ… Memory usage acceptable!")
        return True

def test_depth_increase():
    """æµ‹è¯•æ·±åº¦å¢åŠ æ“ä½œ"""
    print("=" * 60)
    print("ğŸ§ª æ·±åº¦å¢åŠ æµ‹è¯•")
    print("=" * 60)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    
    # è®°å½•åˆå§‹å†…å­˜
    initial_memory = get_memory_usage()
    print(f"Initial system memory: {initial_memory:.1f} MB")
    
    # åˆ›å»ºæ¨¡å‹
    model = TestCNN().to(device)
    dataloader = load_test_data(batch_size=32)
    
    # åˆå§‹æ¶æ„åˆ†æ
    initial_params = sum(p.numel() for p in model.parameters())
    print(f"\nğŸ“Š Initial Architecture:")
    print(f"   Parameters: {initial_params:,}")
    
    # æ£€æŸ¥å±‚æ•°çš„æ›´å®‰å…¨æ–¹å¼
    features_layers = len(list(model.features.children())) if isinstance(model.features, nn.Sequential) else "N/A"
    classifier_layers = len(list(model.classifier.children())) if isinstance(model.classifier, nn.Sequential) else "N/A"
    
    print(f"   Layers in features: {features_layers}")
    print(f"   Layers in classifier: {classifier_layers}")
    
    # æµ‹è¯•åˆå§‹å¼ é‡å½¢çŠ¶å…¼å®¹æ€§
    initial_compatibility = test_tensor_shape_compatibility(model, dataloader, device)
    if not initial_compatibility:
        print("âŒ Initial model has tensor shape issues!")
        return
    
    # è¯„ä¼°åˆå§‹æ€§èƒ½
    initial_accuracy, initial_loss = evaluate_model(model, dataloader, device)
    if initial_accuracy is None:
        print("âŒ Initial model evaluation failed!")
        return
    
    print(f"\nğŸ“Š Initial Performance:")
    print(f"   Accuracy: {initial_accuracy:.2f}%")
    print(f"   Loss: {initial_loss:.4f}")
    
    # åˆ›å»ºæ·±åº¦æ‰©å±•æ“ä½œå™¨
    depth_expander = DepthExpansionOperator(min_accuracy_for_pruning=0.9)  # è®¾ç½®é«˜é˜ˆå€¼ç¡®ä¿è§¦å‘
    
    # æ¨¡æ‹Ÿä½å‡†ç¡®ç‡çŠ¶æ€æ¥è§¦å‘æ·±åº¦æ‰©å±•
    test_state = {
        'current_performance': initial_accuracy / 100.0,
        'val_accuracy': initial_accuracy,
        'epoch': 5
    }
    
    print(f"\nğŸ—ï¸ Applying depth expansion...")
    print(f"   Simulated accuracy: {initial_accuracy:.2f}%")
    
    # åº”ç”¨æ·±åº¦æ‰©å±•
    evolved_model = depth_expander(model, test_state)
    
    if evolved_model is not None:
        print("âœ… Depth expansion successful!")
        
        # æ£€æŸ¥æ‰©å±•åçš„æ¶æ„
        expanded_params = sum(p.numel() for p in evolved_model.parameters())
        print(f"\nğŸ“Š Expanded Architecture:")
        print(f"   Parameters: {initial_params:,} â†’ {expanded_params:,}")
        print(f"   Increase: {expanded_params - initial_params:,} (+{((expanded_params - initial_params) / initial_params * 100):.1f}%)")
        
        # æ£€æŸ¥æ‰©å±•åçš„å±‚æ•°
        evolved_features_layers = len(list(evolved_model.features.children())) if isinstance(evolved_model.features, nn.Sequential) else "N/A"
        evolved_classifier_layers = len(list(evolved_model.classifier.children())) if isinstance(evolved_model.classifier, nn.Sequential) else "N/A"
        
        print(f"   Features layers: {features_layers} â†’ {evolved_features_layers}")
        print(f"   Classifier layers: {classifier_layers} â†’ {evolved_classifier_layers}")
        
        # æµ‹è¯•å¼ é‡å½¢çŠ¶å…¼å®¹æ€§
        post_expansion_compatibility = test_tensor_shape_compatibility(evolved_model, dataloader, device)
        
        if post_expansion_compatibility:
            print("âœ… Post-expansion tensor shapes compatible!")
            
            # ç«‹å³è¯„ä¼°æ‰©å±•åçš„æ€§èƒ½
            immediate_accuracy, immediate_loss = evaluate_model(evolved_model, dataloader, device)
            
            if immediate_accuracy is not None:
                print(f"\nğŸ“Š Immediate Post-Expansion Performance:")
                print(f"   Accuracy: {immediate_accuracy:.2f}%")
                print(f"   Loss: {immediate_loss:.4f}")
                print(f"   Accuracy Change: {immediate_accuracy - initial_accuracy:+.2f}%")
                
                # æµ‹è¯•å†…å­˜æ³„éœ²
                memory_ok = test_memory_leaks(evolved_model, dataloader, device)
                
                if memory_ok:
                    print("âœ… No significant memory leaks detected!")
                else:
                    print("âš ï¸ Potential memory issues detected!")
                
                # æœ€ç»ˆè¯„ä¼°
                print(f"\nğŸ¯ Depth Increase Assessment:")
                accuracy_change = immediate_accuracy - initial_accuracy
                
                if post_expansion_compatibility and memory_ok:
                    if accuracy_change >= -2.0:  # å…è®¸å°å¹…åº¦ä¸‹é™
                        print(f"ğŸ‰ DEPTH INCREASE SUCCESS!")
                        print(f"   âœ… Shape compatibility: OK")
                        print(f"   âœ… Memory usage: OK")
                        print(f"   âœ… Accuracy change: {accuracy_change:+.2f}% (acceptable)")
                        print(f"   âœ… Architecture expansion: {((expanded_params - initial_params) / initial_params * 100):.1f}%")
                    else:
                        print(f"âš ï¸ DEPTH INCREASE PARTIAL SUCCESS")
                        print(f"   âœ… Shape compatibility: OK")
                        print(f"   âœ… Memory usage: OK")
                        print(f"   âš ï¸ Accuracy drop: {accuracy_change:+.2f}% (significant)")
                else:
                    print(f"âŒ DEPTH INCREASE FAILED")
                    print(f"   {'âœ…' if post_expansion_compatibility else 'âŒ'} Shape compatibility")
                    print(f"   {'âœ…' if memory_ok else 'âŒ'} Memory usage")
            else:
                print("âŒ Post-expansion evaluation failed!")
        else:
            print("âŒ Post-expansion tensor shape compatibility failed!")
    else:
        print("âŒ Depth expansion failed!")
        print("   No depth expansion was applied.")
    
    # æ¸…ç†å†…å­˜
    del model
    if 'evolved_model' in locals():
        del evolved_model
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    final_memory = get_memory_usage()
    print(f"\nFinal system memory: {final_memory:.1f} MB")
    print(f"Total memory change: {final_memory - initial_memory:+.1f} MB")
    
    print("\n" + "=" * 60)
    print("ğŸ§ª æ·±åº¦å¢åŠ æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        test_depth_increase()
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc() 