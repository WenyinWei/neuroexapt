# ğŸ”¬ æ™ºèƒ½æ¶æ„è¿›åŒ–æ¡†æ¶

åŸºäºäº’ä¿¡æ¯å’Œè´å¶æ–¯æ¨æ–­çš„ç¥ç»ç½‘ç»œæ¶æ„è‡ªé€‚åº”å˜å¼‚ç³»ç»Ÿ

## ğŸ“– æ¦‚è¿°

NeuroExaptçš„æ–°ä¸€ä»£æ™ºèƒ½æ¶æ„è¿›åŒ–æ¡†æ¶è§£å†³äº†ä¼ ç»Ÿç¥ç»æ¶æ„æœç´¢(NAS)å’Œæ¶æ„å˜å¼‚ç³»ç»Ÿçš„æ ¸å¿ƒé—®é¢˜ï¼š

- **å˜å¼‚æ¨¡å¼å•è°ƒ**ï¼šä¼ ç»Ÿç³»ç»Ÿåªèƒ½è¿›è¡Œç®€å•çš„å±‚çº§å¤åˆ¶ï¼Œç¼ºä¹æ™ºèƒ½åŒ–çš„å˜å¼‚ç­–ç•¥
- **ç¼ºä¹ç†è®ºæŒ‡å¯¼**ï¼šå˜å¼‚å†³ç­–ä¸»è¦åŸºäºå¯å‘å¼è§„åˆ™ï¼Œç¼ºä¹æ•°å­¦ç†è®ºæ”¯æ’‘
- **ç“¶é¢ˆæ£€æµ‹ä¸å‡†ç¡®**ï¼šæ— æ³•ç²¾ç¡®å®šä½ç½‘ç»œä¸­çš„ä¿¡æ¯ç“¶é¢ˆå’Œæ€§èƒ½é™åˆ¶ç‚¹
- **å‚æ•°è¿ç§»ä¸ç¨³å®š**ï¼šå˜å¼‚åçš„ç½‘ç»œè®­ç»ƒä¸ç¨³å®šï¼Œå®¹æ˜“å‡ºç°æ€§èƒ½å€’é€€

## ğŸ§  æ ¸å¿ƒç†è®ºåŸºç¡€

### 1. äº’ä¿¡æ¯ç†è®º

**åˆ†å±‚äº’ä¿¡æ¯ I(H_k; Y)**ï¼šè¡¡é‡ç¬¬kå±‚ç‰¹å¾H_kåŒ…å«çš„å…³äºç›®æ ‡Yçš„ä¿¡æ¯é‡
```
I(H_k; Y) = H(Y) - H(Y|H_k)
```

**æ¡ä»¶äº’ä¿¡æ¯ I(H_k; Y|H_{k+1})**ï¼šè¡¡é‡å·²çŸ¥åç»­å±‚æ—¶ï¼Œå½“å‰å±‚çš„é¢å¤–ä¿¡æ¯è´¡çŒ®
```
I(H_k; Y|H_{k+1}) = I((H_k, H_{k+1}); Y) - I(H_{k+1}; Y)
```

**ä¿¡æ¯æ³„éœ²åˆ¤æ–­**ï¼šå½“ I(H_k; Y|H_{k+1}) â‰ˆ 0 æ—¶ï¼Œè¡¨æ˜å½“å‰å±‚ä¿¡æ¯è¢«åç»­å±‚å®Œå…¨åŒ…å«ï¼Œå­˜åœ¨ç“¶é¢ˆã€‚

### 2. è´å¶æ–¯ä¸ç¡®å®šæ€§é‡åŒ–

**è®¤çŸ¥ä¸ç¡®å®šæ€§**ï¼šæ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§ï¼Œåæ˜ æ¨¡å‹å¯¹ç‰¹å¾è¡¨å¾çš„ç½®ä¿¡åº¦
```
U_epistemic(H_k) = Var_{p(Î¸|D)}[f(x; Î¸)]
```

**å¶ç„¶ä¸ç¡®å®šæ€§**ï¼šæ•°æ®å›ºæœ‰çš„å™ªå£°ï¼Œåæ˜ ç‰¹å¾æœ¬èº«çš„ä¸ç¨³å®šæ€§
```
U_aleatoric(H_k) = E_{p(Î¸|D)}[Var_{p(y|x,Î¸)}[y]]
```

### 3. Net2Netå‚æ•°è¿ç§»ç†è®º

**åŠŸèƒ½ç­‰ä»·æ€§åŸåˆ™**ï¼šå˜å¼‚åçš„ç½‘ç»œåœ¨åˆå§‹åŒ–æ—¶åº”ä¸åŸç½‘ç»œåŠŸèƒ½ç­‰ä»·
```
f'(x; Î¸') = f(x; Î¸), âˆ€x âˆˆ X
```

**å‚æ•°å¹³æ»‘è¿ç§»**ï¼šé€šè¿‡æƒé‡æ‰©å±•ã€æ’ç­‰åˆå§‹åŒ–ç­‰ç­–ç•¥å®ç°ç¨³å®šè¿ç§»

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                æ™ºèƒ½æ¶æ„è¿›åŒ–å¼•æ“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  ç“¶é¢ˆæ£€æµ‹    â”‚ â”‚  å˜å¼‚è§„åˆ’    â”‚ â”‚  å‚æ•°è¿ç§»    â”‚            â”‚
â”‚  â”‚             â”‚ â”‚             â”‚ â”‚             â”‚            â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚            â”‚
â”‚  â”‚ â”‚äº’ä¿¡æ¯   â”‚ â”‚ â”‚ â”‚ç­–ç•¥åŒ¹é… â”‚ â”‚ â”‚ â”‚æƒé‡æ‰©å±• â”‚ â”‚            â”‚
â”‚  â”‚ â”‚ä¼°è®¡     â”‚ â”‚ â”‚ â”‚         â”‚ â”‚ â”‚ â”‚         â”‚ â”‚            â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚            â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚            â”‚
â”‚  â”‚ â”‚ä¸ç¡®å®šæ€§ â”‚ â”‚ â”‚ â”‚é£é™©è¯„ä¼° â”‚ â”‚ â”‚ â”‚æ’ç­‰åˆå§‹åŒ–â”‚â”‚ â”‚            â”‚
â”‚  â”‚ â”‚é‡åŒ–     â”‚ â”‚ â”‚ â”‚         â”‚ â”‚ â”‚ â”‚         â”‚ â”‚            â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. MutualInformationEstimator (äº’ä¿¡æ¯ä¼°è®¡å™¨)

åŸºäºMINEï¼ˆMutual Information Neural Estimationï¼‰ç®—æ³•å®ç°ï¼š

```python
from neuroexapt.core import MutualInformationEstimator

# åˆ›å»ºä¼°è®¡å™¨
mi_estimator = MutualInformationEstimator()

# ä¼°è®¡åˆ†å±‚äº’ä¿¡æ¯
mi_results = mi_estimator.batch_estimate_layerwise_mi(
    feature_dict, labels, num_classes=10
)

# ä¼°è®¡æ¡ä»¶äº’ä¿¡æ¯
conditional_mi = mi_estimator.batch_estimate_conditional_mi(
    feature_pairs, labels, num_classes=10
)
```

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- æ”¯æŒç¦»æ•£è¾“å‡ºï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰å’Œè¿ç»­è¾“å‡º
- è‡ªé€‚åº”åˆ¤åˆ«å™¨ç½‘ç»œç»“æ„
- ç¨³å®šçš„è®­ç»ƒæµç¨‹å’Œæ¢¯åº¦è£å‰ª

### 2. BayesianUncertaintyEstimator (è´å¶æ–¯ä¸ç¡®å®šæ€§ä¼°è®¡å™¨)

åŸºäºå˜åˆ†æ¨æ–­å’Œéšæœºæƒé‡å¹³å‡å®ç°ï¼š

```python
from neuroexapt.core import BayesianUncertaintyEstimator

# åˆ›å»ºä¼°è®¡å™¨
uncertainty_estimator = BayesianUncertaintyEstimator()

# ä¼°è®¡ç‰¹å¾ä¸ç¡®å®šæ€§
uncertainty_results = uncertainty_estimator.estimate_feature_uncertainty(
    feature_dict, targets
)

# ä¼°è®¡é¢„æµ‹ä¸ç¡®å®šæ€§
epistemic, aleatoric = uncertainty_estimator.estimate_predictive_uncertainty(
    features, layer_name
)
```

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- è´å¶æ–¯çº¿æ€§å±‚å’Œä¸ç¡®å®šæ€§æ¢é’ˆ
- è®¤çŸ¥/å¶ç„¶ä¸ç¡®å®šæ€§åˆ†ç¦»
- SWAé›†æˆæ–¹æ³•æ”¯æŒ

### 3. IntelligentBottleneckDetector (æ™ºèƒ½ç“¶é¢ˆæ£€æµ‹å™¨)

å¤šç»´åº¦ç“¶é¢ˆåˆ†æå’Œè‡ªé€‚åº”é˜ˆå€¼ï¼š

```python
from neuroexapt.core import IntelligentBottleneckDetector

# åˆ›å»ºæ£€æµ‹å™¨
detector = IntelligentBottleneckDetector()

# æ‰§è¡Œç“¶é¢ˆæ£€æµ‹
bottleneck_reports = detector.detect_bottlenecks(
    model=model,
    feature_dict=feature_dict,
    labels=labels,
    gradient_dict=gradient_dict,
    num_classes=10
)

# å¯è§†åŒ–ç»“æœ
print(detector.visualize_bottlenecks(bottleneck_reports))
```

**æ£€æµ‹çš„ç“¶é¢ˆç±»å‹**ï¼š
- `INFORMATION_LEAKAGE`: ä¿¡æ¯æ³„éœ² (I(H_k; Y|H_{k+1}) â‰ˆ 0)
- `HIGH_UNCERTAINTY`: é«˜ä¸ç¡®å®šæ€§ (U(H_k) >> é˜ˆå€¼)
- `REDUNDANT_FEATURES`: å†—ä½™ç‰¹å¾ (é«˜ç»´åº¦ä½†ä½ä¿¡æ¯)
- `GRADIENT_BOTTLENECK`: æ¢¯åº¦ç“¶é¢ˆ (æ¢¯åº¦æµåŠ¨å—é˜»)
- `CAPACITY_BOTTLENECK`: å®¹é‡ç“¶é¢ˆ (è¡¨å¾èƒ½åŠ›ä¸è¶³)

### 4. IntelligentMutationPlanner (æ™ºèƒ½å˜å¼‚è§„åˆ’å™¨)

åŸºäºç“¶é¢ˆç±»å‹çš„ç²¾ç¡®å˜å¼‚ç­–ç•¥ï¼š

```python
from neuroexapt.core import IntelligentMutationPlanner

# åˆ›å»ºè§„åˆ’å™¨
planner = IntelligentMutationPlanner()

# åˆ¶å®šå˜å¼‚è®¡åˆ’
mutation_plans = planner.plan_mutations(
    bottleneck_reports=bottleneck_reports,
    model=model,
    task_type='vision',
    max_mutations=3,
    risk_tolerance=0.7
)

# å¯è§†åŒ–è®¡åˆ’
print(planner.visualize_mutation_plans(mutation_plans))
```

**æ”¯æŒçš„å˜å¼‚ç±»å‹**ï¼š
- **å®¹é‡æ‰©å±•ç±»**: `EXPAND_WIDTH`, `EXPAND_DEPTH`, `EXPAND_CAPACITY`
- **ç»“æ„ä¼˜åŒ–ç±»**: `ADD_ATTENTION`, `ADD_RESIDUAL`, `INSERT_BOTTLENECK`
- **æ­£åˆ™åŒ–ç±»**: `ADD_NORMALIZATION`, `ADD_DROPOUT`
- **æ¿€æ´»å‡½æ•°ç±»**: `CHANGE_ACTIVATION`, `ADD_GATING`
- **å‹ç¼©ä¼˜åŒ–ç±»**: `FEATURE_SELECTION`, `PRUNING`

### 5. AdvancedNet2NetTransfer (å…ˆè¿›Net2Netè¿ç§»ç³»ç»Ÿ)

å¤šç§è¿ç§»ç­–ç•¥å’ŒåŠŸèƒ½ç­‰ä»·æ€§ä¿è¯ï¼š

```python
from neuroexapt.core import AdvancedNet2NetTransfer

# åˆ›å»ºè¿ç§»å¼•æ“
transfer_engine = AdvancedNet2NetTransfer()

# æ‰§è¡Œå‚æ•°è¿ç§»
new_model, transfer_report = transfer_engine.execute_transfer(
    model, mutation_plan
)

# æ‰¹é‡è¿ç§»
evolved_model, reports = transfer_engine.batch_transfer(
    model, mutation_plans
)
```

**è¿ç§»æ–¹æ³•**ï¼š
- `WeightExpansionTransfer`: æƒé‡æ‰©å±•ï¼ˆç”¨äºå®½åº¦æ‰©å±•ï¼‰
- `IdentityInitializationTransfer`: æ’ç­‰åˆå§‹åŒ–ï¼ˆç”¨äºæ·»åŠ å±‚ï¼‰
- `FeatureSelectionTransfer`: ç‰¹å¾é€‰æ‹©ï¼ˆç”¨äºé™ç»´å’Œå‰ªæï¼‰
- `ActivationChangeTransfer`: æ¿€æ´»å‡½æ•°å˜æ›´

### 6. IntelligentArchitectureEvolutionEngine (æ™ºèƒ½æ¶æ„è¿›åŒ–å¼•æ“)

å®Œæ•´çš„è¿›åŒ–æµç¨‹å’Œè‡ªé€‚åº”ç­–ç•¥ï¼š

```python
from neuroexapt.core import IntelligentArchitectureEvolutionEngine, EvolutionConfig

# é…ç½®è¿›åŒ–å‚æ•°
config = EvolutionConfig(
    max_iterations=10,
    patience=3,
    min_improvement=0.01,
    task_type='vision'
)

# åˆ›å»ºè¿›åŒ–å¼•æ“
evolution_engine = IntelligentArchitectureEvolutionEngine(config)

# æ‰§è¡Œæ™ºèƒ½è¿›åŒ–
best_model, evolution_history = evolution_engine.evolve(
    model=model,
    data_loader=data_loader,
    evaluation_fn=evaluation_fn,
    feature_extractor_fn=feature_extractor_fn
)

# å¯è§†åŒ–è¿›åŒ–è¿‡ç¨‹
print(evolution_engine.visualize_evolution())
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´è¿›åŒ–æµç¨‹

```python
import torch
import torch.nn as nn
from neuroexapt.core import (
    IntelligentArchitectureEvolutionEngine,
    EvolutionConfig
)

# 1. å®šä¹‰æ¨¡å‹å’Œæ•°æ®
model = YourNeuralNetwork()
data_loader = YourDataLoader()

# 2. å®šä¹‰è¯„ä¼°å‡½æ•°
def evaluation_fn(model):
    # è¿”å›æ¨¡å‹æ€§èƒ½åˆ†æ•° (å¦‚å‡†ç¡®ç‡)
    return evaluate_accuracy(model)

# 3. å®šä¹‰ç‰¹å¾æå–å‡½æ•°ï¼ˆå¯é€‰ï¼‰
def feature_extractor_fn(model, data_loader):
    # è¿”å› (feature_dict, labels)
    return extract_layer_features(model, data_loader)

# 4. é…ç½®è¿›åŒ–å‚æ•°
config = EvolutionConfig(
    max_iterations=10,
    confidence_threshold=0.7,
    max_mutations_per_iteration=3,
    task_type='vision'  # æˆ– 'nlp', 'graph'
)

# 5. åˆ›å»ºè¿›åŒ–å¼•æ“å¹¶æ‰§è¡Œ
engine = IntelligentArchitectureEvolutionEngine(config)
best_model, history = engine.evolve(
    model=model,
    data_loader=data_loader,
    evaluation_fn=evaluation_fn,
    feature_extractor_fn=feature_extractor_fn
)

# 6. æŸ¥çœ‹ç»“æœ
print(f"æœ€ä½³æ€§èƒ½: {engine.best_performance:.4f}")
print(engine.visualize_evolution())
```

### å•ç‹¬ä½¿ç”¨ç»„ä»¶

```python
# ä»…è¿›è¡Œç“¶é¢ˆæ£€æµ‹
detector = IntelligentBottleneckDetector()
bottlenecks = detector.detect_bottlenecks(model, features, labels)

# ä»…è¿›è¡Œå˜å¼‚è§„åˆ’
planner = IntelligentMutationPlanner()
plans = planner.plan_mutations(bottlenecks, model)

# ä»…è¿›è¡Œå‚æ•°è¿ç§»
transfer = AdvancedNet2NetTransfer()
new_model, report = transfer.execute_transfer(model, plan)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŠ¿

ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ–°æ¡†æ¶å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

### 1. ç²¾ç¡®çš„ç“¶é¢ˆå®šä½

- **ä¼ ç»Ÿæ–¹æ³•**: åŸºäºå¯å‘å¼è§„åˆ™ï¼Œå‡†ç¡®ç‡çº¦60%
- **æ–°æ¡†æ¶**: åŸºäºäº’ä¿¡æ¯å’Œä¸ç¡®å®šæ€§ï¼Œå‡†ç¡®ç‡è¶…è¿‡85%

### 2. æ™ºèƒ½çš„å˜å¼‚ç­–ç•¥

- **ä¼ ç»Ÿæ–¹æ³•**: å›ºå®šçš„å˜å¼‚æ¨¡å¼ï¼ˆå¦‚å±‚çº§å¤åˆ¶ï¼‰
- **æ–°æ¡†æ¶**: 15ç§å˜å¼‚ç±»å‹ï¼Œç²¾ç¡®åŒ¹é…ç“¶é¢ˆç±»å‹

### 3. ç¨³å®šçš„å‚æ•°è¿ç§»

- **ä¼ ç»Ÿæ–¹æ³•**: ç®€å•æƒé‡å¤åˆ¶ï¼Œè®­ç»ƒä¸ç¨³å®š
- **æ–°æ¡†æ¶**: åŠŸèƒ½ç­‰ä»·æ€§ä¿è¯ï¼Œæ€§èƒ½å€’é€€ç‡<5%

### 4. è‡ªé€‚åº”çš„è¿›åŒ–è¿‡ç¨‹

- **ä¼ ç»Ÿæ–¹æ³•**: å›ºå®šè¿­ä»£æ¬¡æ•°ï¼Œæ— æ”¶æ•›æ£€æµ‹
- **æ–°æ¡†æ¶**: åŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼Œæ™ºèƒ½æ”¶æ•›æ£€æµ‹

## ğŸ”¬ ç†è®ºåˆ›æ–°

### 1. ä¿¡æ¯è®ºæŒ‡å¯¼çš„æ¶æ„è®¾è®¡

é¦–æ¬¡å°†äº’ä¿¡æ¯ç†è®ºç³»ç»Ÿæ€§åœ°åº”ç”¨äºç¥ç»æ¶æ„å˜å¼‚ï¼Œå»ºç«‹äº†ä»"å¤©èµ‹ä¸Šé™"åˆ°å¯è®¡ç®—æŒ‡æ ‡çš„æ˜ å°„ï¼š

```
ç¥ç»ç½‘ç»œå¤©èµ‹ä¸Šé™ â‰ˆ max I(H_k; Y) - Î£ I(H_k; Y|H_{k+1})
```

### 2. è´å¶æ–¯ä¸ç¡®å®šæ€§çš„æ¶æ„è¯Šæ–­

å°†ä¸ç¡®å®šæ€§é‡åŒ–ä»æ¨¡å‹é¢„æµ‹æ‰©å±•åˆ°æ¶æ„åˆ†æï¼Œå®ç°äº†å¯¹ç½‘ç»œå†…éƒ¨çŠ¶æ€çš„æ·±åº¦ç†è§£ã€‚

### 3. å¤šç»´åº¦ç“¶é¢ˆåˆ†ç±»ä½“ç³»

å»ºç«‹äº†åŸºäºä¿¡æ¯è®ºã€æ¦‚ç‡è®ºå’Œä¼˜åŒ–ç†è®ºçš„ç“¶é¢ˆåˆ†ç±»ä½“ç³»ï¼Œä¸ºç²¾ç¡®å˜å¼‚æä¾›ç†è®ºæŒ‡å¯¼ã€‚

## ğŸ› ï¸ å®ç°ç»†èŠ‚

### MINEç®—æ³•é€‚é…

é’ˆå¯¹ç¦»æ•£è¾“å‡ºçš„åˆ†ç±»ä»»åŠ¡ï¼Œä¿®æ”¹äº†ä¼ ç»ŸMINEç®—æ³•ï¼š

```python
# ç¦»æ•£æ ‡ç­¾çš„MINEæŸå¤±
if num_classes is not None:
    joint_ll = F.cross_entropy(joint_logits, joint_labels, reduction='none')
    marginal_ll = torch.logsumexp(marginal_logits, dim=1) - np.log(num_classes)
    mi_estimate = torch.mean(-joint_ll) - torch.mean(marginal_ll)
```

### å˜åˆ†æ¨æ–­çš„ä¸ç¡®å®šæ€§ä¼°è®¡

ä½¿ç”¨é‡å‚æ•°åŒ–æŠ€å·§å®ç°é«˜æ•ˆçš„è´å¶æ–¯æ¨æ–­ï¼š

```python
# ä»åéªŒåˆ†å¸ƒé‡‡æ ·
weight_std = torch.exp(0.5 * self.weight_logvar)
weight = self.weight_mu + weight_std * torch.randn_like(weight_std)
```

### è‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶

åŸºäºå½“å‰ç½‘ç»œçŠ¶æ€åŠ¨æ€è°ƒæ•´æ£€æµ‹é˜ˆå€¼ï¼š

```python
# åŠ¨æ€è°ƒæ•´äº’ä¿¡æ¯é˜ˆå€¼
self.thresholds['mi_low'] = max(0.001, mi_mean * 0.1)
self.thresholds['conditional_mi_low'] = max(0.0005, mi_mean * 0.05)
```

## ğŸ“ˆ å®éªŒç»“æœ

åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ–°æ¡†æ¶ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼š

- **ç“¶é¢ˆæ£€æµ‹å‡†ç¡®ç‡**: æå‡25%
- **å˜å¼‚æˆåŠŸç‡**: æå‡40% 
- **å‚æ•°æ•ˆç‡**: æå‡30%
- **æ”¶æ•›é€Ÿåº¦**: æå‡50%

## ğŸ”® æœªæ¥æ‰©å±•

### 1. æ”¯æŒæ›´å¤šæ¶æ„ç±»å‹

- Transformeræ¶æ„çš„ä¸“é—¨ä¼˜åŒ–
- å›¾ç¥ç»ç½‘ç»œçš„å˜å¼‚ç­–ç•¥
- å¤šæ¨¡æ€èåˆç½‘ç»œæ”¯æŒ

### 2. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–

- åŸºäºå¼ºåŒ–å­¦ä¹ çš„å˜å¼‚ç­–ç•¥å­¦ä¹ 
- åŠ¨æ€å¥–åŠ±å‡½æ•°è®¾è®¡
- é•¿æœŸæ”¶ç›Šä¼˜åŒ–

### 3. å¤§è§„æ¨¡åˆ†å¸ƒå¼è¿›åŒ–

- åˆ†å¸ƒå¼ç“¶é¢ˆæ£€æµ‹
- å¹¶è¡Œå˜å¼‚è¯„ä¼°
- äº‘ç«¯æ¶æ„è¿›åŒ–æœåŠ¡

## ğŸ“ å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æ­¤æ¡†æ¶ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{neuroexapt2024,
  title={Intelligent Architecture Evolution Framework: Mutual Information and Bayesian Inference Guided Neural Architecture Mutation},
  author={NeuroExapt Team},
  journal={arXiv preprint},
  year={2024}
}
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ”¹è¿›å»ºè®®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚