"""
æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤ºè„šæœ¬
å±•ç¤ºåŸºäºäº’ä¿¡æ¯å’Œè´å¶æ–¯æ¨æ–­çš„ç¥ç»ç½‘ç»œæ¶æ„è¿›åŒ–
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¯¼å…¥æ–°çš„æ™ºèƒ½æ¶æ„è¿›åŒ–ç»„ä»¶
from neuroexapt.core import (
    IntelligentArchitectureEvolutionEngine,
    EvolutionConfig,
    MutualInformationEstimator,
    BayesianUncertaintyEstimator,
    IntelligentBottleneckDetector
)


class SimpleClassificationModel(nn.Module):
    """ç®€å•çš„åˆ†ç±»æ¨¡å‹ç”¨äºæ¼”ç¤º"""
    
    def __init__(self, input_dim=784, hidden_dims=[128, 64], num_classes=10):
        super().__init__()
        
        layers = []
        prev_dim = input_dim
        
        for i, hidden_dim in enumerate(hidden_dims):
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.ReLU())
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, num_classes))
        
        self.network = nn.Sequential(*layers)
        
    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³
        return self.network(x)


def create_dummy_data(num_samples=1000, input_dim=784, num_classes=10):
    """åˆ›å»ºè™šæ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º"""
    # ç”Ÿæˆå…·æœ‰ä¸€å®šç»“æ„çš„æ•°æ®
    X = torch.randn(num_samples, input_dim)
    
    # åˆ›å»ºä¸€äº›æ¨¡å¼ï¼šè®©æŸäº›ç‰¹å¾ä¸æ ‡ç­¾ç›¸å…³
    patterns = torch.randn(num_classes, input_dim // 4)
    y = torch.randint(0, num_classes, (num_samples,))
    
    for i in range(num_samples):
        label = y[i].item()
        # åœ¨å‰1/4çš„ç‰¹å¾ä¸­æ³¨å…¥æ¨¡å¼
        X[i, :input_dim//4] += patterns[label] * 0.5 + torch.randn(input_dim//4) * 0.2
    
    return X, y


def evaluate_model(model, data_loader, device='cpu'):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in data_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    
    accuracy = correct / total
    return accuracy


def extract_features_and_labels(model, data_loader):
    """æå–æ¨¡å‹ç‰¹å¾å’Œæ ‡ç­¾"""
    feature_dict = {}
    all_labels = []
    
    # æ³¨å†Œhookæ”¶é›†ç‰¹å¾
    def get_hook(name):
        def hook(module, input, output):
            if name not in feature_dict:
                feature_dict[name] = []
            feature_dict[name].append(output.detach().cpu())
        return hook
    
    hooks = []
    for name, module in model.named_modules():
        if isinstance(module, nn.Linear) and 'network' in name:
            hook = module.register_forward_hook(get_hook(name))
            hooks.append(hook)
    
    model.eval()
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(data_loader):
            if batch_idx >= 3:  # åªå¤„ç†å‡ ä¸ªæ‰¹æ¬¡
                break
            data = data.to(next(model.parameters()).device)
            _ = model(data)
            all_labels.append(target)
    
    # æ¸…ç†hooks
    for hook in hooks:
        hook.remove()
    
    # åˆå¹¶ç‰¹å¾
    for name in feature_dict:
        if feature_dict[name]:
            feature_dict[name] = torch.cat(feature_dict[name], dim=0)
    
    labels = torch.cat(all_labels, dim=0) if all_labels else torch.tensor([])
    
    return feature_dict, labels


def demo_mutual_information_estimation():
    """æ¼”ç¤ºäº’ä¿¡æ¯ä¼°è®¡"""
    print("\n" + "="*50)
    print("ğŸ”¬ æ¼”ç¤ºï¼šäº’ä¿¡æ¯ä¼°è®¡")
    print("="*50)
    
    # åˆ›å»ºè™šæ‹Ÿæ•°æ®
    X, y = create_dummy_data(500, 100, 5)
    
    # åˆ›å»ºäº’ä¿¡æ¯ä¼°è®¡å™¨
    mi_estimator = MutualInformationEstimator()
    
    # ä¼°è®¡äº’ä¿¡æ¯
    feature_dict = {'test_features': X}
    mi_results = mi_estimator.batch_estimate_layerwise_mi(
        feature_dict, y, num_classes=5
    )
    
    print(f"ç‰¹å¾ä¸æ ‡ç­¾çš„äº’ä¿¡æ¯: {mi_results['test_features']:.4f}")
    
    # åˆ›å»ºå™ªå£°ç‰¹å¾å¯¹æ¯”
    noise_features = torch.randn_like(X)
    noise_dict = {'noise_features': noise_features}
    noise_mi = mi_estimator.batch_estimate_layerwise_mi(
        noise_dict, y, num_classes=5
    )
    
    print(f"å™ªå£°ç‰¹å¾ä¸æ ‡ç­¾çš„äº’ä¿¡æ¯: {noise_mi['noise_features']:.4f}")
    print(f"æœ‰æ„ä¹‰ç‰¹å¾çš„äº’ä¿¡æ¯æ˜¾è‘—é«˜äºå™ªå£°ç‰¹å¾ âœ“")


def demo_uncertainty_estimation():
    """æ¼”ç¤ºä¸ç¡®å®šæ€§ä¼°è®¡"""
    print("\n" + "="*50)
    print("ğŸ² æ¼”ç¤ºï¼šè´å¶æ–¯ä¸ç¡®å®šæ€§ä¼°è®¡")
    print("="*50)
    
    # åˆ›å»ºæ•°æ®
    X, y = create_dummy_data(300, 50, 3)
    
    # åˆ›å»ºä¸ç¡®å®šæ€§ä¼°è®¡å™¨
    uncertainty_estimator = BayesianUncertaintyEstimator()
    
    # ä¼°è®¡ä¸ç¡®å®šæ€§
    feature_dict = {'test_features': X}
    uncertainty_results = uncertainty_estimator.estimate_feature_uncertainty(
        feature_dict, y
    )
    
    print(f"ç‰¹å¾ä¸ç¡®å®šæ€§: {uncertainty_results['test_features']:.4f}")
    
    # æ·»åŠ é«˜å™ªå£°ç‰¹å¾
    noisy_features = X + torch.randn_like(X) * 2.0
    noisy_dict = {'noisy_features': noisy_features}
    noisy_uncertainty = uncertainty_estimator.estimate_feature_uncertainty(
        noisy_dict, y
    )
    
    print(f"é«˜å™ªå£°ç‰¹å¾ä¸ç¡®å®šæ€§: {noisy_uncertainty['noisy_features']:.4f}")
    print(f"é«˜å™ªå£°ç‰¹å¾çš„ä¸ç¡®å®šæ€§æ›´é«˜ âœ“")


def demo_bottleneck_detection():
    """æ¼”ç¤ºç“¶é¢ˆæ£€æµ‹"""
    print("\n" + "="*50)
    print("ğŸ” æ¼”ç¤ºï¼šæ™ºèƒ½ç“¶é¢ˆæ£€æµ‹")
    print("="*50)
    
    # åˆ›å»ºæ•°æ®å’Œæ¨¡å‹
    X, y = create_dummy_data(400, 784, 10)
    data_loader = DataLoader(TensorDataset(X, y), batch_size=32, shuffle=False)
    
    # åˆ›å»ºä¸€ä¸ªæœ‰æ˜æ˜¾ç“¶é¢ˆçš„æ¨¡å‹ï¼ˆä¸­é—´å±‚å¤ªå°ï¼‰
    model = SimpleClassificationModel(input_dim=784, hidden_dims=[256, 16, 128], num_classes=10)
    
    # æå–ç‰¹å¾
    feature_dict, labels = extract_features_and_labels(model, data_loader)
    
    # åˆ›å»ºç“¶é¢ˆæ£€æµ‹å™¨
    detector = IntelligentBottleneckDetector()
    
    # æ‰§è¡Œç“¶é¢ˆæ£€æµ‹
    bottleneck_reports = detector.detect_bottlenecks(
        model=model,
        feature_dict=feature_dict,
        labels=labels,
        num_classes=10,
        confidence_threshold=0.5  # é™ä½é˜ˆå€¼ä»¥æ›´å®¹æ˜“æ£€æµ‹åˆ°ç“¶é¢ˆ
    )
    
    print(f"æ£€æµ‹åˆ° {len(bottleneck_reports)} ä¸ªç“¶é¢ˆ")
    
    # å¯è§†åŒ–ç“¶é¢ˆæŠ¥å‘Š
    visualization = detector.visualize_bottlenecks(bottleneck_reports)
    print(visualization)


def demo_complete_evolution():
    """æ¼”ç¤ºå®Œæ•´çš„æ¶æ„è¿›åŒ–"""
    print("\n" + "="*50)
    print("ğŸš€ æ¼”ç¤ºï¼šå®Œæ•´æ™ºèƒ½æ¶æ„è¿›åŒ–")
    print("="*50)
    
    # åˆ›å»ºæ•°æ®
    X, y = create_dummy_data(600, 784, 10)
    train_loader = DataLoader(TensorDataset(X[:500], y[:500]), batch_size=32, shuffle=True)
    test_loader = DataLoader(TensorDataset(X[500:], y[500:]), batch_size=32, shuffle=False)
    
    # åˆ›å»ºåˆå§‹æ¨¡å‹
    model = SimpleClassificationModel(input_dim=784, hidden_dims=[128, 32], num_classes=10)
    
    # ç®€å•è®­ç»ƒå‡ ä¸ªepoch
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    model.train()
    for epoch in range(3):
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = F.cross_entropy(output, target)
            loss.backward()
            optimizer.step()
            
            if batch_idx >= 5:  # åªè®­ç»ƒå‡ ä¸ªæ‰¹æ¬¡
                break
    
    # è¯„ä¼°åˆå§‹æ€§èƒ½
    initial_accuracy = evaluate_model(model, test_loader)
    print(f"åˆå§‹æ¨¡å‹å‡†ç¡®ç‡: {initial_accuracy:.4f}")
    
    # é…ç½®è¿›åŒ–å‚æ•°
    config = EvolutionConfig(
        max_iterations=3,  # é™åˆ¶è¿­ä»£æ¬¡æ•°
        patience=2,
        min_improvement=0.001,
        confidence_threshold=0.5,
        max_mutations_per_iteration=2,
        task_type='vision'
    )
    
    # åˆ›å»ºè¿›åŒ–å¼•æ“
    evolution_engine = IntelligentArchitectureEvolutionEngine(config)
    
    # å®šä¹‰è¯„ä¼°å‡½æ•°
    def evaluation_fn(model):
        return evaluate_model(model, test_loader)
    
    # å®šä¹‰ç‰¹å¾æå–å‡½æ•°
    def feature_extractor_fn(model, data_loader):
        return extract_features_and_labels(model, data_loader)
    
    try:
        # æ‰§è¡Œæ™ºèƒ½è¿›åŒ–
        best_model, evolution_history = evolution_engine.evolve(
            model=model,
            data_loader=train_loader,
            evaluation_fn=evaluation_fn,
            feature_extractor_fn=feature_extractor_fn
        )
        
        # è¯„ä¼°æœ€ç»ˆæ€§èƒ½
        final_accuracy = evaluate_model(best_model, test_loader)
        print(f"è¿›åŒ–åæ¨¡å‹å‡†ç¡®ç‡: {final_accuracy:.4f}")
        print(f"æ€§èƒ½æå‡: {final_accuracy - initial_accuracy:+.4f}")
        
        # å¯è§†åŒ–è¿›åŒ–è¿‡ç¨‹
        print("\n" + evolution_engine.visualize_evolution())
        
        # è·å–è¿›åŒ–æ‘˜è¦
        summary = evolution_engine.get_evolution_summary()
        print(f"\nğŸ“Š è¿›åŒ–æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
        
    except Exception as e:
        print(f"è¿›åŒ–è¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
        print("è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºè¿™æ˜¯æ¼”ç¤ºä»£ç ï¼ŒæŸäº›å¤æ‚æ“ä½œå¯èƒ½éœ€è¦æ›´å¤šçš„æ•°æ®å’Œè®­ç»ƒ")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¯ NeuroExapt æ™ºèƒ½æ¶æ„è¿›åŒ–æ¼”ç¤º")
    print("åŸºäºäº’ä¿¡æ¯å’Œè´å¶æ–¯æ¨æ–­çš„ç¥ç»ç½‘ç»œæ¶æ„å˜å¼‚ç³»ç»Ÿ")
    
    try:
        # æ¼”ç¤ºå„ä¸ªç»„ä»¶
        demo_mutual_information_estimation()
        demo_uncertainty_estimation()
        demo_bottleneck_detection()
        demo_complete_evolution()
        
        print("\n" + "="*50)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("æ–°æ¡†æ¶æˆåŠŸå±•ç¤ºäº†ä»¥ä¸‹èƒ½åŠ›ï¼š")
        print("âœ“ åŸºäºMINEçš„äº’ä¿¡æ¯ä¼°è®¡")
        print("âœ“ è´å¶æ–¯ä¸ç¡®å®šæ€§é‡åŒ–")
        print("âœ“ æ™ºèƒ½ç“¶é¢ˆæ£€æµ‹ä¸å®šä½")
        print("âœ“ ç²¾ç¡®çš„å˜å¼‚ç­–ç•¥è§„åˆ’")
        print("âœ“ ç¨³å¥çš„Net2Netå‚æ•°è¿ç§»")
        print("âœ“ å®Œæ•´çš„æ¶æ„è¿›åŒ–æµç¨‹")
        print("\nè¿™ä¸ªæ¡†æ¶è§£å†³äº†åŸæœ‰ç³»ç»Ÿçš„å…³é”®é—®é¢˜ï¼š")
        print("â€¢ å˜å¼‚æ¨¡å¼å•è°ƒ -> åŸºäºç“¶é¢ˆç±»å‹çš„ç²¾ç¡®å˜å¼‚")
        print("â€¢ ç¼ºä¹ç†è®ºæŒ‡å¯¼ -> äº’ä¿¡æ¯å’Œè´å¶æ–¯æ¨æ–­çš„æ•°å­¦åŸºç¡€")
        print("â€¢ æ£€æµ‹ç»“æœä¸å‡†ç¡® -> åŠ¨æ€é˜ˆå€¼å’Œå¤šç»´åº¦åˆ†æ")
        print("â€¢ å‚æ•°è¿ç§»ä¸ç¨³å®š -> åŠŸèƒ½ç­‰ä»·æ€§ä¿è¯")
        print("="*50)
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main()