#!/usr/bin/env python3
"""
æµ‹è¯•é«˜çº§å½¢æ€å‘ç”ŸåŠŸèƒ½
Test Advanced Morphogenesis Features

ğŸ§¬ æµ‹è¯•å†…å®¹ï¼š
1. ä¸²è¡Œåˆ†è£‚ (Serial Division) - å¢åŠ ç½‘ç»œæ·±åº¦
2. å¹¶è¡Œåˆ†è£‚ (Parallel Division) - åˆ›å»ºå¤šåˆ†æ”¯ç»“æ„
3. æ··åˆåˆ†è£‚ (Hybrid Division) - ç»„åˆä¸åŒç±»å‹çš„å±‚
4. æ™ºèƒ½ç“¶é¢ˆåˆ†æ
5. å†³ç­–åˆ¶å®šç³»ç»Ÿ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import numpy as np
import time
from collections import defaultdict

# å¯¼å…¥å¢å¼ºçš„DNMç»„ä»¶
from neuroexapt.core import (
    EnhancedDNMFramework,
    AdvancedBottleneckAnalyzer,
    AdvancedMorphogenesisExecutor,
    IntelligentMorphogenesisDecisionMaker,
    MorphogenesisType,
    MorphogenesisDecision
)

class AdvancedTestNetwork(nn.Module):
    """é«˜çº§æµ‹è¯•ç½‘ç»œ"""
    
    def __init__(self, num_classes=10):
        super(AdvancedTestNetwork, self).__init__()
        
        # ç‰¹å¾æå–å±‚
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.AdaptiveAvgPool2d((4, 4))
        )
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
        
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

def capture_activations_and_gradients(model, data_loader, device):
    """æ•è·æ¿€æ´»å€¼å’Œæ¢¯åº¦"""
    model.eval()
    activations = {}
    gradients = {}
    
    # æ³¨å†Œé’©å­å‡½æ•°
    def forward_hook(name):
        def hook(module, input, output):
            if isinstance(output, torch.Tensor):
                activations[name] = output.detach().cpu()
        return hook
    
    def backward_hook(name):
        def hook(module, grad_input, grad_output):
            if grad_output[0] is not None:
                gradients[name] = grad_output[0].detach().cpu()
        return hook
    
    # æ³¨å†Œé’©å­
    hooks = []
    for name, module in model.named_modules():
        if isinstance(module, (nn.Linear, nn.Conv2d)):
            hooks.append(module.register_forward_hook(forward_hook(name)))
            hooks.append(module.register_backward_hook(backward_hook(name)))
    
    # æ‰§è¡Œå‰å‘å’Œåå‘ä¼ æ’­
    model.train()
    data, target = next(iter(data_loader))
    data, target = data.to(device), target.to(device)
    
    output = model(data)
    loss = F.cross_entropy(output, target)
    loss.backward()
    
    # ç§»é™¤é’©å­
    for hook in hooks:
        hook.remove()
    
    return activations, gradients

def test_advanced_bottleneck_analyzer():
    """æµ‹è¯•é«˜çº§ç“¶é¢ˆåˆ†æå™¨"""
    print("\nğŸ” æµ‹è¯•é«˜çº§ç“¶é¢ˆåˆ†æå™¨...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = AdvancedTestNetwork().to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    dataset = torchvision.datasets.CIFAR10(
        root='./data', train=True, download=True, transform=transform
    )
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    # æ•è·æ¿€æ´»å€¼å’Œæ¢¯åº¦
    activations, gradients = capture_activations_and_gradients(model, data_loader, device)
    
    # æµ‹è¯•ç“¶é¢ˆåˆ†æå™¨
    analyzer = AdvancedBottleneckAnalyzer()
    analysis = analyzer.analyze_network_bottlenecks(model, activations, gradients)
    
    print("  âœ… ç“¶é¢ˆåˆ†æå®Œæˆ")
    print(f"  ğŸ“Š åˆ†æç»“æœ:")
    
    for analysis_type, scores in analysis.items():
        if scores:
            top_bottleneck = max(scores.items(), key=lambda x: x[1])
            print(f"    {analysis_type}: æœ€é«˜åˆ†æ•° {top_bottleneck[1]:.3f} (å±‚: {top_bottleneck[0]})")
        else:
            print(f"    {analysis_type}: æ— æ•°æ®")
    
    return analysis

def test_morphogenesis_decision_maker(bottleneck_analysis):
    """æµ‹è¯•å½¢æ€å‘ç”Ÿå†³ç­–åˆ¶å®šå™¨"""
    print("\nğŸ§  æµ‹è¯•æ™ºèƒ½å†³ç­–åˆ¶å®šå™¨...")
    
    decision_maker = IntelligentMorphogenesisDecisionMaker()
    
    # æ¨¡æ‹Ÿæ€§èƒ½å†å²
    performance_history = [0.1, 0.2, 0.35, 0.5, 0.65, 0.75, 0.82, 0.85, 0.86, 0.86]
    
    decision = decision_maker.make_decision(bottleneck_analysis, performance_history)
    
    if decision:
        print("  âœ… å†³ç­–åˆ¶å®šå®Œæˆ")
        print(f"  ğŸ¯ å†³ç­–ç»“æœ:")
        print(f"    å½¢æ€å‘ç”Ÿç±»å‹: {decision.morphogenesis_type.value}")
        print(f"    ç›®æ ‡ä½ç½®: {decision.target_location}")
        print(f"    ç½®ä¿¡åº¦: {decision.confidence:.3f}")
        print(f"    é¢„æœŸæ”¹è¿›: {decision.expected_improvement:.3f}")
        print(f"    å¤æ‚åº¦æˆæœ¬: {decision.complexity_cost:.3f}")
        print(f"    é¢„ä¼°å‚æ•°: {decision.parameters_added}")
        print(f"    å†³ç­–ç†ç”±: {decision.reasoning}")
        return decision
    else:
        print("  âš ï¸ æœªå‘ç°éœ€è¦å½¢æ€å‘ç”Ÿçš„ç“¶é¢ˆ")
        return None

def test_morphogenesis_executor(model, decision):
    """æµ‹è¯•å½¢æ€å‘ç”Ÿæ‰§è¡Œå™¨"""
    if not decision:
        print("\nâ­ï¸ è·³è¿‡å½¢æ€å‘ç”Ÿæ‰§è¡Œæµ‹è¯•ï¼ˆæ— å†³ç­–ï¼‰")
        return model, 0
    
    print(f"\nğŸš€ æµ‹è¯•å½¢æ€å‘ç”Ÿæ‰§è¡Œå™¨ - {decision.morphogenesis_type.value}...")
    
    executor = AdvancedMorphogenesisExecutor()
    
    # è®°å½•åŸå§‹å‚æ•°æ•°é‡
    original_params = sum(p.numel() for p in model.parameters())
    
    # æ‰§è¡Œå½¢æ€å‘ç”Ÿ
    new_model, parameters_added = executor.execute_morphogenesis(model, decision)
    
    # éªŒè¯ç»“æœ
    new_params = sum(p.numel() for p in new_model.parameters())
    actual_added = new_params - original_params
    
    print("  âœ… å½¢æ€å‘ç”Ÿæ‰§è¡Œå®Œæˆ")
    print(f"  ğŸ“Š æ‰§è¡Œç»“æœ:")
    print(f"    åŸå§‹å‚æ•°: {original_params:,}")
    print(f"    æ–°å¢å‚æ•°: {actual_added:,}")
    print(f"    æ€»å‚æ•°: {new_params:,}")
    print(f"    å¢é•¿æ¯”ä¾‹: {(actual_added / original_params * 100):.2f}%")
    
    # æµ‹è¯•æ–°æ¨¡å‹çš„åŠŸèƒ½
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    new_model = new_model.to(device)
    
    test_input = torch.randn(2, 3, 32, 32).to(device)
    
    try:
        with torch.no_grad():
            output = new_model(test_input)
        print(f"    è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print("  âœ… æ–°æ¨¡å‹åŠŸèƒ½éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"  âŒ æ–°æ¨¡å‹åŠŸèƒ½éªŒè¯å¤±è´¥: {e}")
    
    return new_model, actual_added

def test_enhanced_dnm_framework():
    """æµ‹è¯•å¢å¼ºçš„DNMæ¡†æ¶"""
    print("\nğŸ§¬ æµ‹è¯•å¢å¼ºçš„DNMæ¡†æ¶...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = AdvancedTestNetwork().to(device)
    
    # åˆå§‹åŒ–å¢å¼ºçš„DNMæ¡†æ¶
    config = {
        'trigger_interval': 1,  # æ¯ä¸ªepochæ£€æŸ¥
        'complexity_threshold': 0.5,  # é™ä½é˜ˆå€¼ä»¥ä¾¿æµ‹è¯•
        'enable_serial_division': True,
        'enable_parallel_division': True,
        'enable_hybrid_division': True
    }
    
    dnm_framework = EnhancedDNMFramework(config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    dataset = torchvision.datasets.CIFAR10(
        root='./data', train=True, download=True, transform=transform
    )
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    print("  ğŸ“š æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹...")
    
    for epoch in range(3):  # æµ‹è¯•3ä¸ªepoch
        print(f"    Epoch {epoch + 1}:")
        
        # æ•è·æ¿€æ´»å€¼å’Œæ¢¯åº¦
        activations, gradients = capture_activations_and_gradients(model, data_loader, device)
        
        # æ›´æ–°æ€§èƒ½å†å²
        performance = 0.7 + epoch * 0.05 + np.random.normal(0, 0.02)
        dnm_framework.update_performance_history(performance)
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context = {
            'epoch': epoch,
            'activations': activations,
            'gradients': gradients,
            'performance_history': dnm_framework.performance_history
        }
        
        # æ‰§è¡Œå½¢æ€å‘ç”Ÿ
        results = dnm_framework.execute_morphogenesis(model, context)
        
        if results['model_modified']:
            model = results['new_model']
            print(f"      ğŸ‰ å½¢æ€å‘ç”ŸæˆåŠŸ: {results['morphogenesis_type']}")
            print(f"      ğŸ“ˆ æ–°å¢å‚æ•°: {results['parameters_added']:,}")
            print(f"      ğŸ¯ ç½®ä¿¡åº¦: {results.get('decision_confidence', 0):.3f}")
        else:
            print(f"      ğŸ˜´ æœªè§¦å‘å½¢æ€å‘ç”Ÿ")
    
    # è·å–æ€»ç»“
    summary = dnm_framework.get_morphogenesis_summary()
    
    print("  âœ… å¢å¼ºDNMæ¡†æ¶æµ‹è¯•å®Œæˆ")
    print(f"  ğŸ“Š æ€»ç»“:")
    print(f"    æ€»äº‹ä»¶æ•°: {summary['total_events']}")
    print(f"    æ€»æ–°å¢å‚æ•°: {summary['total_parameters_added']:,}")
    print(f"    å½¢æ€å‘ç”Ÿç±»å‹: {summary['morphogenesis_types']}")
    
    return dnm_framework, summary

def compare_morphogenesis_types():
    """æ¯”è¾ƒä¸åŒå½¢æ€å‘ç”Ÿç±»å‹çš„æ•ˆæœ"""
    print("\nâš–ï¸ æ¯”è¾ƒä¸åŒå½¢æ€å‘ç”Ÿç±»å‹...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•æ¯ç§å½¢æ€å‘ç”Ÿç±»å‹
    morphogenesis_types = [
        MorphogenesisType.WIDTH_EXPANSION,
        MorphogenesisType.SERIAL_DIVISION,
        MorphogenesisType.PARALLEL_DIVISION,
        MorphogenesisType.HYBRID_DIVISION
    ]
    
    results = {}
    
    for morph_type in morphogenesis_types:
        print(f"  ğŸ”¬ æµ‹è¯• {morph_type.value}...")
        
        # åˆ›å»ºåŸå§‹æ¨¡å‹
        model = AdvancedTestNetwork().to(device)
        original_params = sum(p.numel() for p in model.parameters())
        
        # åˆ›å»ºå†³ç­–
        decision = MorphogenesisDecision(
            morphogenesis_type=morph_type,
            target_location='classifier.1',  # é€‰æ‹©ä¸€ä¸ªçº¿æ€§å±‚
            confidence=0.8,
            expected_improvement=0.05,
            complexity_cost=0.3,
            parameters_added=5000,
            reasoning=f"æµ‹è¯•{morph_type.value}"
        )
        
        # æ‰§è¡Œå½¢æ€å‘ç”Ÿ
        executor = AdvancedMorphogenesisExecutor()
        try:
            new_model, params_added = executor.execute_morphogenesis(model, decision)
            new_params = sum(p.numel() for p in new_model.parameters())
            
            # æµ‹è¯•åŠŸèƒ½
            test_input = torch.randn(2, 3, 32, 32).to(device)
            with torch.no_grad():
                output = new_model(test_input)
            
            results[morph_type.value] = {
                'success': True,
                'original_params': original_params,
                'new_params': new_params,
                'params_added': params_added,
                'growth_ratio': (new_params - original_params) / original_params,
                'output_shape': output.shape
            }
            
            print(f"    âœ… æˆåŠŸ - æ–°å¢å‚æ•°: {params_added:,}")
            
        except Exception as e:
            results[morph_type.value] = {
                'success': False,
                'error': str(e)
            }
            print(f"    âŒ å¤±è´¥: {e}")
    
    # æ‰“å°æ¯”è¾ƒç»“æœ
    print("\n  ğŸ“‹ æ¯”è¾ƒç»“æœ:")
    print("    ç±»å‹                | æˆåŠŸ | åŸå§‹å‚æ•°    | æ–°å¢å‚æ•°    | å¢é•¿ç‡")
    print("    " + "-" * 65)
    
    for morph_type, result in results.items():
        if result['success']:
            print(f"    {morph_type:<18} | âœ…  | {result['original_params']:>10,} | {result['params_added']:>10,} | {result['growth_ratio']:>6.1%}")
        else:
            print(f"    {morph_type:<18} | âŒ  | -          | -          | -")
    
    return results

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§¬ é«˜çº§å½¢æ€å‘ç”ŸåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    try:
        # 1. æµ‹è¯•ç“¶é¢ˆåˆ†æå™¨
        bottleneck_analysis = test_advanced_bottleneck_analyzer()
        
        # 2. æµ‹è¯•å†³ç­–åˆ¶å®šå™¨
        decision = test_morphogenesis_decision_maker(bottleneck_analysis)
        
        # 3. æµ‹è¯•å½¢æ€å‘ç”Ÿæ‰§è¡Œå™¨
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = AdvancedTestNetwork().to(device)
        new_model, params_added = test_morphogenesis_executor(model, decision)
        
        # 4. æµ‹è¯•å¢å¼ºçš„DNMæ¡†æ¶
        dnm_framework, summary = test_enhanced_dnm_framework()
        
        # 5. æ¯”è¾ƒä¸åŒå½¢æ€å‘ç”Ÿç±»å‹
        comparison_results = compare_morphogenesis_types()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("=" * 50)
        
        print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"  é«˜çº§ç“¶é¢ˆåˆ†æå™¨: âœ… æ­£å¸¸å·¥ä½œ")
        print(f"  æ™ºèƒ½å†³ç­–åˆ¶å®šå™¨: âœ… æ­£å¸¸å·¥ä½œ")
        print(f"  å½¢æ€å‘ç”Ÿæ‰§è¡Œå™¨: âœ… æ­£å¸¸å·¥ä½œ")
        print(f"  å¢å¼ºDNMæ¡†æ¶: âœ… æ­£å¸¸å·¥ä½œ")
        
        # ç»Ÿè®¡æˆåŠŸçš„å½¢æ€å‘ç”Ÿç±»å‹
        successful_types = [t for t, r in comparison_results.items() if r['success']]
        print(f"  æ”¯æŒçš„å½¢æ€å‘ç”Ÿç±»å‹: {len(successful_types)}/4")
        
        if len(successful_types) >= 3:
            print("  ğŸŒŸ é«˜çº§å½¢æ€å‘ç”ŸåŠŸèƒ½å·²å°±ç»ª!")
        else:
            print("  âš ï¸ éƒ¨åˆ†å½¢æ€å‘ç”Ÿç±»å‹éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()