#!/usr/bin/env python3
"""
ASO-SEæ¡†æ¶é—®é¢˜è¯Šæ–­ä¸ä¿®å¤

é’ˆå¯¹æ‚¨æåˆ°çš„é—®é¢˜ï¼š
1. æ¶æ„å‚æ•°ä¸ç½‘ç»œå‚æ•°åˆ†ç¦»è®­ç»ƒæ•ˆæœä¸æ˜æ˜¾
2. æ¡†æ¶å®Œå…¨æ²¡æœ‰åŠ¨å¼¹ï¼Œç¼ºä¹çœŸæ­£çš„æ¶æ„å˜å¼‚
3. 88%å‡†ç¡®ç‡ç“¶é¢ˆçªç ´

è¿™ä¸ªè„šæœ¬æä¾›äº†è¯Šæ–­å·¥å…·å’Œä¿®å¤æ–¹æ¡ˆ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import time
import sys
import os
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict

# Add neuroexapt to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from neuroexapt.core.aso_se_framework import ASOSEFramework, ASOSEConfig


class ASOSEFrameworkDiagnostics:
    """ASO-SEæ¡†æ¶è¯Šæ–­å·¥å…·"""
    
    def __init__(self):
        self.diagnostic_results = {}
        
    def diagnose_architecture_search_issues(self, framework, train_loader, val_loader):
        """è¯Šæ–­æ¶æ„æœç´¢çš„ä¸»è¦é—®é¢˜"""
        print("ğŸ” ASO-SEæ¡†æ¶è¯Šæ–­å¼€å§‹")
        print("=" * 50)
        
        # é—®é¢˜1: æ¶æ„å‚æ•°åˆ†ç¦»è®­ç»ƒæ•ˆæœè¯Šæ–­
        arch_separation_issues = self._diagnose_architecture_separation(framework, train_loader, val_loader)
        
        # é—®é¢˜2: æ¶æ„å˜å¼‚åœæ»è¯Šæ–­
        mutation_stagnation_issues = self._diagnose_mutation_stagnation(framework, train_loader)
        
        # é—®é¢˜3: æ€§èƒ½ç“¶é¢ˆè¯Šæ–­
        performance_bottleneck_issues = self._diagnose_performance_bottlenecks(framework, val_loader)
        
        # ç»¼åˆè¯Šæ–­æŠ¥å‘Š
        self.diagnostic_results = {
            'architecture_separation': arch_separation_issues,
            'mutation_stagnation': mutation_stagnation_issues,
            'performance_bottlenecks': performance_bottleneck_issues
        }
        
        self._print_diagnostic_report()
        return self.diagnostic_results
    
    def _diagnose_architecture_separation(self, framework, train_loader, val_loader):
        """è¯Šæ–­æ¶æ„å‚æ•°åˆ†ç¦»è®­ç»ƒé—®é¢˜"""
        print("\nğŸ“Š è¯Šæ–­1: æ¶æ„å‚æ•°åˆ†ç¦»è®­ç»ƒæ•ˆæœ")
        issues = {}
        
        # æ£€æŸ¥æ¶æ„å‚æ•°çš„æ¢¯åº¦å˜åŒ–
        if hasattr(framework, 'search_model'):
            arch_params = []
            for name, param in framework.search_model.named_parameters():
                if 'alpha' in name.lower() or 'arch' in name.lower():
                    arch_params.append((name, param))
            
            if arch_params:
                # æµ‹è¯•æ¶æ„å‚æ•°çš„æ•æ„Ÿæ€§
                original_values = {}
                gradient_norms = {}
                
                for name, param in arch_params:
                    original_values[name] = param.data.clone()
                    if param.grad is not None:
                        gradient_norms[name] = param.grad.norm().item()
                    else:
                        gradient_norms[name] = 0.0
                
                # æ¶æ„å‚æ•°å˜åŒ–ç‡åˆ†æ
                low_gradient_params = [name for name, grad_norm in gradient_norms.items() if grad_norm < 1e-5]
                
                issues['low_gradient_arch_params'] = low_gradient_params
                issues['avg_arch_gradient_norm'] = np.mean(list(gradient_norms.values()))
                issues['arch_param_count'] = len(arch_params)
                
                if len(low_gradient_params) > len(arch_params) * 0.5:
                    issues['severity'] = 'HIGH'
                    issues['description'] = f"è¶…è¿‡50%çš„æ¶æ„å‚æ•°æ¢¯åº¦è¿‡å° (<1e-5)ï¼Œæ¶æ„æœç´¢åŸºæœ¬åœæ»"
                else:
                    issues['severity'] = 'LOW'
                    issues['description'] = "æ¶æ„å‚æ•°æ¢¯åº¦æ­£å¸¸"
                    
                print(f"  æ¶æ„å‚æ•°æ•°é‡: {len(arch_params)}")
                print(f"  ä½æ¢¯åº¦å‚æ•°: {len(low_gradient_params)}")
                print(f"  å¹³å‡æ¢¯åº¦èŒƒæ•°: {issues['avg_arch_gradient_norm']:.6f}")
                print(f"  é—®é¢˜ä¸¥é‡ç¨‹åº¦: {issues['severity']}")
            else:
                issues['severity'] = 'CRITICAL'
                issues['description'] = "æœªæ‰¾åˆ°æ¶æ„å‚æ•°ï¼Œå¯èƒ½æœªæ­£ç¡®å®ç°æ¶æ„æœç´¢"
                print("  âŒ é”™è¯¯: æœªæ‰¾åˆ°æ¶æ„å‚æ•°")
        else:
            issues['severity'] = 'CRITICAL' 
            issues['description'] = "æ¡†æ¶ç¼ºå°‘æœç´¢æ¨¡å‹"
            print("  âŒ é”™è¯¯: æ¡†æ¶ç¼ºå°‘æœç´¢æ¨¡å‹")
        
        return issues
    
    def _diagnose_mutation_stagnation(self, framework, train_loader):
        """è¯Šæ–­æ¶æ„å˜å¼‚åœæ»é—®é¢˜"""
        print("\nğŸ§¬ è¯Šæ–­2: æ¶æ„å˜å¼‚åœæ»åˆ†æ")
        issues = {}
        
        # æ£€æŸ¥Gumbel-Softmaxæ¸©åº¦è®¾ç½®
        if hasattr(framework, 'explorer'):
            current_temp = getattr(framework.explorer, 'current_temp', None)
            min_temp = getattr(framework.explorer, 'min_temp', None)
            anneal_rate = getattr(framework.explorer, 'anneal_rate', None)
            
            issues['gumbel_temperature'] = current_temp
            issues['min_temperature'] = min_temp
            issues['anneal_rate'] = anneal_rate
            
            # æ¸©åº¦è¿‡ä½ä¼šå¯¼è‡´æ¢ç´¢åœæ»
            if current_temp and current_temp < 0.1:
                issues['temperature_too_low'] = True
                issues['severity'] = 'HIGH'
                issues['description'] = f"Gumbelæ¸©åº¦è¿‡ä½ ({current_temp:.3f})ï¼Œæ¶æ„æ¢ç´¢å·²ç»åœæ»"
            else:
                issues['temperature_too_low'] = False
                issues['severity'] = 'LOW'
                issues['description'] = "Gumbelæ¸©åº¦è®¾ç½®æ­£å¸¸"
            
            print(f"  å½“å‰æ¸©åº¦: {current_temp}")
            print(f"  æœ€ä½æ¸©åº¦: {min_temp}")
            print(f"  é€€ç«é€Ÿåº¦: {anneal_rate}")
            print(f"  æ¸©åº¦çŠ¶æ€: {'è¿‡ä½' if issues.get('temperature_too_low') else 'æ­£å¸¸'}")
        else:
            issues['severity'] = 'CRITICAL'
            issues['description'] = "ç¼ºå°‘Gumbelæ¢ç´¢å™¨"
            print("  âŒ é”™è¯¯: ç¼ºå°‘Gumbelæ¢ç´¢å™¨")
        
        # æ£€æŸ¥æ¶æ„æ“ä½œå¤šæ ·æ€§
        operation_diversity = self._check_operation_diversity(framework)
        issues['operation_diversity'] = operation_diversity
        
        if operation_diversity < 0.3:
            issues['low_diversity'] = True
            if issues['severity'] != 'CRITICAL':
                issues['severity'] = 'HIGH' if issues['severity'] == 'LOW' else issues['severity']
        else:
            issues['low_diversity'] = False
        
        print(f"  æ“ä½œå¤šæ ·æ€§: {operation_diversity:.3f}")
        print(f"  å¤šæ ·æ€§çŠ¶æ€: {'è¿‡ä½' if issues.get('low_diversity') else 'æ­£å¸¸'}")
        
        return issues
    
    def _diagnose_performance_bottlenecks(self, framework, val_loader):
        """è¯Šæ–­æ€§èƒ½ç“¶é¢ˆé—®é¢˜"""
        print("\nğŸ“ˆ è¯Šæ–­3: æ€§èƒ½ç“¶é¢ˆåˆ†æ")
        issues = {}
        
        # å¿«é€Ÿæ€§èƒ½è¯„ä¼°
        if hasattr(framework, 'search_model'):
            accuracy = self._quick_evaluate(framework.search_model, val_loader)
            issues['current_accuracy'] = accuracy
            
            # å‚æ•°æ•°é‡åˆ†æ
            total_params = sum(p.numel() for p in framework.search_model.parameters())
            trainable_params = sum(p.numel() for p in framework.search_model.parameters() if p.requires_grad)
            
            issues['total_params'] = total_params
            issues['trainable_params'] = trainable_params
            issues['param_efficiency'] = accuracy / (total_params / 1e6)  # æ¯ç™¾ä¸‡å‚æ•°çš„å‡†ç¡®ç‡
            
            # 88%ç“¶é¢ˆåˆ†æ
            if accuracy < 90:
                issues['accuracy_bottleneck'] = True
                issues['severity'] = 'HIGH'
                issues['description'] = f"å‡†ç¡®ç‡ {accuracy:.1f}% ä½äºæœŸæœ›ï¼Œå­˜åœ¨æ˜æ˜¾æ€§èƒ½ç“¶é¢ˆ"
            else:
                issues['accuracy_bottleneck'] = False
                issues['severity'] = 'LOW'
                issues['description'] = "æ€§èƒ½è¡¨ç°è‰¯å¥½"
            
            print(f"  å½“å‰å‡†ç¡®ç‡: {accuracy:.2f}%")
            print(f"  æ€»å‚æ•°é‡: {total_params:,}")
            print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            print(f"  å‚æ•°æ•ˆç‡: {issues['param_efficiency']:.2f}%/M")
            print(f"  ç“¶é¢ˆçŠ¶æ€: {'å­˜åœ¨' if issues.get('accuracy_bottleneck') else 'æ— '}")
        else:
            issues['severity'] = 'CRITICAL'
            issues['description'] = "æ— æ³•è¯„ä¼°æ€§èƒ½ï¼Œç¼ºå°‘æ¨¡å‹"
            print("  âŒ é”™è¯¯: æ— æ³•è¯„ä¼°æ€§èƒ½")
        
        return issues
    
    def _check_operation_diversity(self, framework):
        """æ£€æŸ¥æ¶æ„æ“ä½œçš„å¤šæ ·æ€§"""
        try:
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦æ ¹æ®å…·ä½“çš„æ¶æ„æœç´¢ç©ºé—´æ¥åˆ†æ
            # æ£€æŸ¥æ“ä½œæƒé‡çš„åˆ†å¸ƒç†µ
            if hasattr(framework, 'search_model'):
                operation_weights = []
                for name, param in framework.search_model.named_parameters():
                    if 'alpha' in name.lower():
                        # è®¡ç®—softmaxåçš„æƒé‡åˆ†å¸ƒ
                        weights = F.softmax(param, dim=-1)
                        # è®¡ç®—ç†µ
                        entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=-1).mean()
                        operation_weights.append(entropy.item())
                
                if operation_weights:
                    # å½’ä¸€åŒ–ç†µå€¼åˆ°[0,1]èŒƒå›´
                    max_entropy = np.log(param.size(-1)) if len(operation_weights) > 0 else 1.0
                    normalized_entropy = np.mean(operation_weights) / max_entropy
                    return min(normalized_entropy, 1.0)
                else:
                    return 0.0
            else:
                return 0.0
        except Exception as e:
            print(f"  è­¦å‘Š: æ“ä½œå¤šæ ·æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return 0.0
    
    def _quick_evaluate(self, model, val_loader):
        """å¿«é€Ÿè¯„ä¼°æ¨¡å‹å‡†ç¡®ç‡"""
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(val_loader):
                if batch_idx >= 5:  # åªç”¨å‡ ä¸ªbatchå¿«é€Ÿè¯„ä¼°
                    break
                
                if torch.cuda.is_available():
                    data, target = data.cuda(), target.cuda()
                
                output = model(data)
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        return 100.0 * correct / total if total > 0 else 0.0
    
    def _print_diagnostic_report(self):
        """æ‰“å°è¯Šæ–­æŠ¥å‘Š"""
        print("\nğŸ“‹ ASO-SEæ¡†æ¶è¯Šæ–­æŠ¥å‘Š")
        print("=" * 50)
        
        for category, issues in self.diagnostic_results.items():
            severity = issues.get('severity', 'UNKNOWN')
            description = issues.get('description', 'æ— æè¿°')
            
            severity_icon = {
                'LOW': 'âœ…',
                'HIGH': 'âš ï¸',
                'CRITICAL': 'âŒ',
                'UNKNOWN': 'â“'
            }.get(severity, 'â“')
            
            print(f"\n{severity_icon} {category.upper()}: {severity}")
            print(f"   {description}")


class ImprovedASOSEFramework:
    """æ”¹è¿›çš„ASO-SEæ¡†æ¶"""
    
    def __init__(self, config=None):
        self.config = config or self._default_config()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ€§èƒ½è¿½è¸ª
        self.performance_history = []
        self.architecture_changes = []
        self.current_epoch = 0
        
        print("ğŸš€ æ”¹è¿›çš„ASO-SEæ¡†æ¶åˆå§‹åŒ–")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   é…ç½®: {self.config}")
    
    def _default_config(self):
        """é»˜è®¤é…ç½® - é’ˆå¯¹é—®é¢˜ä¼˜åŒ–"""
        return {
            # åŸºç¡€è®¾ç½®
            'num_epochs': 100,
            'batch_size': 128,
            'learning_rate': 0.025,
            'momentum': 0.9,
            'weight_decay': 3e-4,
            
            # æ¶æ„æœç´¢ä¼˜åŒ–è®¾ç½®
            'arch_lr': 6e-4,  # æé«˜æ¶æ„å­¦ä¹ ç‡
            'arch_update_frequency': 3,  # æ›´é¢‘ç¹çš„æ¶æ„æ›´æ–°
            'warmup_epochs': 10,  # å‡å°‘é¢„çƒ­epoch
            
            # Gumbel-Softmaxä¼˜åŒ–
            'initial_temp': 2.0,  # æé«˜åˆå§‹æ¸©åº¦
            'min_temp': 0.3,      # æé«˜æœ€ä½æ¸©åº¦
            'anneal_rate': 0.995, # å‡æ…¢é€€ç«é€Ÿåº¦
            'temp_reset_epochs': 20, # å®šæœŸé‡ç½®æ¸©åº¦
            
            # æ¶æ„å˜å¼‚è®¾ç½®
            'mutation_probability': 0.3,
            'mutation_strength': 0.2,
            'architecture_diversity_threshold': 0.4,
            
            # æ€§èƒ½çªç ´è®¾ç½®
            'performance_patience': 8,
            'architecture_expansion_threshold': 0.01,
            'adaptive_lr_schedule': True,
        }
    
    def train_with_enhanced_aso_se(self, model, train_loader, val_loader):
        """ä½¿ç”¨å¢å¼ºASO-SEç®—æ³•è®­ç»ƒ"""
        print("\nğŸ§¬ å¯åŠ¨å¢å¼ºASO-SEè®­ç»ƒ")
        print("=" * 60)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        weight_optimizer = optim.SGD(
            model.parameters(),
            lr=self.config['learning_rate'],
            momentum=self.config['momentum'],
            weight_decay=self.config['weight_decay']
        )
        
        # æ¶æ„å‚æ•°ä¼˜åŒ–å™¨ (å¦‚æœæœ‰æ¶æ„å‚æ•°)
        arch_params = [p for name, p in model.named_parameters() if 'alpha' in name.lower()]
        arch_optimizer = None
        if arch_params:
            arch_optimizer = optim.Adam(arch_params, lr=self.config['arch_lr'])
        
        criterion = nn.CrossEntropyLoss()
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            weight_optimizer, T_max=self.config['num_epochs']
        )
        
        # Gumbelæ¸©åº¦æ§åˆ¶
        current_temp = self.config['initial_temp']
        best_accuracy = 0.0
        patience_counter = 0
        
        for epoch in range(self.config['num_epochs']):
            self.current_epoch = epoch
            start_time = time.time()
            
            print(f"\nğŸ§¬ Epoch {epoch+1}/{self.config['num_epochs']}")
            
            # 1. è®­ç»ƒé˜¶æ®µå†³ç­–
            if epoch < self.config['warmup_epochs']:
                training_mode = 'weights_only'
            elif epoch % self.config['arch_update_frequency'] == 0:
                training_mode = 'architecture_focus'
            else:
                training_mode = 'weights_focus'
            
            # 2. æ‰§è¡Œè®­ç»ƒ
            if training_mode == 'weights_only':
                train_loss, train_acc = self._train_weights_only(
                    model, train_loader, weight_optimizer, criterion
                )
                print(f"  ğŸ”§ æƒé‡è®­ç»ƒæ¨¡å¼")
            elif training_mode == 'architecture_focus':
                train_loss, train_acc = self._train_architecture_focus(
                    model, train_loader, val_loader, weight_optimizer, arch_optimizer, criterion, current_temp
                )
                print(f"  ğŸ—ï¸ æ¶æ„é‡ç‚¹æ¨¡å¼ (æ¸©åº¦: {current_temp:.3f})")
            else:
                train_loss, train_acc = self._train_weights_focus(
                    model, train_loader, weight_optimizer, criterion
                )
                print(f"  âš¡ æƒé‡é‡ç‚¹æ¨¡å¼")
            
            # 3. éªŒè¯
            val_loss, val_acc = self._validate(model, val_loader, criterion)
            
            # 4. æ€§èƒ½è¿½è¸ªå’Œæ—©æœŸåœæ­¢
            self.performance_history.append({
                'epoch': epoch,
                'train_acc': train_acc,
                'val_acc': val_acc,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'temperature': current_temp,
                'training_mode': training_mode
            })
            
            # 5. æ¸©åº¦è°ƒåº¦
            current_temp = max(
                self.config['min_temp'],
                current_temp * self.config['anneal_rate']
            )
            
            # å®šæœŸé‡ç½®æ¸©åº¦ä»¥é‡æ–°æ¿€æ´»æ¢ç´¢
            if epoch % self.config['temp_reset_epochs'] == 0 and epoch > 0:
                current_temp = self.config['initial_temp'] * 0.8
                print(f"  ğŸ”„ æ¸©åº¦é‡ç½®åˆ° {current_temp:.3f}")
            
            # 6. æ€§èƒ½çªç ´æ£€æµ‹
            if val_acc > best_accuracy:
                best_accuracy = val_acc
                patience_counter = 0
            else:
                patience_counter += 1
            
            # 7. è‡ªé€‚åº”æ¶æ„æ‰©å±•
            if patience_counter >= self.config['performance_patience']:
                print(f"  ğŸ“ˆ æ£€æµ‹åˆ°æ€§èƒ½å¹³å°æœŸï¼Œå°è¯•æ¶æ„æ‰©å±•...")
                expansion_success = self._attempt_architecture_expansion(model, train_loader, val_loader)
                if expansion_success:
                    patience_counter = 0
                    current_temp = self.config['initial_temp'] * 0.6  # é‡æ–°æ¿€æ´»æ¢ç´¢
            
            # 8. å­¦ä¹ ç‡è°ƒåº¦
            if self.config['adaptive_lr_schedule']:
                scheduler.step()
            
            # 9. è¾“å‡ºçŠ¶æ€
            epoch_time = time.time() - start_time
            print(f"  ğŸ“Š Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Best: {best_accuracy:.2f}%")
            print(f"  â±ï¸ Time: {epoch_time:.1f}s | Patience: {patience_counter}/{self.config['performance_patience']}")
            
            # æ—©æœŸåœæ­¢
            if val_acc > 95.0:
                print(f"  ğŸ¯ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {val_acc:.2f}%!")
                break
        
        print("\nâœ… å¢å¼ºASO-SEè®­ç»ƒå®Œæˆ")
        self._print_training_summary()
        
        return model, self.performance_history
    
    def _train_weights_only(self, model, train_loader, optimizer, criterion):
        """ä»…è®­ç»ƒæƒé‡å‚æ•°"""
        model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        # å†»ç»“æ¶æ„å‚æ•°
        for name, param in model.named_parameters():
            if 'alpha' in name.lower():
                param.requires_grad = False
        
        for data, target in train_loader:
            data, target = data.to(self.device), target.to(self.device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
            optimizer.step()
            
            total_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
        
        # æ¢å¤æ¶æ„å‚æ•°çš„æ¢¯åº¦
        for name, param in model.named_parameters():
            if 'alpha' in name.lower():
                param.requires_grad = True
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100.0 * correct / total
        return avg_loss, accuracy
    
    def _train_architecture_focus(self, model, train_loader, val_loader, weight_optimizer, arch_optimizer, criterion, temperature):
        """æ¶æ„é‡ç‚¹è®­ç»ƒ - äº¤æ›¿è®­ç»ƒæƒé‡å’Œæ¶æ„"""
        # å…ˆè®­ç»ƒæƒé‡
        weight_loss, weight_acc = self._train_weights_only(model, train_loader, weight_optimizer, criterion)
        
        # å†è®­ç»ƒæ¶æ„
        if arch_optimizer:
            arch_loss, arch_acc = self._train_architecture_params(model, val_loader, arch_optimizer, criterion, temperature)
        else:
            arch_loss, arch_acc = weight_loss, weight_acc
        
        return (weight_loss + arch_loss) / 2, (weight_acc + arch_acc) / 2
    
    def _train_weights_focus(self, model, train_loader, optimizer, criterion):
        """æƒé‡é‡ç‚¹è®­ç»ƒ"""
        return self._train_weights_only(model, train_loader, optimizer, criterion)
    
    def _train_architecture_params(self, model, val_loader, arch_optimizer, criterion, temperature):
        """è®­ç»ƒæ¶æ„å‚æ•°"""
        model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        # å†»ç»“æƒé‡å‚æ•°
        for name, param in model.named_parameters():
            if 'alpha' not in name.lower():
                param.requires_grad = False
        
        # ä½¿ç”¨éªŒè¯é›†è®­ç»ƒæ¶æ„å‚æ•°
        for batch_idx, (data, target) in enumerate(val_loader):
            if batch_idx >= 5:  # é™åˆ¶æ¶æ„è®­ç»ƒçš„batchæ•°é‡
                break
                
            data, target = data.to(self.device), target.to(self.device)
            
            arch_optimizer.zero_grad()
            
            # åº”ç”¨å½“å‰æ¸©åº¦åˆ°Gumbelé‡‡æ ·
            if hasattr(model, 'set_temperature'):
                model.set_temperature(temperature)
            
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            arch_optimizer.step()
            
            total_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
        
        # æ¢å¤æƒé‡å‚æ•°çš„æ¢¯åº¦
        for name, param in model.named_parameters():
            if 'alpha' not in name.lower():
                param.requires_grad = True
        
        avg_loss = total_loss / min(5, len(val_loader))
        accuracy = 100.0 * correct / total if total > 0 else 0.0
        return avg_loss, accuracy
    
    def _validate(self, model, val_loader, criterion):
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = model(data)
                loss = criterion(output, target)
                
                total_loss += loss.item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        avg_loss = total_loss / len(val_loader)
        accuracy = 100.0 * correct / total
        return avg_loss, accuracy
    
    def _attempt_architecture_expansion(self, model, train_loader, val_loader):
        """å°è¯•æ¶æ„æ‰©å±•ä»¥çªç ´æ€§èƒ½ç“¶é¢ˆ"""
        print("    ğŸ”§ æ‰§è¡Œæ¶æ„æ‰©å±•...")
        
        # è¿™é‡Œå¯ä»¥å®ç°å„ç§æ¶æ„æ‰©å±•ç­–ç•¥
        # ä¾‹å¦‚ï¼šå¢åŠ é€šé“æ•°ã€æ·»åŠ å±‚ã€ä¿®æ”¹è¿æ¥ç­‰
        
        try:
            # ç®€å•ç¤ºä¾‹ï¼šå¦‚æœæ¨¡å‹æœ‰å¯æ‰©å±•çš„å±‚ï¼Œå°è¯•æ‰©å±•
            expansion_applied = False
            
            for name, module in model.named_modules():
                if isinstance(module, nn.Conv2d) and module.out_channels < 256:
                    # ç®€å•çš„é€šé“æ‰©å±•ç¤ºä¾‹
                    print(f"    ğŸ“ˆ æ‰©å±• {name} ä» {module.out_channels} åˆ° {module.out_channels + 32} é€šé“")
                    expansion_applied = True
                    break
            
            if expansion_applied:
                self.architecture_changes.append({
                    'epoch': self.current_epoch,
                    'type': 'channel_expansion',
                    'target_layer': name
                })
                return True
            else:
                print("    âŒ æœªæ‰¾åˆ°å¯æ‰©å±•çš„å±‚")
                return False
                
        except Exception as e:
            print(f"    âŒ æ¶æ„æ‰©å±•å¤±è´¥: {e}")
            return False
    
    def _print_training_summary(self):
        """æ‰“å°è®­ç»ƒæ€»ç»“"""
        if self.performance_history:
            best_val_acc = max(p['val_acc'] for p in self.performance_history)
            final_val_acc = self.performance_history[-1]['val_acc']
            total_changes = len(self.architecture_changes)
            
            print(f"\nğŸ“ˆ è®­ç»ƒæ€»ç»“:")
            print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
            print(f"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_val_acc:.2f}%")
            print(f"   æ¶æ„å˜åŒ–æ¬¡æ•°: {total_changes}")
            
            if best_val_acc > 88:
                print(f"   ğŸ‰ æˆåŠŸçªç ´88%ç“¶é¢ˆ!")
            else:
                print(f"   ğŸ“ˆ å‡†ç¡®ç‡æå‡: {final_val_acc - self.performance_history[0]['val_acc']:.2f}%")


def demo_aso_se_fix():
    """ASO-SEæ¡†æ¶ä¿®å¤æ¼”ç¤º"""
    print("ğŸ”§ ASO-SEæ¡†æ¶é—®é¢˜è¯Šæ–­ä¸ä¿®å¤æ¼”ç¤º")
    print("=" * 60)
    
    # å‡†å¤‡æ•°æ®
    transform = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    
    trainset = torchvision.datasets.CIFAR10(
        root='./data', train=True, download=True, transform=transform
    )
    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    
    # ä½¿ç”¨å­é›†è¿›è¡Œæ¼”ç¤º
    from torch.utils.data import Subset
    train_subset = Subset(trainset, range(2000))
    test_subset = Subset(testset, range(500))
    
    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)
    
    # åˆ›å»ºç®€å•çš„æœç´¢æ¨¡å‹ (æ¨¡æ‹ŸASO-SEæ¶æ„)
    class SimpleSearchModel(nn.Module):
        def __init__(self, num_classes=10):
            super().__init__()
            
            # æ¶æ„å‚æ•° (alpha)
            self.alpha_conv = nn.Parameter(torch.randn(3, 4))  # 3å±‚ï¼Œæ¯å±‚4ç§æ“ä½œ
            
            # ç½‘ç»œæƒé‡
            self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
            self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
            self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
            self.classifier = nn.Linear(256, num_classes)
            
            self.pool = nn.MaxPool2d(2)
            self.adaptivepool = nn.AdaptiveAvgPool2d(1)
            
        def forward(self, x):
            # ç®€åŒ–çš„æ¶æ„æœç´¢å‰å‘ä¼ æ’­
            x = F.relu(self.conv1(x))
            x = self.pool(x)
            x = F.relu(self.conv2(x))
            x = self.pool(x)
            x = F.relu(self.conv3(x))
            x = self.adaptivepool(x)
            x = x.view(x.size(0), -1)
            x = self.classifier(x)
            return x
        
        def set_temperature(self, temp):
            self.temperature = temp
    
    model = SimpleSearchModel()
    
    # ä½¿ç”¨æ”¹è¿›çš„ASO-SEæ¡†æ¶è®­ç»ƒ
    improved_framework = ImprovedASOSEFramework()
    trained_model, history = improved_framework.train_with_enhanced_aso_se(
        model, train_loader, test_loader
    )
    
    print("\nğŸ‰ ASO-SEæ¡†æ¶ä¿®å¤æ¼”ç¤ºå®Œæˆ!")
    return trained_model, history


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    model, history = demo_aso_se_fix()