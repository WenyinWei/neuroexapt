#!/usr/bin/env python3
"""
Enhanced Dynamic Neural Morphogenesis (DNM) Framework - å¢å¼ºç‰ˆ

ğŸ§¬ æ ¸å¿ƒæ”¹è¿›ï¼š
1. å¤šç»´åº¦ç“¶é¢ˆåˆ†æ - æ·±åº¦ã€å®½åº¦ã€ä¿¡æ¯æµã€æ¢¯åº¦æµã€å®¹é‡ç“¶é¢ˆ
2. é«˜çº§å½¢æ€å‘ç”Ÿç­–ç•¥ - ä¸²è¡Œåˆ†è£‚ã€å¹¶è¡Œåˆ†è£‚ã€æ··åˆåˆ†è£‚
3. æ™ºèƒ½å†³ç­–åˆ¶å®š - åŸºäºç“¶é¢ˆç±»å‹çš„æœ€ä¼˜ç­–ç•¥é€‰æ‹©
4. æ€§èƒ½å¯¼å‘ - è¿½æ±‚æ›´é«˜çš„å‡†ç¡®ç‡çªç ´

ğŸ¯ ç›®æ ‡ï¼šå®ç°90%+çš„å‡†ç¡®ç‡ï¼Œæ¢ç´¢ç½‘ç»œç»“æ„çš„æ— é™å¯èƒ½
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from abc import ABC, abstractmethod
import math
from collections import defaultdict, deque
import copy
import traceback
import time
import os

# å¯¼å…¥é«˜çº§å½¢æ€å‘ç”Ÿæ¨¡å—
from .advanced_morphogenesis import (
    AdvancedBottleneckAnalyzer,
    AdvancedMorphogenesisExecutor,
    IntelligentMorphogenesisDecisionMaker,
    MorphogenesisType,
    MorphogenesisDecision
)

class ConfigurableLogger:
    """å¯é…ç½®çš„é«˜æ€§èƒ½æ—¥å¿—ç³»ç»Ÿï¼Œæ›¿ä»£ANSIå½©è‰²æ‰“å°"""
    
    def __init__(self, name: str = "neuroexapt", level: str = "INFO", enable_console: bool = True):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(getattr(logging, level.upper()))
        
        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
        if not self.logger.handlers:
            # æ§åˆ¶å°å¤„ç†å™¨
            if enable_console:
                console_handler = logging.StreamHandler()
                console_formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    datefmt='%H:%M:%S'
                )
                console_handler.setFormatter(console_formatter)
                self.logger.addHandler(console_handler)
            
            # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
            log_file = os.environ.get('NEUROEXAPT_LOG_FILE')
            if log_file:
                file_handler = logging.FileHandler(log_file)
                file_formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
                )
                file_handler.setFormatter(file_formatter)
                self.logger.addHandler(file_handler)
        
        self.section_stack = []
        
    def debug(self, message: str, *args, **kwargs):
        """è®°å½•è°ƒè¯•ä¿¡æ¯"""
        if self.logger.isEnabledFor(logging.DEBUG):
            indent = "  " * len(self.section_stack)
            self.logger.debug(f"{indent}{message}", *args, **kwargs)
    
    def info(self, message: str, *args, **kwargs):
        """è®°å½•ä¿¡æ¯"""
        if self.logger.isEnabledFor(logging.INFO):
            indent = "  " * len(self.section_stack)
            self.logger.info(f"{indent}{message}", *args, **kwargs)
    
    def warning(self, message: str, *args, **kwargs):
        """è®°å½•è­¦å‘Š"""
        if self.logger.isEnabledFor(logging.WARNING):
            indent = "  " * len(self.section_stack)
            self.logger.warning(f"{indent}{message}", *args, **kwargs)
    
    def error(self, message: str, *args, **kwargs):
        """è®°å½•é”™è¯¯"""
        if self.logger.isEnabledFor(logging.ERROR):
            indent = "  " * len(self.section_stack)
            self.logger.error(f"{indent}{message}", *args, **kwargs)
    
    def success(self, message: str, *args, **kwargs):
        """è®°å½•æˆåŠŸä¿¡æ¯ï¼ˆä½¿ç”¨INFOçº§åˆ«ï¼‰"""
        if self.logger.isEnabledFor(logging.INFO):
            indent = "  " * len(self.section_stack)
            self.logger.info(f"{indent}âœ… {message}", *args, **kwargs)
    
    def enter_section(self, section_name: str):
        """è¿›å…¥æ–°çš„æ—¥å¿—åŒºåŸŸ"""
        if self.logger.isEnabledFor(logging.DEBUG):
            indent = "  " * len(self.section_stack)
            self.logger.debug(f"{indent}ğŸ” è¿›å…¥ {section_name}")
        self.section_stack.append(section_name)
    
    def exit_section(self, section_name: str):
        """é€€å‡ºæ—¥å¿—åŒºåŸŸ"""
        if self.section_stack and self.section_stack[-1] == section_name:
            self.section_stack.pop()
        if self.logger.isEnabledFor(logging.DEBUG):
            indent = "  " * len(self.section_stack)
            self.logger.debug(f"{indent}âœ… å®Œæˆ {section_name}")
    
    def log_tensor_info(self, tensor: torch.Tensor, name: str):
        """è®°å½•å¼ é‡ä¿¡æ¯"""
        if not self.logger.isEnabledFor(logging.DEBUG):
            return
            
        if tensor is None:
            self.warning(f"âŒ {name}: None")
            return
        
        device_info = f"({tensor.device})" if hasattr(tensor, 'device') else ""
        self.debug(f"ğŸ“Š {name}: shape={list(tensor.shape)}, dtype={tensor.dtype}, device={device_info}")
    
    def log_model_info(self, model: nn.Module, name: str = "Model"):
        """è®°å½•æ¨¡å‹ä¿¡æ¯"""
        if not self.logger.isEnabledFor(logging.INFO):
            return
            
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        device = next(model.parameters()).device if list(model.parameters()) else "Unknown"
        
        self.info(f"ğŸ§  {name}: æ€»å‚æ•°={total_params:,}, å¯è®­ç»ƒ={trainable_params:,}, è®¾å¤‡={device}")

# å…¨å±€æ—¥å¿—å™¨é…ç½®
_log_level = os.environ.get('NEUROEXAPT_LOG_LEVEL', 'INFO')
_enable_console = os.environ.get('NEUROEXAPT_CONSOLE_LOG', 'true').lower() == 'true'

# åˆ›å»ºå…¨å±€æ—¥å¿—å™¨å®ä¾‹
logger = ConfigurableLogger("neuroexapt.dnm", _log_level, _enable_console)

# ä¿æŒå‘åå…¼å®¹æ€§çš„DebugPrinterç±»
class DebugPrinter:
    """å‘åå…¼å®¹çš„è°ƒè¯•æ‰“å°å™¨ï¼ˆå·²åºŸå¼ƒï¼Œå»ºè®®ä½¿ç”¨loggerï¼‰"""
    
    def __init__(self, enabled: bool = True):
        self.enabled = enabled
        self._logger = logger
        import warnings
        warnings.warn(
            "DebugPrinter is deprecated. Use the global 'logger' instance instead.",
            DeprecationWarning,
            stacklevel=2
        )
    
    def print_debug(self, message: str, level: str = "INFO"):
        if not self.enabled:
            return
        
        level_map = {
            "INFO": self._logger.info,
            "SUCCESS": self._logger.success,
            "WARNING": self._logger.warning,
            "ERROR": self._logger.error,
            "DEBUG": self._logger.debug
        }
        level_map.get(level, self._logger.info)(message)
    
    def enter_section(self, section_name: str):
        if self.enabled:
            self._logger.enter_section(section_name)
    
    def exit_section(self, section_name: str):
        if self.enabled:
            self._logger.exit_section(section_name)
    
    def print_tensor_info(self, tensor: torch.Tensor, name: str):
        if self.enabled:
            self._logger.log_tensor_info(tensor, name)
    
    def print_model_info(self, model: nn.Module, name: str = "Model"):
        if self.enabled:
            self._logger.log_model_info(model, name)

# ä¸ºäº†å‘åå…¼å®¹ä¿ç•™debug_printerå®ä¾‹
debug_printer = DebugPrinter(enabled=True)

@dataclass
class EnhancedMorphogenesisEvent:
    """å¢å¼ºçš„å½¢æ€å‘ç”Ÿäº‹ä»¶è®°å½•"""
    epoch: int
    event_type: str  # 'width_expansion', 'serial_division', 'parallel_division', 'hybrid_division'
    location: str
    trigger_reason: str
    performance_before: float
    performance_after: Optional[float] = None
    parameters_added: int = 0
    complexity_change: float = 0.0
    morphogenesis_type: MorphogenesisType = MorphogenesisType.WIDTH_EXPANSION
    confidence: float = 0.0
    expected_improvement: float = 0.0

class EnhancedInformationTheoryTrigger:
    """å¢å¼ºçš„ä¿¡æ¯è®ºè§¦å‘å™¨"""
    
    def __init__(self, entropy_threshold: float = 0.1, complexity_threshold: float = 0.7):
        self.entropy_threshold = entropy_threshold
        self.complexity_threshold = complexity_threshold
        self.history = deque(maxlen=15)
        
    def should_trigger(self, context: Dict[str, Any]) -> Tuple[bool, str]:
        logger.enter_section("ä¿¡æ¯è®ºè§¦å‘å™¨æ£€æŸ¥")
        
        activations = context.get('activations', {})
        gradients = context.get('gradients', {})
        
        logger.debug(f"è¾“å…¥æ•°æ®: æ¿€æ´»å€¼å±‚æ•°={len(activations)}, æ¢¯åº¦å±‚æ•°={len(gradients)}")
        
        if not activations or not gradients:
            logger.warning("âŒ ç¼ºå°‘æ¿€æ´»å€¼æˆ–æ¢¯åº¦ä¿¡æ¯")
            logger.exit_section("ä¿¡æ¯è®ºè§¦å‘å™¨æ£€æŸ¥")
            return False, "ç¼ºå°‘æ¿€æ´»å€¼æˆ–æ¢¯åº¦ä¿¡æ¯"
            
        # è®¡ç®—ç»¼åˆå¤æ‚åº¦åˆ†æ•°
        complexity_score = self._compute_complexity_score(activations, gradients)
        
        logger.info(f"å¤æ‚åº¦åˆ†æ•°: {complexity_score:.4f} (é˜ˆå€¼: {self.complexity_threshold})")
        
        self.history.append({
            'complexity_score': complexity_score,
            'epoch': context.get('epoch', 0)
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´å¤æ‚çš„ç»“æ„å˜å¼‚
        if complexity_score > self.complexity_threshold:
            logger.success(f"è§¦å‘æ¡ä»¶æ»¡è¶³: {complexity_score:.4f} > {self.complexity_threshold}")
            logger.exit_section("ä¿¡æ¯è®ºè§¦å‘å™¨æ£€æŸ¥")
            return True, f"å¤æ‚åº¦ç“¶é¢ˆæ£€æµ‹ï¼šåˆ†æ•°={complexity_score:.4f}"
            
        logger.info(f"âŒ æœªè¾¾åˆ°è§¦å‘æ¡ä»¶: {complexity_score:.4f} <= {self.complexity_threshold}")
        logger.exit_section("ä¿¡æ¯è®ºè§¦å‘å™¨æ£€æŸ¥")
        return False, "å¤æ‚åº¦æŒ‡æ ‡æœªè¾¾åˆ°è§¦å‘æ¡ä»¶"
    
    def _compute_complexity_score(self, activations: Dict[str, torch.Tensor], 
                                gradients: Dict[str, torch.Tensor]) -> float:
        """è®¡ç®—ç½‘ç»œå¤æ‚åº¦åˆ†æ•°"""
        logger.enter_section("å¤æ‚åº¦åˆ†æ•°è®¡ç®—")
        scores = []
        
        for name, activation in activations.items():
            if name not in gradients or gradients[name] is None:
                logger.warning(f"âš ï¸ è·³è¿‡å±‚ {name}: ç¼ºå°‘æ¢¯åº¦ä¿¡æ¯")
                continue
                
            gradient = gradients[name]
            logger.log_tensor_info(activation, f"æ¿€æ´»å€¼[{name}]")
            logger.log_tensor_info(gradient, f"æ¢¯åº¦[{name}]")
            
            # 1. ä¿¡æ¯ç†µåˆ†æ
            entropy = self._compute_entropy(activation)
            logger.debug(f"ä¿¡æ¯ç†µ[{name}]: {entropy:.4f}")
            
            # 2. æ¢¯åº¦å¤æ‚åº¦
            grad_complexity = self._compute_gradient_complexity(gradient)
            logger.debug(f"æ¢¯åº¦å¤æ‚åº¦[{name}]: {grad_complexity:.4f}")
            
            # 3. æ¿€æ´»æ¨¡å¼å¤æ‚åº¦
            activation_complexity = self._compute_activation_complexity(activation)
            logger.debug(f"æ¿€æ´»å¤æ‚åº¦[{name}]: {activation_complexity:.4f}")
            
            # ç»¼åˆåˆ†æ•°
            layer_score = 0.4 * entropy + 0.3 * grad_complexity + 0.3 * activation_complexity
            scores.append(layer_score)
            logger.debug(f"å±‚åˆ†æ•°[{name}]: {layer_score:.4f}")
        
        final_score = np.mean(scores) if scores else 0.0
        logger.info(f"æœ€ç»ˆå¤æ‚åº¦åˆ†æ•°: {final_score:.4f} (å…±{len(scores)}å±‚)")
        logger.exit_section("å¤æ‚åº¦åˆ†æ•°è®¡ç®—")
        return final_score
    
    def _compute_entropy(self, activation: torch.Tensor) -> float:
        """è®¡ç®—æ¿€æ´»å€¼ç†µ"""
        if activation.numel() == 0:
            return 0.0
            
        activation_flat = activation.flatten()
        activation_abs = torch.abs(activation_flat) + 1e-8
        probs = activation_abs / torch.sum(activation_abs)
        
        entropy = -torch.sum(probs * torch.log(probs + 1e-8))
        # å½’ä¸€åŒ–åˆ° [0, 1]
        max_entropy = math.log(len(probs))
        return min(entropy.item() / max_entropy, 1.0) if max_entropy > 0 else 0.0
    
    def _compute_gradient_complexity(self, gradient: torch.Tensor) -> float:
        """è®¡ç®—æ¢¯åº¦å¤æ‚åº¦"""
        if gradient is None or gradient.numel() == 0:
            return 0.0
            
        grad_flat = gradient.flatten()
        
        # æ¢¯åº¦çš„æ ‡å‡†å·®/å‡å€¼æ¯”ç‡
        grad_std = torch.std(grad_flat)
        grad_mean = torch.mean(torch.abs(grad_flat))
        
        if grad_mean > 1e-8:
            complexity = grad_std / grad_mean
            return min(complexity.item(), 1.0)
        else:
            return 0.0
    
    def _compute_activation_complexity(self, activation: torch.Tensor) -> float:
        """è®¡ç®—æ¿€æ´»æ¨¡å¼å¤æ‚åº¦"""
        if activation.numel() == 0 or len(activation.shape) < 2:
            return 0.0
            
        # è®¡ç®—æ¿€æ´»æ¨¡å¼çš„å˜å¼‚ç³»æ•°
        activation_flat = activation.view(activation.shape[0], -1)
        
        # æ‰¹æ¬¡é—´çš„å˜å¼‚æ€§
        batch_means = torch.mean(activation_flat, dim=1)
        batch_std = torch.std(batch_means)
        batch_mean_avg = torch.mean(batch_means)
        
        if batch_mean_avg > 1e-8:
            complexity = batch_std / batch_mean_avg
            return min(complexity.item(), 1.0)
        else:
            return 0.0

class EnhancedBiologicalPrinciplesTrigger:
    """å¢å¼ºçš„ç”Ÿç‰©å­¦åŸç†è§¦å‘å™¨"""
    
    def __init__(self, maturation_threshold: float = 0.6):
        self.maturation_threshold = maturation_threshold
        self.development_history = deque(maxlen=20)
        
    def should_trigger(self, context: Dict[str, Any]) -> Tuple[bool, str]:
        """æ£€æµ‹æ˜¯å¦å¤„äºå…³é”®å‘è‚²æœŸ"""
        logger.enter_section("ç”Ÿç‰©å­¦åŸç†è§¦å‘å™¨æ£€æŸ¥")
        
        performance_history = context.get('performance_history', [])
        epoch = context.get('epoch', 0)
        
        debug_printer.print_debug(f"å½“å‰epoch: {epoch}, æ€§èƒ½å†å²é•¿åº¦: {len(performance_history)}", "DEBUG")
        
        if len(performance_history) < 10:
            logger.warning("âŒ æ€§èƒ½å†å²æ•°æ®ä¸è¶³ (éœ€è¦è‡³å°‘10ä¸ªæ•°æ®ç‚¹)")
            logger.exit_section("ç”Ÿç‰©å­¦åŸç†è§¦å‘å™¨æ£€æŸ¥")
            return False, "æ€§èƒ½å†å²æ•°æ®ä¸è¶³"
        
        # æ£€æµ‹å‘è‚²é˜¶æ®µ
        logger.debug("è®¡ç®—å‘è‚²æˆç†Ÿåº¦åˆ†æ•°...")
        maturation_score = self._compute_maturation_score(performance_history)
        logger.info(f"æˆç†Ÿåº¦åˆ†æ•°: {maturation_score:.4f} (é˜ˆå€¼: {self.maturation_threshold})")
        
        self.development_history.append({
            'epoch': epoch,
            'maturation_score': maturation_score,
            'performance': performance_history[-1] if performance_history else 0.0
        })
        
        # æ£€æµ‹æ˜¯å¦éœ€è¦ç»“æ„åˆ†åŒ–
        differentiation_needed = self._detect_structural_differentiation_need(maturation_score)
        debug_printer.print_debug(f"ç»“æ„åˆ†åŒ–éœ€æ±‚: {'âœ…éœ€è¦' if differentiation_needed else 'âŒä¸éœ€è¦'}", 
                               "SUCCESS" if differentiation_needed else "DEBUG")
        
        if differentiation_needed:
            logger.success(f"âœ… è§¦å‘æ¡ä»¶æ»¡è¶³: æˆç†Ÿåº¦={maturation_score:.3f}")
            logger.exit_section("ç”Ÿç‰©å­¦åŸç†è§¦å‘å™¨æ£€æŸ¥")
            return True, f"å…³é”®å‘è‚²æœŸæ£€æµ‹ï¼šæˆç†Ÿåº¦={maturation_score:.3f}ï¼Œé€‚åˆç»“æ„é‡ç»„"
            
        logger.info("âŒ æœªè¾¾åˆ°è§¦å‘æ¡ä»¶: æœªå¤„äºå…³é”®å‘è‚²æœŸ")
        logger.exit_section("ç”Ÿç‰©å­¦åŸç†è§¦å‘å™¨æ£€æŸ¥")
        return False, "æœªå¤„äºå…³é”®å‘è‚²æœŸ"
    
    def _compute_maturation_score(self, performance_history: List[float]) -> float:
        """è®¡ç®—å‘è‚²æˆç†Ÿåº¦åˆ†æ•°"""
        if len(performance_history) < 5:
            return 0.0
        
        recent_performances = performance_history[-10:]
        
        # 1. æ€§èƒ½ç¨³å®šæ€§
        stability = 1.0 - np.std(recent_performances[-5:]) / (np.mean(recent_performances[-5:]) + 1e-8)
        
        # 2. æ”¹è¿›é€Ÿåº¦
        if len(recent_performances) >= 5:
            early_avg = np.mean(recent_performances[:5])
            late_avg = np.mean(recent_performances[-5:])
            improvement_rate = (late_avg - early_avg) / (early_avg + 1e-8)
        else:
            improvement_rate = 0.0
        
        # 3. æ€§èƒ½é«˜åº¦
        performance_level = recent_performances[-1] if recent_performances else 0.0
        
        # ç»¼åˆæˆç†Ÿåº¦åˆ†æ•°
        maturation = (
            0.4 * min(stability, 1.0) +
            0.3 * min(improvement_rate, 1.0) +
            0.3 * performance_level
        )
        
        return max(0.0, min(maturation, 1.0))
    
    def _detect_structural_differentiation_need(self, maturation_score: float) -> bool:
        """æ£€æµ‹æ˜¯å¦éœ€è¦ç»“æ„åˆ†åŒ–"""
        return maturation_score > self.maturation_threshold

class EnhancedCognitiveScienceTrigger:
    """å¢å¼ºçš„è®¤çŸ¥ç§‘å­¦è§¦å‘å™¨"""
    
    def __init__(self, forgetting_threshold: float = 0.05):
        self.forgetting_threshold = forgetting_threshold
        self.learning_patterns = deque(maxlen=25)
        
    def should_trigger(self, context: Dict[str, Any]) -> Tuple[bool, str]:
        """æ£€æµ‹è®¤çŸ¥ç“¶é¢ˆå’Œç¾éš¾æ€§é—å¿˜"""
        logger.enter_section("è®¤çŸ¥ç§‘å­¦è§¦å‘å™¨æ£€æŸ¥")
        
        performance_history = context.get('performance_history', [])
        activations = context.get('activations', {})
        
        debug_printer.print_debug(f"æ€§èƒ½å†å²é•¿åº¦: {len(performance_history)}, æ¿€æ´»å€¼å±‚æ•°: {len(activations)}", "DEBUG")
        
        if len(performance_history) < 8:
            logger.warning("âŒ å­¦ä¹ å†å²æ•°æ®ä¸è¶³ (éœ€è¦è‡³å°‘8ä¸ªæ•°æ®ç‚¹)")
            logger.exit_section("è®¤çŸ¥ç§‘å­¦è§¦å‘å™¨æ£€æŸ¥")
            return False, "å­¦ä¹ å†å²æ•°æ®ä¸è¶³"
        
        # æ£€æµ‹ç¾éš¾æ€§é—å¿˜
        logger.debug("æ£€æµ‹ç¾éš¾æ€§é—å¿˜...")
        forgetting_detected = self._detect_catastrophic_forgetting(performance_history)
        debug_printer.print_debug(f"ç¾éš¾æ€§é—å¿˜æ£€æµ‹: {'âœ…å‘ç°' if forgetting_detected else 'âŒæœªå‘ç°'}", 
                               "WARNING" if forgetting_detected else "DEBUG")
        
        # æ£€æµ‹å­¦ä¹ é¥±å’Œ
        logger.debug("æ£€æµ‹å­¦ä¹ é¥±å’Œ...")
        saturation_detected = self._detect_learning_saturation(performance_history)
        debug_printer.print_debug(f"å­¦ä¹ é¥±å’Œæ£€æµ‹: {'âœ…å‘ç°' if saturation_detected else 'âŒæœªå‘ç°'}", 
                               "WARNING" if saturation_detected else "DEBUG")
        
        # æ£€æµ‹ç‰¹å¾è¡¨ç¤ºå†²çª
        logger.debug("æ£€æµ‹ç‰¹å¾è¡¨ç¤ºå†²çª...")
        conflict_detected = self._detect_representation_conflict(activations)
        debug_printer.print_debug(f"ç‰¹å¾è¡¨ç¤ºå†²çªæ£€æµ‹: {'âœ…å‘ç°' if conflict_detected else 'âŒæœªå‘ç°'}", 
                               "WARNING" if conflict_detected else "DEBUG")
        
        self.learning_patterns.append({
            'epoch': context.get('epoch', 0),
            'performance': performance_history[-1] if performance_history else 0.0,
            'forgetting_risk': forgetting_detected,
            'saturation_risk': saturation_detected,
            'conflict_risk': conflict_detected
        })
        
        if forgetting_detected or conflict_detected:
            reason = []
            if forgetting_detected:
                reason.append("ç¾éš¾æ€§é—å¿˜é£é™©")
            if conflict_detected:
                reason.append("ç‰¹å¾è¡¨ç¤ºå†²çª")
            debug_printer.print_debug(f"âœ… è§¦å‘æ¡ä»¶æ»¡è¶³: {', '.join(reason)}", "SUCCESS")
            logger.exit_section("è®¤çŸ¥ç§‘å­¦è§¦å‘å™¨æ£€æŸ¥")
            return True, f"è®¤çŸ¥ç“¶é¢ˆæ£€æµ‹ï¼š{', '.join(reason)}ï¼Œéœ€è¦åˆ†åŒ–ä¸“é—¨åŒ–ç¥ç»å…ƒ"
            
        logger.info("âŒ æœªè¾¾åˆ°è§¦å‘æ¡ä»¶: è®¤çŸ¥æŒ‡æ ‡æ­£å¸¸")
        logger.exit_section("è®¤çŸ¥ç§‘å­¦è§¦å‘å™¨æ£€æŸ¥")
        return False, "è®¤çŸ¥æŒ‡æ ‡æ­£å¸¸"
    
    def _detect_catastrophic_forgetting(self, performance_history: List[float]) -> bool:
        """æ£€æµ‹ç¾éš¾æ€§é—å¿˜"""
        if len(performance_history) < 8:
            return False
        
        # æ£€æŸ¥æœ€è¿‘æ€§èƒ½æ˜¯å¦æ˜¾è‘—ä¸‹é™
        recent_window = 5
        past_window = 5
        
        recent_avg = np.mean(performance_history[-recent_window:])
        past_avg = np.mean(performance_history[-(recent_window + past_window):-recent_window])
        
        if past_avg > 0:
            decline_ratio = (past_avg - recent_avg) / past_avg
            return decline_ratio > self.forgetting_threshold
        
        return False
    
    def _detect_learning_saturation(self, performance_history: List[float]) -> bool:
        """æ£€æµ‹å­¦ä¹ é¥±å’Œ"""
        if len(performance_history) < 10:
            return False
        
        # æ£€æŸ¥æœ€è¿‘10ä¸ªepochçš„æ”¹è¿›
        recent_performances = performance_history[-10:]
        improvements = [recent_performances[i] - recent_performances[i-1] 
                       for i in range(1, len(recent_performances))]
        
        avg_improvement = np.mean(improvements)
        return avg_improvement < 0.001  # æ”¹è¿›æå°
    
    def _detect_representation_conflict(self, activations: Dict[str, torch.Tensor]) -> bool:
        """æ£€æµ‹ç‰¹å¾è¡¨ç¤ºå†²çª"""
        if not activations:
            return False
        
        # ç®€åŒ–çš„å†²çªæ£€æµ‹ï¼šæ£€æŸ¥æ¿€æ´»æ¨¡å¼çš„ä¸€è‡´æ€§
        conflict_scores = []
        
        for name, activation in activations.items():
            if len(activation.shape) >= 2 and activation.shape[0] > 1:
                # è®¡ç®—æ‰¹æ¬¡å†…æ¿€æ´»æ¨¡å¼çš„ä¸€è‡´æ€§
                activation_flat = activation.view(activation.shape[0], -1)
                
                # è®¡ç®—æ ·æœ¬é—´çš„ç›¸å…³æ€§
                if activation_flat.shape[1] > 1:
                    try:
                        correlation_matrix = torch.corrcoef(activation_flat)
                        # å¯¹è§’çº¿å¤–çš„ç›¸å…³ç³»æ•°
                        mask = ~torch.eye(correlation_matrix.shape[0], dtype=torch.bool)
                        off_diagonal = correlation_matrix[mask]
                        
                        if len(off_diagonal) > 0:
                            consistency = torch.mean(torch.abs(off_diagonal))
                            conflict_scores.append(1.0 - consistency.item())
                    except:
                        continue
        
        if conflict_scores:
            avg_conflict = np.mean(conflict_scores)
            return avg_conflict > 0.7  # å†²çªé˜ˆå€¼
        
        return False

class EnhancedDNMFramework:
    """å¢å¼ºçš„DNMæ¡†æ¶"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.bottleneck_analyzer = AdvancedBottleneckAnalyzer()
        self.morphogenesis_executor = AdvancedMorphogenesisExecutor()
        self.decision_maker = IntelligentMorphogenesisDecisionMaker()
        
        # åˆå§‹åŒ–è§¦å‘å™¨
        self.triggers = {
            'information_theory': EnhancedInformationTheoryTrigger(),
            'biological_principles': EnhancedBiologicalPrinciplesTrigger(),
            'cognitive_science': EnhancedCognitiveScienceTrigger()
        }
        
        # è·Ÿè¸ªæ•°æ®
        self.morphogenesis_events = []
        self.performance_history = []
        self.activation_cache = {}
        self.gradient_cache = {}
        
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'trigger_interval': 3,  # æ¯3ä¸ªepochæ£€æŸ¥ä¸€æ¬¡
            'max_morphogenesis_per_epoch': 1,
            'performance_patience': 8,
            'min_improvement_threshold': 0.001,
            'max_parameter_growth_ratio': 0.5,  # æœ€å¤§å‚æ•°å¢é•¿50%
            'enable_serial_division': True,
            'enable_parallel_division': True,
            'enable_hybrid_division': True,
            'complexity_threshold': 0.6
        }
    
    def should_trigger_morphogenesis(self, context: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘å½¢æ€å‘ç”Ÿ"""
        logger.enter_section("å½¢æ€å‘ç”Ÿè§¦å‘æ£€æŸ¥")
        epoch = context.get('epoch', 0)
        
        debug_printer.print_debug(f"å½“å‰epoch: {epoch}, è§¦å‘é—´éš”: {self.config['trigger_interval']}", "INFO")
        
        # æ£€æŸ¥è§¦å‘é—´éš”
        if epoch % self.config['trigger_interval'] != 0:
            logger.info(f"âŒ ä¸åœ¨è§¦å‘é—´éš”å†… ({epoch} % {self.config['trigger_interval']} != 0)")
            logger.exit_section("å½¢æ€å‘ç”Ÿè§¦å‘æ£€æŸ¥")
            return False, []
        
        logger.info("âœ… åœ¨è§¦å‘é—´éš”å†…ï¼Œæ£€æŸ¥å„è§¦å‘å™¨")
        
        # æ£€æŸ¥å„ä¸ªè§¦å‘å™¨
        trigger_results = []
        trigger_reasons = []
        
        for name, trigger in self.triggers.items():
            logger.debug(f"æ£€æŸ¥è§¦å‘å™¨: {name}")
            try:
                should_trigger, reason = trigger.should_trigger(context)
                debug_printer.print_debug(f"è§¦å‘å™¨[{name}]: {'âœ…æ¿€æ´»' if should_trigger else 'âŒæœªæ¿€æ´»'} - {reason}", 
                                       "SUCCESS" if should_trigger else "INFO")
                if should_trigger:
                    trigger_results.append(True)
                    trigger_reasons.append(f"{name}: {reason}")
                else:
                    trigger_results.append(False)
            except Exception as e:
                logger.error(f"âŒ è§¦å‘å™¨ {name} æ‰§è¡Œå¤±è´¥: {e}")
                logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                trigger_results.append(False)
        
        # è‡³å°‘æœ‰ä¸€ä¸ªè§¦å‘å™¨æ¿€æ´»
        should_trigger = any(trigger_results)
        
        logger.info(f"è§¦å‘å™¨æ±‡æ€»: {len([r for r in trigger_results if r])}/{len(trigger_results)} æ¿€æ´»")
        debug_printer.print_debug(f"æœ€ç»ˆå†³å®š: {'âœ…è§¦å‘å½¢æ€å‘ç”Ÿ' if should_trigger else 'âŒä¸è§¦å‘'}", 
                               "SUCCESS" if should_trigger else "INFO")
        logger.exit_section("å½¢æ€å‘ç”Ÿè§¦å‘æ£€æŸ¥")
        
        return should_trigger, trigger_reasons
    
    def execute_morphogenesis(self, model: nn.Module, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå½¢æ€å‘ç”Ÿ"""
        logger.enter_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
        logger.log_model_info(model, "è¾“å…¥æ¨¡å‹")
        
        results = {
            'model_modified': False,
            'new_model': model,
            'parameters_added': 0,
            'morphogenesis_events': 0,
            'morphogenesis_type': 'none',
            'trigger_reasons': []
        }
        
        try:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘
            should_trigger, trigger_reasons = self.should_trigger_morphogenesis(context)
            
            if not should_trigger:
                logger.info("âŒ æœªæ»¡è¶³è§¦å‘æ¡ä»¶ï¼Œè·³è¿‡å½¢æ€å‘ç”Ÿ")
                logger.exit_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
                return results
            
            logger.success(f"âœ… æ»¡è¶³è§¦å‘æ¡ä»¶ï¼ŒåŸå› : {trigger_reasons}")
            
            # è¾“å‡ºè§¦å‘åŸå› 
            logger.enter_section("è§¦å‘åŸå› åˆ†æ")
            for i, reason in enumerate(trigger_reasons, 1):
                logger.info(f"{i}. {reason}")
            logger.exit_section("è§¦å‘åŸå› åˆ†æ")
            
            results['trigger_reasons'] = trigger_reasons
            
            # æ‰§è¡Œç“¶é¢ˆåˆ†æ
            logger.enter_section("ç“¶é¢ˆåˆ†æ")
            activations = context.get('activations', {})
            gradients = context.get('gradients', {})
            
            debug_printer.print_debug(f"åˆ†ææ•°æ®: æ¿€æ´»å€¼{len(activations)}å±‚, æ¢¯åº¦{len(gradients)}å±‚", "INFO")
            
            if not activations or not gradients:
                logger.error("âŒ ç¼ºå°‘æ¿€æ´»å€¼æˆ–æ¢¯åº¦ä¿¡æ¯ï¼Œè·³è¿‡å½¢æ€å‘ç”Ÿ")
                logger.exit_section("ç“¶é¢ˆåˆ†æ")
                logger.exit_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
                return results
            
            bottleneck_analysis = self.bottleneck_analyzer.analyze_network_bottlenecks(
                model, activations, gradients
            )
            logger.success(f"ç“¶é¢ˆåˆ†æå®Œæˆ: {len(bottleneck_analysis) if bottleneck_analysis else 0}ä¸ªç“¶é¢ˆ")
            logger.exit_section("ç“¶é¢ˆåˆ†æ")
            
            # åˆ¶å®šå†³ç­–
            logger.enter_section("å½¢æ€å‘ç”Ÿå†³ç­–")
            performance_history = context.get('performance_history', [])
            logger.info(f"æ€§èƒ½å†å²: {len(performance_history)}ä¸ªæ•°æ®ç‚¹")
            decision = self.decision_maker.make_decision(bottleneck_analysis, performance_history)
            
            if decision is None:
                logger.warning("âŒ æœªå‘ç°éœ€è¦å½¢æ€å‘ç”Ÿçš„ç“¶é¢ˆ")
                logger.exit_section("å½¢æ€å‘ç”Ÿå†³ç­–")
                logger.exit_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
                return results
            
            logger.success(f"âœ… å†³ç­–åˆ¶å®šå®Œæˆ: {decision.morphogenesis_type.value} (ç½®ä¿¡åº¦: {decision.confidence:.3f})")
            logger.exit_section("å½¢æ€å‘ç”Ÿå†³ç­–")
            
            # æ‰§è¡Œå½¢æ€å‘ç”Ÿ
            logger.enter_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
            logger.info(f"æ‰§è¡Œç­–ç•¥: {decision.morphogenesis_type.value} åœ¨ {decision.target_location}")
            
            new_model, parameters_added = self.morphogenesis_executor.execute_morphogenesis(
                model, decision
            )
            
            logger.info(f"å½¢æ€å‘ç”Ÿç»“æœ: æ–°å¢å‚æ•°={parameters_added}")
            logger.log_model_info(new_model, "æ–°æ¨¡å‹")
            logger.exit_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
            
            if parameters_added > 0:
                logger.success("âœ… å½¢æ€å‘ç”ŸæˆåŠŸï¼Œè®°å½•äº‹ä»¶")
                
                # è®°å½•äº‹ä»¶
                event = EnhancedMorphogenesisEvent(
                    epoch=context.get('epoch', 0),
                    event_type=decision.morphogenesis_type.value,
                    location=decision.target_location,
                    trigger_reason=decision.reasoning,
                    performance_before=performance_history[-1] if performance_history else 0.0,
                    parameters_added=parameters_added,
                    morphogenesis_type=decision.morphogenesis_type,
                    confidence=decision.confidence,
                    expected_improvement=decision.expected_improvement
                )
                
                self.morphogenesis_events.append(event)
                
                # æ›´æ–°ç»“æœ
                results.update({
                    'model_modified': True,
                    'new_model': new_model,
                    'parameters_added': parameters_added,
                    'morphogenesis_events': 1,
                    'morphogenesis_type': decision.morphogenesis_type.value,
                    'decision_confidence': decision.confidence,
                    'expected_improvement': decision.expected_improvement
                })
                
                debug_printer.print_debug(f"âœ… é«˜çº§å½¢æ€å‘ç”Ÿå®Œæˆ: {decision.morphogenesis_type.value}, æ–°å¢å‚æ•°: {parameters_added:,}", "SUCCESS")
            else:
                logger.warning("âŒ å½¢æ€å‘ç”Ÿæœªæ·»åŠ ä»»ä½•å‚æ•°")
                
        except Exception as e:
            logger.error(f"âŒ å½¢æ€å‘ç”Ÿæ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
        logger.exit_section("å½¢æ€å‘ç”Ÿæ‰§è¡Œ")
        return results
    
    def update_performance_history(self, performance: float):
        """æ›´æ–°æ€§èƒ½å†å²"""
        self.performance_history.append(performance)
        
        # ä¿æŒå†å²é•¿åº¦
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]
    
    def cache_activations_and_gradients(self, activations: Dict[str, torch.Tensor], 
                                       gradients: Dict[str, torch.Tensor]):
        """ç¼“å­˜æ¿€æ´»å€¼å’Œæ¢¯åº¦"""
        self.activation_cache = activations
        self.gradient_cache = gradients
    
    def get_morphogenesis_summary(self) -> Dict[str, Any]:
        """è·å–å½¢æ€å‘ç”Ÿæ€»ç»“"""
        if not self.morphogenesis_events:
            return {
                'total_events': 0,
                'total_parameters_added': 0,
                'morphogenesis_types': {},
                'events': []
            }
        
        # ç»Ÿè®¡å„ç§ç±»å‹çš„å½¢æ€å‘ç”Ÿ
        type_counts = defaultdict(int)
        for event in self.morphogenesis_events:
            type_counts[event.morphogenesis_type.value] += 1
        
        total_params = sum(event.parameters_added for event in self.morphogenesis_events)
        
        return {
            'total_events': len(self.morphogenesis_events),
            'total_parameters_added': total_params,
            'morphogenesis_types': dict(type_counts),
            'events': [
                {
                    'epoch': event.epoch,
                    'type': event.morphogenesis_type.value,
                    'location': event.location,
                    'parameters_added': event.parameters_added,
                    'confidence': event.confidence,
                    'expected_improvement': event.expected_improvement,
                    'reasoning': event.trigger_reason
                }
                for event in self.morphogenesis_events
            ]
        }