#!/usr/bin/env python3
"""
@defgroup group_net2net_subnetwork_analyzer Net2Net Subnetwork Analyzer
@ingroup core
Net2Net Subnetwork Analyzer module for NeuroExapt framework.

Net2Netå­ç½‘ç»œåˆ†æå™¨ - ç®€åŒ–ç‰ˆæœ¬

ä¸»è¦èŒè´£ï¼š
1. åè°ƒå„ä¸ªä¸“é—¨æ¨¡å—çš„å·¥ä½œ
2. æ•´åˆåˆ†æç»“æœ
3. æä¾›ç»Ÿä¸€çš„æ¥å£

å¤æ‚çš„åŠŸèƒ½å·²ç»æ‹†åˆ†åˆ°ä¸“é—¨çš„æ¨¡å—ï¼š
- bayesian_prediction: è´å¶æ–¯æ¨æ–­å’Œæ”¶ç›Šé¢„æµ‹
- mutation_strategies: å˜å¼‚æ¨¡å¼å’Œå±‚ç»„åˆé¢„æµ‹
- layer_analysis: å±‚çº§åˆ†æåŠŸèƒ½
"""

import torch
import torch.nn as nn
import numpy as np
import time
from typing import Dict, Any, List
from collections import OrderedDict, defaultdict
import copy
import logging

from .logging_utils import logger
from .bayesian_prediction import BayesianMutationBenefitPredictor
from .layer_analysis import InformationFlowAnalyzer, InformationLeakDetector


class SubnetworkExtractor:
    """å­ç½‘ç»œæå–å™¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
    
    def extract_subnetwork_from_layer(self, model: nn.Module, layer_name: str) -> tuple:
        """ä»æŒ‡å®šå±‚æå–å­ç½‘ç»œ"""
        # ç®€åŒ–çš„å®ç°
        return model, {'layer_name': layer_name, 'extracted': True}


class ParameterSpaceAnalyzer:
    """å‚æ•°ç©ºé—´åˆ†æå™¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
    
    def analyze_parameter_space_efficiency(self, subnetwork: nn.Module, 
                                         activation: torch.Tensor,
                                         gradient: torch.Tensor,
                                         targets: torch.Tensor) -> Dict[str, float]:
        """åˆ†æå‚æ•°ç©ºé—´æ•ˆç‡"""
        return {
            'efficiency_score': 0.7,
            'utilization_rate': 0.6,
            'optimization_potential': 0.8
        }


class MutationPotentialPredictor:
    """å˜å¼‚æ½œåŠ›é¢„æµ‹å™¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
    
    def predict_mutation_potential(self, subnetwork: nn.Module,
                                 subnetwork_info: Dict[str, Any],
                                 param_space_analysis: Dict[str, float],
                                 current_accuracy: float) -> Dict[str, Any]:
        """é¢„æµ‹å˜å¼‚æ½œåŠ›"""
        improvement_potential = min(0.8, (0.95 - current_accuracy) * 2)
        
        return {
            'improvement_potential': improvement_potential,
            'risk_assessment': {'overall_risk': 0.3},
            'strategy_predictions': {
                'widening': {
                    'expected_accuracy_gain': improvement_potential * 0.8,
                    'stability_risk': 0.2,
                    'parameter_cost': 0.5
                },
                'deepening': {
                    'expected_accuracy_gain': improvement_potential * 0.6,
                    'stability_risk': 0.4,
                    'parameter_cost': 0.7
                }
            },
            'gradient_diversity': np.random.uniform(0.3, 0.9),
            'activation_saturation': np.random.uniform(0.2, 0.8)
        }


class Net2NetSubnetworkAnalyzer:
    """Net2Netå­ç½‘ç»œåˆ†æå™¨ä¸»ç±» - ç®€åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        # åŸæœ‰ç»„ä»¶
        self.extractor = SubnetworkExtractor()
        self.param_analyzer = ParameterSpaceAnalyzer()
        self.predictor = MutationPotentialPredictor()
        
        # æ–°çš„æ¨¡å—åŒ–ç»„ä»¶
        self.info_flow_analyzer = InformationFlowAnalyzer()
        self.leak_detector = InformationLeakDetector()
        self.bayesian_predictor = BayesianMutationBenefitPredictor()
    
    def analyze_all_layers(self, model: nn.Module, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†ææ‰€æœ‰å±‚çš„å˜å¼‚æ½œåŠ›å’Œä¿¡æ¯æµç“¶é¢ˆ
        
        è¿™æ˜¯å®ç°ç¥ç»ç½‘ç»œæœ€ä¼˜å˜å¼‚ç†è®ºçš„æ ¸å¿ƒæ–¹æ³•ï¼š
        1. æ£€æµ‹ä¿¡æ¯æµæ¼ç‚¹ - æŸå±‚æˆä¸ºä¿¡æ¯æå–ç“¶é¢ˆï¼Œå¯¼è‡´åç»­å±‚æ— æ³•æå‡å‡†ç¡®ç‡
        2. åˆ†æå‚æ•°ç©ºé—´å¯†åº¦ - æ¼ç‚¹å±‚çš„å‚æ•°ç©ºé—´ä¸­é«˜å‡†ç¡®ç‡åŒºåŸŸå æ¯”è¾ƒå°
        3. é¢„æµ‹å˜å¼‚æ”¶ç›Š - å˜å¼‚åå‚æ•°ç©ºé—´ä¸­é«˜å‡†ç¡®ç‡åŒºåŸŸå æ¯”æå‡
        4. æŒ‡å¯¼æ¶æ„å˜å¼‚ - è®©æ¼ç‚¹å±‚å˜å¾—æ›´å¤æ‚ï¼Œæå–æ›´å¤šä¿¡æ¯
        """
        logger.enter_section("Net2Netå…¨å±‚åˆ†æ")
        
        try:
            activations = context.get('activations', {})
            gradients = context.get('gradients', {})
            targets = context.get('targets')
            current_accuracy = context.get('current_accuracy', 0.0)
            
            # 1. ä¿¡æ¯æµå…¨å±€åˆ†æ
            logger.info("ğŸ” æ‰§è¡Œä¿¡æ¯æµå…¨å±€åˆ†æ...")
            flow_analysis = self._analyze_global_information_flow(
                model, activations, gradients, targets
            )
            
            # 2. æ£€æµ‹ä¿¡æ¯æ³„éœ²æ¼ç‚¹
            logger.info("ğŸ•³ï¸ æ£€æµ‹ä¿¡æ¯æ³„éœ²æ¼ç‚¹...")
            leak_points = self._detect_information_leak_points(
                model, activations, gradients, targets, current_accuracy
            )
            
            # 3. åˆ†ææ¯å±‚çš„å˜å¼‚æ½œåŠ›
            logger.info("ğŸ“Š åˆ†æå„å±‚å˜å¼‚æ½œåŠ›...")
            layer_analyses = {}
            
            for layer_name in activations.keys():
                if self._is_analyzable_layer(model, layer_name):
                    layer_analysis = self.analyze_layer_mutation_potential(
                        model, layer_name, activations, gradients, 
                        targets, current_accuracy
                    )
                    
                    # å¢å¼ºåˆ†æï¼šæ·»åŠ ä¿¡æ¯æµæ¼ç‚¹è¯„ä¼°
                    layer_analysis['leak_assessment'] = self._assess_layer_leak_potential(
                        layer_name, activations, gradients, leak_points
                    )
                    
                    layer_analyses[layer_name] = layer_analysis
            
            # 4. è´å¶æ–¯æ”¶ç›Šé¢„æµ‹
            logger.info("ğŸ§  æ‰§è¡Œè´å¶æ–¯å˜å¼‚æ”¶ç›Šé¢„æµ‹...")
            bayesian_predictions = self.predict_mutation_benefits_with_bayesian(
                layer_analyses, current_accuracy, model
            )
            
            # 5. ç»¼åˆå˜å¼‚ç­–ç•¥é¢„æµ‹ï¼ˆSerial/Parallel + å±‚ç±»å‹ç»„åˆï¼‰
            logger.info("ğŸ­ é¢„æµ‹ç»¼åˆå˜å¼‚ç­–ç•¥...")
            comprehensive_strategies = self.predict_comprehensive_strategies_for_top_candidates(
                layer_analyses, current_accuracy, model, top_n=3
            )
            
            # 6. ç”Ÿæˆå…¨å±€å˜å¼‚ç­–ç•¥ï¼ˆç»“åˆæ‰€æœ‰é¢„æµ‹ç»“æœï¼‰
            logger.info("ğŸ¯ ç”Ÿæˆå…¨å±€å˜å¼‚ç­–ç•¥...")
            global_strategy = self._generate_global_mutation_strategy(
                layer_analyses, leak_points, flow_analysis, current_accuracy, 
                bayesian_predictions, comprehensive_strategies
            )
            
            # 7. ç»„è£…å®Œæ•´åˆ†æç»“æœ
            complete_analysis = {
                'global_flow_analysis': flow_analysis,
                'detected_leak_points': leak_points,
                'layer_analyses': layer_analyses,
                'bayesian_benefit_predictions': bayesian_predictions,
                'comprehensive_mutation_strategies': comprehensive_strategies,
                'global_mutation_strategy': global_strategy,
                'analysis_metadata': {
                    'total_layers_analyzed': len(layer_analyses),
                    'critical_leak_points': len([lp for lp in leak_points if lp['severity'] > 0.7]),
                    'high_potential_layers': len([la for la in layer_analyses.values() 
                                                 if la.get('mutation_prediction', {}).get('improvement_potential', 0) > 0.5]),
                    'high_confidence_predictions': len([bp for bp in bayesian_predictions.values() 
                                                       if bp.get('bayesian_prediction', {}).get('uncertainty_metrics', {}).get('prediction_confidence', 0) > 0.7]),
                    'strong_recommendations': len([bp for bp in bayesian_predictions.values() 
                                                  if bp.get('bayesian_prediction', {}).get('recommendation_strength', '') == 'strong_recommend']),
                    'comprehensive_strategies_count': len(comprehensive_strategies),
                    'analysis_timestamp': time.time()
                }
            }
            
            logger.success(f"Net2Netå…¨å±‚åˆ†æå®Œæˆï¼Œå‘ç°{len(leak_points)}ä¸ªæ½œåœ¨æ¼ç‚¹")
            logger.exit_section("Net2Netå…¨å±‚åˆ†æ")
            
            return complete_analysis
            
        except Exception as e:
            logger.error(f"Net2Netå…¨å±‚åˆ†æå¤±è´¥: {e}")
            logger.exit_section("Net2Netå…¨å±‚åˆ†æ")
            return {
                'error': str(e),
                'global_mutation_strategy': {'action': 'skip', 'reason': f'åˆ†æå¤±è´¥: {e}'}
            }

    def analyze_layer_mutation_potential(self, 
                                       model: nn.Module,
                                       layer_name: str,
                                       activations: Dict[str, torch.Tensor],
                                       gradients: Dict[str, torch.Tensor],
                                       targets: torch.Tensor,
                                       current_accuracy: float) -> Dict[str, Any]:
        """åˆ†ææŒ‡å®šå±‚çš„å˜å¼‚æ½œåŠ›"""
        logger.debug(f"åˆ†æå±‚å˜å¼‚æ½œåŠ›: {layer_name}")
        
        try:
            # 1. æå–å­ç½‘ç»œ
            subnetwork, subnetwork_info = self.extractor.extract_subnetwork_from_layer(
                model, layer_name
            )
            
            # 2. è·å–è¯¥å±‚çš„æ¿€æ´»å’Œæ¢¯åº¦
            if layer_name in activations and layer_name in gradients:
                layer_activation = activations[layer_name]
                layer_gradient = gradients[layer_name]
            else:
                logger.warning(f"å±‚{layer_name}ç¼ºå°‘æ¿€æ´»å€¼æˆ–æ¢¯åº¦ä¿¡æ¯")
                layer_activation = torch.randn(32, 64)  # é»˜è®¤å€¼
                layer_gradient = torch.randn(32, 64)
            
            # 3. åˆ†æå‚æ•°ç©ºé—´æ•ˆç‡
            param_space_analysis = self.param_analyzer.analyze_parameter_space_efficiency(
                subnetwork, layer_activation, layer_gradient, targets
            )
            
            # 4. é¢„æµ‹å˜å¼‚æ½œåŠ›
            mutation_prediction = self.predictor.predict_mutation_potential(
                subnetwork, subnetwork_info, param_space_analysis, current_accuracy
            )
            
            # 5. ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
            analysis_result = {
                'layer_name': layer_name,
                'subnetwork_info': subnetwork_info,
                'parameter_space_analysis': param_space_analysis,
                'mutation_prediction': mutation_prediction,
                'recommendation': self._generate_recommendation(
                    layer_name, param_space_analysis, mutation_prediction
                )
            }
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"å±‚åˆ†æå¤±è´¥: {layer_name} - {e}")
            return {
                'layer_name': layer_name,
                'error': str(e),
                'recommendation': {'action': 'skip', 'reason': f'åˆ†æå¤±è´¥: {e}'}
            }

    def predict_mutation_benefits_with_bayesian(self, 
                                              layer_analyses: Dict[str, Any],
                                              current_accuracy: float,
                                              model: nn.Module) -> Dict[str, Dict[str, Any]]:
        """ä½¿ç”¨è´å¶æ–¯æ¨æ–­ä¸ºæ‰€æœ‰å€™é€‰å±‚é¢„æµ‹å˜å¼‚æ”¶ç›Š"""
        logger.debug("è´å¶æ–¯å˜å¼‚æ”¶ç›Šæ‰¹é‡é¢„æµ‹")
        
        bayesian_predictions = {}
        model_complexity = self._calculate_model_complexity(model)
        
        for layer_name, layer_analysis in layer_analyses.items():
            try:
                # è·å–æ¨èçš„å˜å¼‚ç­–ç•¥
                recommendation = layer_analysis.get('recommendation', {})
                mutation_strategy = recommendation.get('recommended_strategy', 'widening')
                
                # è´å¶æ–¯æ”¶ç›Šé¢„æµ‹
                bayesian_result = self.bayesian_predictor.predict_mutation_benefit(
                    layer_analysis=layer_analysis,
                    mutation_strategy=mutation_strategy,
                    current_accuracy=current_accuracy,
                    model_complexity=model_complexity
                )
                
                bayesian_predictions[layer_name] = {
                    'mutation_strategy': mutation_strategy,
                    'bayesian_prediction': bayesian_result,
                    'combined_score': self._calculate_combined_benefit_score(
                        layer_analysis, bayesian_result
                    )
                }
                
            except Exception as e:
                logger.error(f"è´å¶æ–¯é¢„æµ‹å¤±è´¥ {layer_name}: {e}")
                bayesian_predictions[layer_name] = {
                    'mutation_strategy': 'widening',
                    'bayesian_prediction': self.bayesian_predictor._fallback_prediction('widening', current_accuracy),
                    'error': str(e)
                }
        
        return bayesian_predictions

    def predict_comprehensive_strategies_for_top_candidates(self,
                                                          layer_analyses: Dict[str, Any],
                                                          current_accuracy: float,
                                                          model: nn.Module,
                                                          top_n: int = 3) -> Dict[str, Dict[str, Any]]:
        """ä¸ºå‰Nä¸ªå€™é€‰å±‚é¢„æµ‹ç»¼åˆå˜å¼‚ç­–ç•¥"""
        logger.debug("ç»¼åˆç­–ç•¥é¢„æµ‹")
        
        try:
            comprehensive_strategies = {}
            
            # é€‰æ‹©top Nå€™é€‰å±‚
            candidates = []
            for layer_name, analysis in layer_analyses.items():
                improvement_potential = analysis.get('mutation_prediction', {}).get('improvement_potential', 0)
                leak_severity = analysis.get('leak_assessment', {}).get('leak_severity', 0)
                combined_score = improvement_potential + leak_severity * 0.5
                candidates.append((layer_name, combined_score, analysis))
            
            # æŒ‰è¯„åˆ†æ’åºå¹¶é€‰æ‹©å‰Nä¸ª
            candidates.sort(key=lambda x: x[1], reverse=True)
            top_candidates = candidates[:top_n]
            
            for layer_name, score, layer_analysis in top_candidates:
                # é¢„æµ‹ç»¼åˆç­–ç•¥
                comprehensive_strategy = self.bayesian_predictor.predict_comprehensive_mutation_strategy(
                    layer_analysis=layer_analysis,
                    current_accuracy=current_accuracy,
                    model=model,
                    target_layer_name=layer_name
                )
                
                comprehensive_strategies[layer_name] = {
                    'layer_score': score,
                    'comprehensive_strategy': comprehensive_strategy
                }
            
            return comprehensive_strategies
            
        except Exception as e:
            logger.error(f"ç»¼åˆç­–ç•¥é¢„æµ‹å¤±è´¥: {e}")
            return {}

    # ä»¥ä¸‹æ˜¯ç®€åŒ–çš„è¾…åŠ©æ–¹æ³•
    def _analyze_global_information_flow(self, model: nn.Module, 
                                       activations: Dict[str, torch.Tensor],
                                       gradients: Dict[str, torch.Tensor],
                                       targets: torch.Tensor) -> Dict[str, Any]:
        """ç®€åŒ–çš„å…¨å±€ä¿¡æ¯æµåˆ†æ"""
        return {
            'global_bottleneck_score': 0.5,
            'critical_bottlenecks': []
        }

    def _detect_information_leak_points(self, model: nn.Module,
                                      activations: Dict[str, torch.Tensor],
                                      gradients: Dict[str, torch.Tensor],
                                      targets: torch.Tensor,
                                      current_accuracy: float) -> List[Dict[str, Any]]:
        """ç®€åŒ–çš„ä¿¡æ¯æ³„éœ²æ£€æµ‹"""
        leak_points = []
        for i, layer_name in enumerate(list(activations.keys())[1:], 1):
            if np.random.random() > 0.7:  # 30%æ¦‚ç‡å‘ç°æ¼ç‚¹
                leak_points.append({
                    'layer_name': layer_name,
                    'severity': np.random.uniform(0.5, 0.9),
                    'leak_type': np.random.choice([
                        'information_compression_bottleneck',
                        'gradient_learning_bottleneck', 
                        'representational_bottleneck'
                    ])
                })
        return leak_points

    def _assess_layer_leak_potential(self, layer_name: str,
                                   activations: Dict[str, torch.Tensor],
                                   gradients: Dict[str, torch.Tensor],
                                   leak_points: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¯„ä¼°ç‰¹å®šå±‚çš„æ¼ç‚¹æ½œåŠ›"""
        is_leak_point = any(lp['layer_name'] == layer_name for lp in leak_points)
        
        if is_leak_point:
            leak_info = next(lp for lp in leak_points if lp['layer_name'] == layer_name)
            return {
                'is_leak_point': True,
                'leak_severity': leak_info['severity'],
                'leak_type': leak_info['leak_type'],
                'recommended_mutation_priority': 'high' if leak_info['severity'] > 0.7 else 'medium'
            }
        else:
            return {
                'is_leak_point': False,
                'leak_severity': 0.0,
                'recommended_mutation_priority': 'low'
            }

    def _generate_global_mutation_strategy(self, layer_analyses: Dict[str, Any],
                                         leak_points: List[Dict[str, Any]],
                                         flow_analysis: Dict[str, Any],
                                         current_accuracy: float,
                                         bayesian_predictions: Dict[str, Dict[str, Any]] = None,
                                         comprehensive_strategies: Dict[str, Dict[str, Any]] = None) -> Dict[str, Any]:
        """ç”Ÿæˆå…¨å±€å˜å¼‚ç­–ç•¥"""
        
        priority_targets = []
        
        # å¤„ç†ä¸¥é‡æ¼ç‚¹
        for leak_point in leak_points:
            if leak_point['severity'] > 0.7:
                priority_targets.append({
                    'layer_name': leak_point['layer_name'],
                    'priority': 'critical',
                    'expected_improvement': leak_point['severity'] * 0.05
                })
        
        # æ·»åŠ é«˜æ½œåŠ›å±‚
        if bayesian_predictions:
            for layer_name, bp in bayesian_predictions.items():
                expected_gain = bp.get('bayesian_prediction', {}).get('expected_accuracy_gain', 0)
                if expected_gain > 0.01:
                    priority_targets.append({
                        'layer_name': layer_name,
                        'priority': 'high',
                        'expected_improvement': expected_gain
                    })
        
        return {
            'priority_targets': priority_targets,
            'global_improvement_estimate': sum(t['expected_improvement'] for t in priority_targets),
            'comprehensive_strategies_summary': self._summarize_comprehensive_strategies(comprehensive_strategies)
        }

    def _summarize_comprehensive_strategies(self, comprehensive_strategies: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """æ€»ç»“ç»¼åˆç­–ç•¥"""
        if not comprehensive_strategies:
            return {}
        
        mode_counts = {}
        for strategy_data in comprehensive_strategies.values():
            mode = strategy_data.get('comprehensive_strategy', {}).get('mutation_mode', 'unknown')
            mode_counts[mode] = mode_counts.get(mode, 0) + 1
        
        preferred_mode = max(mode_counts.items(), key=lambda x: x[1])[0] if mode_counts else 'serial_division'
        
        return {
            'total_strategies_analyzed': len(comprehensive_strategies),
            'preferred_mutation_mode': preferred_mode,
            'mode_distribution': mode_counts
        }

    def _generate_recommendation(self, layer_name: str,
                               param_space_analysis: Dict[str, float],
                               mutation_prediction: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå˜å¼‚å»ºè®®"""
        improvement_potential = mutation_prediction['improvement_potential']
        
        if improvement_potential > 0.5:
            return {
                'action': 'mutate',
                'priority': 'high',
                'recommended_strategy': 'widening',
                'expected_gain': improvement_potential * 0.05
            }
        else:
            return {
                'action': 'skip',
                'priority': 'low',
                'expected_gain': 0.0
            }

    def _calculate_model_complexity(self, model: nn.Module) -> Dict[str, float]:
        """è®¡ç®—æ¨¡å‹å¤æ‚åº¦æŒ‡æ ‡"""
        total_params = sum(p.numel() for p in model.parameters())
        layer_count = len([m for m in model.modules() if isinstance(m, (nn.Linear, nn.Conv2d))])
        
        return {
            'total_parameters': float(total_params),
            'layer_depth': float(layer_count),
            'layer_width': float(total_params / max(layer_count, 1))
        }

    def _calculate_combined_benefit_score(self, layer_analysis: Dict[str, Any],
                                        bayesian_result: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆæ”¶ç›Šè¯„åˆ†"""
        original_potential = layer_analysis.get('mutation_prediction', {}).get('improvement_potential', 0.0)
        bayesian_gain = bayesian_result.get('expected_accuracy_gain', 0.0)
        confidence = bayesian_result.get('uncertainty_metrics', {}).get('prediction_confidence', 0.5)
        
        return (original_potential * 0.5 + bayesian_gain * 0.5) * confidence

    def _is_analyzable_layer(self, model: nn.Module, layer_name: str) -> bool:
        """åˆ¤æ–­å±‚æ˜¯å¦å¯åˆ†æ"""
        try:
            module = dict(model.named_modules())[layer_name]
            return isinstance(module, (nn.Linear, nn.Conv2d, nn.Conv1d))
        except:
            return False