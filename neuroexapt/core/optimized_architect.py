"""
defgroup group_optimized_architect Optimized Architect
ingroup core
Optimized Architect module for NeuroExapt framework.
"""


import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import numpy as np
from typing import Optional, Dict, Any, List, Tuple
import time
import gc
from collections import OrderedDict

from .architect import Architect
from ..utils.performance_monitor import PerformanceMonitor

class OptimizedArchitect(Architect):
    """
    ä¼˜åŒ–çš„æ¶æ„æœç´¢å™¨ï¼Œåˆ©ç”¨PyTorchçš„å‚æ•°ä¼˜åŒ–è®¾æ–½æ¥æé«˜æ€§èƒ½
    
    ä¸»è¦ä¼˜åŒ–ç­–ç•¥ï¼š
    1. å‡å°‘æ¶æ„æ›´æ–°é¢‘ç‡
    2. ä½¿ç”¨ä¸€é˜¶è¿‘ä¼¼æ›¿ä»£äºŒé˜¶è¿‘ä¼¼
    3. æ¢¯åº¦ç´¯ç§¯å’Œæ‰¹å¤„ç†
    4. å†…å­˜ç®¡ç†ä¼˜åŒ–
    5. æ—©åœæœºåˆ¶
    """
    
    def __init__(self, model, args, performance_monitor: Optional[PerformanceMonitor] = None):
        super().__init__(model, args)
        
        # æ€§èƒ½ç›‘æ§
        self.monitor = performance_monitor
        
        # ä¼˜åŒ–å‚æ•°
        self.arch_update_freq = getattr(args, 'arch_update_freq', 50)
        self.warmup_epochs = getattr(args, 'warmup_epochs', 5)
        self.use_first_order = getattr(args, 'use_first_order', True)
        self.grad_accumulation_steps = getattr(args, 'grad_accumulation_steps', 1)
        self.arch_early_stop_patience = getattr(args, 'arch_early_stop_patience', 20)
        
        # è®­ç»ƒç›¸å…³
        self.total_epochs = getattr(args, 'epochs', 50)  # æ€»è®­ç»ƒè½®æ•°
        
        # çŠ¶æ€è·Ÿè¸ª
        self.current_epoch = 0
        self.arch_step_count = 0
        self.last_arch_loss = float('inf')
        self.arch_loss_history = []
        self.no_improve_count = 0
        
        # æ¢¯åº¦ç´¯ç§¯ç¼“å†²åŒº
        self.accumulated_grads = None
        self.accumulation_count = 0
        
        # ä¼˜åŒ–å™¨é…ç½®
        self.optimizer = self._create_optimized_optimizer(args)
        
        # è®°å½•åˆå§‹åŒ–
        if self.monitor:
            self.monitor.logger.info(f"ğŸš€ OptimizedArchitect initialized:")
            self.monitor.logger.info(f"   Update frequency: every {self.arch_update_freq} steps")
            self.monitor.logger.info(f"   Warmup epochs: {self.warmup_epochs}")
            self.monitor.logger.info(f"   First-order approximation: {self.use_first_order}")
            self.monitor.logger.info(f"   Gradient accumulation: {self.grad_accumulation_steps} steps")
    
    def _create_optimized_optimizer(self, args):
        """åˆ›å»ºä¼˜åŒ–çš„æ¶æ„å‚æ•°ä¼˜åŒ–å™¨"""
        arch_params = list(self.model.arch_parameters())
        
        if len(arch_params) == 0:
            return None
        
        # ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œæ›´å¥½çš„æƒé‡è¡°å‡
        optimizer = torch.optim.AdamW(
            arch_params,
            lr=args.arch_learning_rate,
            betas=(0.9, 0.999),
            eps=1e-8,
            weight_decay=args.arch_weight_decay,
            amsgrad=True  # ä½¿ç”¨AMSGradå˜ä½“
        )
        
        return optimizer
    
    def set_epoch(self, epoch: int):
        """è®¾ç½®å½“å‰epoch"""
        self.current_epoch = epoch
        
        # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
        if epoch > self.warmup_epochs:
            self._adjust_learning_rate(epoch)
    
    def _adjust_learning_rate(self, epoch: int):
        """åŠ¨æ€è°ƒæ•´æ¶æ„å­¦ä¹ ç‡"""
        if self.optimizer is None:
            return
        
        # åŸºäºæŸå¤±å†å²è°ƒæ•´å­¦ä¹ ç‡
        if len(self.arch_loss_history) >= 5:
            recent_losses = self.arch_loss_history[-5:]
            if all(recent_losses[i] >= recent_losses[i+1] for i in range(len(recent_losses)-1)):
                # æŸå¤±åœ¨ä¸‹é™ï¼Œä¿æŒå­¦ä¹ ç‡
                pass
            else:
                # æŸå¤±ä¸ç¨³å®šï¼Œå‡å°å­¦ä¹ ç‡
                for param_group in self.optimizer.param_groups:
                    param_group['lr'] *= 0.95
                    
                if self.monitor:
                    self.monitor.logger.info(f"ğŸ”§ Architecture learning rate adjusted to {param_group['lr']:.6f}")
    
    def should_update_arch(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°æ¶æ„"""
        # é¢„çƒ­æœŸè·³è¿‡ï¼Œä½†è¦è€ƒè™‘æ€»è®­ç»ƒæ—¶é—´
        if self.current_epoch < self.warmup_epochs:
            return False
        
        # æ—©åœæ£€æŸ¥
        if self.no_improve_count >= self.arch_early_stop_patience:
            return False
        
        # æ™ºèƒ½é¢‘ç‡æ§åˆ¶
        self.arch_step_count += 1
        
        # æ ¹æ®å®é™…æƒ…å†µåŠ¨æ€è°ƒæ•´é¢‘ç‡
        if self.total_epochs <= 5:
            # çŸ­æ—¶é—´è®­ç»ƒï¼Œéœ€è¦æ›´é¢‘ç¹çš„æ¶æ„æ›´æ–°
            effective_freq = max(5, self.arch_update_freq // 20)
        elif self.total_epochs <= 10:
            effective_freq = max(10, self.arch_update_freq // 10)
        elif self.total_epochs <= 20:
            effective_freq = max(20, self.arch_update_freq // 5)
        else:
            # é•¿æ—¶é—´è®­ç»ƒï¼Œä½¿ç”¨åŸå§‹é¢‘ç‡
            effective_freq = self.arch_update_freq
        
        should_update = self.arch_step_count % effective_freq == 0
        
        if should_update and self.monitor and effective_freq != self.arch_update_freq:
            self.monitor.logger.info(f"ğŸ”§ Architecture update frequency auto-adjusted: "
                                   f"{self.arch_update_freq} -> {effective_freq} "
                                   f"(step {self.arch_step_count})")
        
        return should_update
    
    def step(self, input_train, target_train, input_valid, target_valid, eta, network_optimizer, unrolled):
        """ä¼˜åŒ–çš„æ¶æ„æ›´æ–°æ­¥éª¤"""
        if not self.should_update_arch():
            if self.monitor:
                self.monitor.log_architecture_step('arch_skip', 0.0)
            return
        
        if self.optimizer is None:
            return
        
        step_start_time = time.time()
        
        try:
            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
                if self.use_first_order or not unrolled:
                    # ä½¿ç”¨é«˜æ•ˆçš„ä¸€é˜¶è¿‘ä¼¼
                    self._step_first_order(input_valid, target_valid)
                else:
                    # ä½¿ç”¨äºŒé˜¶è¿‘ä¼¼ï¼ˆæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰
                    self._step_second_order(input_train, target_train, input_valid, target_valid, eta, network_optimizer)
        
        except RuntimeError as e:
            if "out of memory" in str(e):
                if self.monitor:
                    self.monitor.logger.warning(f"ğŸ”§ OOM in architecture step, falling back to first-order")
                torch.cuda.empty_cache()
                self._step_first_order(input_valid, target_valid)
            else:
                raise e
        
        step_time = time.time() - step_start_time
        
        if self.monitor:
            self.monitor.log_architecture_step('arch_update', step_time, {
                'method': 'first_order' if self.use_first_order else 'second_order',
                'accumulation_steps': self.grad_accumulation_steps
            })
    
    def _step_first_order(self, input_valid, target_valid):
        """é«˜æ•ˆçš„ä¸€é˜¶è¿‘ä¼¼æ›´æ–°"""
        if self.optimizer is None:
            return
            
        if self.grad_accumulation_steps <= 1:
            # ç›´æ¥æ›´æ–°
            self.optimizer.zero_grad()
            loss = self._compute_arch_loss(input_valid, target_valid)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            self._clip_arch_gradients()
            
            self.optimizer.step()
            self._update_arch_loss_history(loss.item())
        else:
            # æ¢¯åº¦ç´¯ç§¯
            self._step_with_accumulation(input_valid, target_valid)
    
    def _step_second_order(self, input_train, target_train, input_valid, target_valid, eta, network_optimizer):
        """äºŒé˜¶è¿‘ä¼¼æ›´æ–°ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if self.optimizer is None:
            return
            
        self.optimizer.zero_grad()
        
        # ä½¿ç”¨å†…å­˜æ•ˆç‡æ›´é«˜çš„äºŒé˜¶è¿‘ä¼¼
        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            # è®¡ç®—è™šæ‹Ÿæ¨¡å‹
            virtual_model = self._compute_virtual_model_efficient(input_train, target_train, eta, network_optimizer)
            
            # è®¡ç®—æ¶æ„æŸå¤±
            if self.criterion is None:
                raise ValueError("Criterion not set")
            arch_loss = self.criterion(virtual_model(input_valid), target_valid)
            
            # è®¡ç®—æ¢¯åº¦
            arch_grads = torch.autograd.grad(arch_loss, self.model.arch_parameters(), 
                                           create_graph=False, retain_graph=False)
            
            # åº”ç”¨æ¢¯åº¦
            for param, grad in zip(self.model.arch_parameters(), arch_grads):
                if param.grad is None:
                    param.grad = grad.detach()
                else:
                    param.grad.data.copy_(grad.detach())
        
        # æ¢¯åº¦è£å‰ª
        self._clip_arch_gradients()
        
        self.optimizer.step()
        self._update_arch_loss_history(arch_loss.item())
    
    def _compute_virtual_model_efficient(self, input_train, target_train, eta, network_optimizer):
        """å†…å­˜æ•ˆç‡æ›´é«˜çš„è™šæ‹Ÿæ¨¡å‹è®¡ç®—"""
        # è®¡ç®—å½“å‰æŸå¤±å’Œæ¢¯åº¦
        if self.criterion is None:
            raise ValueError("Criterion not set")
        self.model.zero_grad()
        loss = self.criterion(self.model(input_train), target_train)
        
        # è®¡ç®—æƒé‡æ¢¯åº¦
        weight_grads = torch.autograd.grad(loss, self.model.parameters(), 
                                         create_graph=False, retain_graph=False)
        
        # åˆ›å»ºè™šæ‹Ÿå‚æ•°
        virtual_params = []
        for param, grad in zip(self.model.parameters(), weight_grads):
            # ç®€åŒ–çš„æƒé‡æ›´æ–°ï¼ˆä¸è€ƒè™‘åŠ¨é‡ï¼‰
            virtual_param = param - eta * grad
            virtual_params.append(virtual_param)
        
        # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹
        virtual_model = self._create_virtual_model(virtual_params)
        return virtual_model
    
    def _create_virtual_model(self, virtual_params):
        """åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ï¼ˆå…±äº«æ¶æ„å‚æ•°ï¼‰"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„æ¨¡å‹ç»“æ„å®ç°
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥è¿”å›å½“å‰æ¨¡å‹
        return self.model
    
    def _step_with_accumulation(self, input_valid, target_valid):
        """ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯çš„æ›´æ–°"""
        if self.optimizer is None:
            return
            
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±
        loss = self._compute_arch_loss(input_valid, target_valid)
        loss = loss / self.grad_accumulation_steps
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        self.accumulation_count += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if self.accumulation_count >= self.grad_accumulation_steps:
            # æ¢¯åº¦è£å‰ª
            self._clip_arch_gradients()
            
            # æ›´æ–°å‚æ•°
            self.optimizer.step()
            self.optimizer.zero_grad()
            
            # é‡ç½®è®¡æ•°å™¨
            self.accumulation_count = 0
            
            # æ›´æ–°æŸå¤±å†å²
            self._update_arch_loss_history(loss.item() * self.grad_accumulation_steps)
    
    def _compute_arch_loss(self, input_valid, target_valid):
        """è®¡ç®—æ¶æ„æŸå¤±"""
        if self.criterion is None:
            raise ValueError("Criterion not set")
        logits = self.model(input_valid)
        loss = self.criterion(logits, target_valid)
        return loss
    
    def _clip_arch_gradients(self, max_norm: float = 5.0):
        """æ¶æ„æ¢¯åº¦è£å‰ª"""
        if self.model.arch_parameters():
            arch_params = list(self.model.arch_parameters())
            total_norm = torch.nn.utils.clip_grad_norm_(arch_params, max_norm)
            
            if self.monitor and total_norm > max_norm:
                self.monitor.logger.info(f"ğŸ”§ Architecture gradients clipped: {total_norm:.4f} -> {max_norm}")
    
    def _update_arch_loss_history(self, loss_value: float):
        """æ›´æ–°æ¶æ„æŸå¤±å†å²"""
        self.arch_loss_history.append(loss_value)
        
        # ä¿æŒå†å²è®°å½•é•¿åº¦
        if len(self.arch_loss_history) > 100:
            self.arch_loss_history = self.arch_loss_history[-100:]
        
        # æ—©åœæ£€æŸ¥
        if loss_value < self.last_arch_loss:
            self.last_arch_loss = loss_value
            self.no_improve_count = 0
        else:
            self.no_improve_count += 1
    
    def get_arch_statistics(self) -> Dict[str, Any]:
        """è·å–æ¶æ„æœç´¢ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'arch_step_count': self.arch_step_count,
            'current_epoch': self.current_epoch,
            'last_arch_loss': self.last_arch_loss,
            'no_improve_count': self.no_improve_count,
            'arch_loss_history_length': len(self.arch_loss_history)
        }
        
        if self.arch_loss_history:
            stats.update({
                'arch_loss_mean': np.mean(self.arch_loss_history[-10:]),
                'arch_loss_std': np.std(self.arch_loss_history[-10:]),
                'arch_loss_trend': self._compute_loss_trend()
            })
        
        return stats
    
    def _compute_loss_trend(self) -> str:
        """è®¡ç®—æŸå¤±è¶‹åŠ¿"""
        if len(self.arch_loss_history) < 5:
            return 'insufficient_data'
        
        recent_losses = self.arch_loss_history[-5:]
        trend = np.polyfit(range(len(recent_losses)), recent_losses, 1)[0]
        
        if trend < -0.001:
            return 'decreasing'
        elif trend > 0.001:
            return 'increasing'
        else:
            return 'stable'
    
    def cleanup_gradients(self):
        """æ¸…ç†æ¢¯åº¦å’Œå†…å­˜"""
        # æ¸…ç†æ¨¡å‹æ¢¯åº¦
        self.model.zero_grad()
        
        # æ¸…ç†æ¶æ„å‚æ•°æ¢¯åº¦
        for param in self.model.arch_parameters():
            if param.grad is not None:
                param.grad.data.zero_()
        
        # æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€
        if self.optimizer is not None:
            self.optimizer.zero_grad()
        
        # æ¸…ç†ç´¯ç§¯æ¢¯åº¦
        self.accumulated_grads = None
        self.accumulation_count = 0
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # æ¸…ç†CUDAç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    def save_checkpoint(self, filepath: str):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'arch_step_count': self.arch_step_count,
            'current_epoch': self.current_epoch,
            'last_arch_loss': self.last_arch_loss,
            'arch_loss_history': self.arch_loss_history,
            'no_improve_count': self.no_improve_count,
            'optimizer_state_dict': self.optimizer.state_dict() if self.optimizer else None
        }
        
        torch.save(checkpoint, filepath)
        
        if self.monitor:
            self.monitor.logger.info(f"ğŸ’¾ Architecture checkpoint saved to {filepath}")
    
    def load_checkpoint(self, filepath: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(filepath, map_location='cpu')
        
        self.arch_step_count = checkpoint['arch_step_count']
        self.current_epoch = checkpoint['current_epoch']
        self.last_arch_loss = checkpoint['last_arch_loss']
        self.arch_loss_history = checkpoint['arch_loss_history']
        self.no_improve_count = checkpoint['no_improve_count']
        
        if self.optimizer and checkpoint['optimizer_state_dict']:
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if self.monitor:
            self.monitor.logger.info(f"ğŸ“‚ Architecture checkpoint loaded from {filepath}")


class ArchitectureSpaceOptimizer:
    """
    æ¶æ„ç©ºé—´ä¼˜åŒ–å™¨ï¼Œå¤ç”¨PyTorchçš„å‚æ•°ä¼˜åŒ–æ€è·¯
    """
    
    def __init__(self, model, optimizer_config: Dict[str, Any], monitor: Optional[PerformanceMonitor] = None):
        self.model = model
        self.monitor = monitor
        self.config = optimizer_config
        
        # åˆ›å»ºå‚æ•°ç»„
        self.param_groups = self._create_parameter_groups()
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = self._create_optimizer()
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = self._create_scheduler()
        
        if self.monitor:
            self.monitor.logger.info(f"ğŸ”§ ArchitectureSpaceOptimizer initialized with {len(self.param_groups)} parameter groups")
    
    def _create_parameter_groups(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºå‚æ•°ç»„ï¼Œä¸ºä¸åŒç±»å‹çš„æ¶æ„å‚æ•°è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡"""
        param_groups = []
        
        # æ­£å¸¸å•å…ƒçš„æ¶æ„å‚æ•°
        normal_params = []
        # é™ç»´å•å…ƒçš„æ¶æ„å‚æ•°
        reduce_params = []
        # æ·±åº¦ç›¸å…³çš„æ¶æ„å‚æ•°
        depth_params = []
        
        for name, param in self.model.named_parameters():
            if 'arch' in name.lower() or 'alpha' in name.lower():
                if 'normal' in name.lower():
                    normal_params.append(param)
                elif 'reduce' in name.lower():
                    reduce_params.append(param)
                elif 'depth' in name.lower() or 'gate' in name.lower():
                    depth_params.append(param)
        
        # ä¸ºä¸åŒç±»å‹çš„å‚æ•°è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡
        if normal_params:
            param_groups.append({
                'params': normal_params,
                'lr': self.config.get('normal_lr', 3e-4),
                'weight_decay': self.config.get('normal_wd', 1e-3),
                'name': 'normal_arch'
            })
        
        if reduce_params:
            param_groups.append({
                'params': reduce_params,
                'lr': self.config.get('reduce_lr', 3e-4),
                'weight_decay': self.config.get('reduce_wd', 1e-3),
                'name': 'reduce_arch'
            })
        
        if depth_params:
            param_groups.append({
                'params': depth_params,
                'lr': self.config.get('depth_lr', 6e-4),
                'weight_decay': self.config.get('depth_wd', 1e-4),
                'name': 'depth_arch'
            })
        
        return param_groups
    
    def _create_optimizer(self):
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        optimizer_type = self.config.get('type', 'adamw')
        
        if optimizer_type.lower() == 'adamw':
            return torch.optim.AdamW(self.param_groups, amsgrad=True)
        elif optimizer_type.lower() == 'adam':
            return torch.optim.Adam(self.param_groups, amsgrad=True)
        elif optimizer_type.lower() == 'sgd':
            return torch.optim.SGD(self.param_groups, momentum=0.9, nesterov=True)
        else:
            raise ValueError(f"Unsupported optimizer type: {optimizer_type}")
    
    def _create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler_type = self.config.get('scheduler', 'cosine')
        
        if scheduler_type == 'cosine':
            return torch.optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, 
                T_max=self.config.get('max_epochs', 50),
                eta_min=self.config.get('min_lr', 1e-6)
            )
        elif scheduler_type == 'step':
            return torch.optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.get('step_size', 20),
                gamma=self.config.get('gamma', 0.5)
            )
        elif scheduler_type == 'none':
            return None
        else:
            raise ValueError(f"Unsupported scheduler type: {scheduler_type}")
    
    def step(self, loss):
        """æ‰§è¡Œä¸€æ­¥ä¼˜åŒ–"""
        self.optimizer.zero_grad()
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        if self.config.get('grad_clip', 0) > 0:
            torch.nn.utils.clip_grad_norm_(
                [p for group in self.param_groups for p in group['params']],
                self.config['grad_clip']
            )
        
        self.optimizer.step()
        
        # æ›´æ–°å­¦ä¹ ç‡
        if self.scheduler:
            self.scheduler.step()
    
    def get_lr(self):
        """è·å–å½“å‰å­¦ä¹ ç‡"""
        return [group['lr'] for group in self.optimizer.param_groups]
    
    def state_dict(self):
        """è·å–çŠ¶æ€å­—å…¸"""
        return {
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict() if self.scheduler else None
        }
    
    def load_state_dict(self, state_dict):
        """åŠ è½½çŠ¶æ€å­—å…¸"""
        self.optimizer.load_state_dict(state_dict['optimizer'])
        if self.scheduler and state_dict['scheduler']:
            self.scheduler.load_state_dict(state_dict['scheduler']) 