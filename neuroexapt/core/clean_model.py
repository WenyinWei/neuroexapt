#!/usr/bin/env python3
"""
@defgroup group_clean_model Clean Model
@ingroup core
Clean Model module for NeuroExapt framework.


ğŸ”§ å®Œå…¨é‡æ„çš„å¹²å‡€æ¨¡å‹å®ç°
ä¿®å¤æ‰€æœ‰é€šé“æ•°è®¡ç®—é—®é¢˜ï¼Œæä¾›å¯é çš„åŸºç¡€æ¶æ„
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Optional
import time

from .operations import OPS, MixedOp, ReLUConvBN, FactorizedReduce
from .genotypes import PRIMITIVES, Genotype

class CleanCell(nn.Module):
    """
    å®Œå…¨é‡æ„çš„Cellå®ç° - ä¿è¯é€šé“æ•°è®¡ç®—æ­£ç¡®
    """
    def __init__(self, steps: int, block_multiplier: int, 
                 C_prev_prev: int, C_prev: int, C: int, 
                 reduction: bool, reduction_prev: bool):
        super(CleanCell, self).__init__()
        
        self.reduction = reduction
        self.steps = steps
        self.block_multiplier = block_multiplier
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿é¢„å¤„ç†å±‚é€šé“æ•°æ­£ç¡®
        if reduction_prev:
            # å‰ä¸€å±‚æ˜¯reductionï¼Œéœ€è¦FactorizedReduce
            self.preprocess0 = FactorizedReduce(C_prev_prev, C, affine=False)
        else:
            # å‰ä¸€å±‚æ˜¯normalï¼Œä½¿ç”¨1x1 convè°ƒæ•´é€šé“æ•°
            self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, affine=False)
        
        # s1çš„é¢„å¤„ç† - ä»C_prevè°ƒæ•´åˆ°C
        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, affine=False)
        
        # åˆ›å»ºMixedOp - æ‰€æœ‰æ“ä½œçš„è¾“å…¥è¾“å‡ºé€šé“æ•°éƒ½æ˜¯C
        self._ops = nn.ModuleList()
        for i in range(steps):
            for j in range(2 + i):  # æ¯ä¸ªèŠ‚ç‚¹è¿æ¥åˆ°å‰é¢æ‰€æœ‰èŠ‚ç‚¹
                # åœ¨reduction cellä¸­ï¼Œå‰ä¸¤ä¸ªèŠ‚ç‚¹çš„æ“ä½œä½¿ç”¨stride=2
                stride = 2 if reduction and j < 2 else 1
                op = MixedOp(C, stride)  # ä½¿ç”¨æœ€åŸºç¡€çš„MixedOp
                self._ops.append(op)
    
    def forward(self, s0: torch.Tensor, s1: torch.Tensor, weights: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­ - ç¡®ä¿å°ºå¯¸å’Œé€šé“æ•°æ­£ç¡®"""
        
        # é¢„å¤„ç†ï¼šè°ƒæ•´è¾“å…¥åˆ°ç»Ÿä¸€çš„é€šé“æ•°C
        s0 = self.preprocess0(s0)  # [B, C_prev_prev, H, W] -> [B, C, H', W']
        s1 = self.preprocess1(s1)  # [B, C_prev, H, W] -> [B, C, H, W]
        
        # ç¡®ä¿s0å’Œs1çš„ç©ºé—´å°ºå¯¸åŒ¹é…
        if s0.shape[2:] != s1.shape[2:]:
            # å¦‚æœå°ºå¯¸ä¸åŒ¹é…ï¼Œè°ƒæ•´s0åˆ°s1çš„å°ºå¯¸
            s0 = F.interpolate(s0, size=s1.shape[2:], mode='bilinear', align_corners=False)
        
        states = [s0, s1]  # åˆå§‹çŠ¶æ€
        offset = 0
        
        # é€æ­¥æ„å»ºä¸­é—´èŠ‚ç‚¹
        for i in range(self.steps):
            # æ”¶é›†å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰è¾“å…¥
            node_inputs = []
            for j in range(len(states)):  # è¿æ¥åˆ°å‰é¢æ‰€æœ‰çŠ¶æ€
                op_idx = offset + j
                if op_idx < len(self._ops) and op_idx < len(weights):
                    h = self._ops[op_idx](states[j], weights[op_idx])
                    node_inputs.append(h)
            
            # æ±‚å’Œå¾—åˆ°æ–°èŠ‚ç‚¹
            if node_inputs:
                # ç¡®ä¿æ‰€æœ‰è¾“å…¥å°ºå¯¸åŒ¹é…
                target_size = node_inputs[0].shape[2:]
                aligned_inputs = []
                for inp in node_inputs:
                    if inp.shape[2:] != target_size:
                        inp = F.interpolate(inp, size=target_size, mode='bilinear', align_corners=False)
                    aligned_inputs.append(inp)
                
                new_state = sum(aligned_inputs)
            else:
                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆè¾“å…¥ï¼Œåˆ›å»ºé›¶å¼ é‡
                new_state = torch.zeros_like(states[-1])
            
            states.append(new_state)
            offset += len(states) - 1  # æ›´æ–°offset
        
        # è¾“å‡ºï¼šè¿æ¥æœ€åblock_multiplierä¸ªçŠ¶æ€
        output_states = states[-self.block_multiplier:]
        
        # ç¡®ä¿æ‰€æœ‰è¾“å‡ºçŠ¶æ€å°ºå¯¸åŒ¹é…
        if len(output_states) > 1:
            target_size = output_states[0].shape[2:]
            aligned_outputs = []
            for state in output_states:
                if state.shape[2:] != target_size:
                    state = F.interpolate(state, size=target_size, mode='bilinear', align_corners=False)
                aligned_outputs.append(state)
            output_states = aligned_outputs
        
        result = torch.cat(output_states, dim=1)  # [B, C*block_multiplier, H, W]
        return result

class CleanNetwork(nn.Module):
    """
    å®Œå…¨é‡æ„çš„Networkå®ç° - ä¿è¯é€šé“æ•°æµåŠ¨æ­£ç¡®
    """
    def __init__(self, C: int, num_classes: int, layers: int, 
                 steps: int = 4, block_multiplier: int = 4):
        super(CleanNetwork, self).__init__()
        
        self._C = C
        self._num_classes = num_classes
        self._layers = layers
        self._steps = steps
        self._block_multiplier = block_multiplier
        
        # Stem: 3 -> C*block_multiplier
        stem_channels = C * block_multiplier
        self.stem = nn.Sequential(
            nn.Conv2d(3, stem_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(stem_channels)
        )
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®çš„é€šé“æ•°åˆå§‹åŒ–å’ŒæµåŠ¨
        self.cells = nn.ModuleList()
        
        # åˆå§‹é€šé“è®¾ç½®
        C_prev_prev = stem_channels  # stemè¾“å‡º
        C_prev = stem_channels       # ç¬¬ä¸€ä¸ªcellçš„è¾“å…¥
        C_curr = C                   # æ¯ä¸ªcellå†…éƒ¨çš„é€šé“æ•°
        reduction_prev = False
        
        print(f"ğŸ”§ å¹²å‡€æ¨¡å‹é€šé“æ•°æµåŠ¨:")
        print(f"   Stem: 3 -> {stem_channels}")
        print(f"   åˆå§‹: C_prev_prev={C_prev_prev}, C_prev={C_prev}, C_curr={C_curr}")
        
        for i in range(layers):
            # ç¡®å®šæ˜¯å¦æ˜¯reduction layer
            if i in [layers // 3, 2 * layers // 3]:
                C_curr *= 2  # reduction layeré€šé“æ•°ç¿»å€
                reduction = True
                print(f"   Layer {i}: Reductionå±‚, C_curr={C_curr}")
            else:
                reduction = False
                print(f"   Layer {i}: Normalå±‚, C_curr={C_curr}")
            
            # åˆ›å»ºCell
            cell = CleanCell(
                steps=steps,
                block_multiplier=block_multiplier,
                C_prev_prev=C_prev_prev,
                C_prev=C_prev, 
                C=C_curr,
                reduction=reduction,
                reduction_prev=reduction_prev
            )
            self.cells.append(cell)
            
            # æ›´æ–°ä¸‹ä¸€è½®çš„é€šé“æ•°
            reduction_prev = reduction
            C_prev_prev = C_prev
            C_prev = C_curr * block_multiplier  # cellè¾“å‡ºçš„é€šé“æ•°
            
            print(f"     -> è¾“å‡º: {C_prev}, ä¸‹ä¸€è½®: C_prev_prev={C_prev_prev}, C_prev={C_prev}")
        
        # åˆ†ç±»å™¨
        self.global_pooling = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Linear(C_prev, num_classes)
        
        # åˆå§‹åŒ–æ¶æ„å‚æ•°
        self._initialize_alphas()
        
        print(f"   æœ€ç»ˆåˆ†ç±»å™¨è¾“å…¥: {C_prev} -> {num_classes}")
        print(f"âœ… å¹²å‡€æ¨¡å‹æ„å»ºå®Œæˆ!")
    
    def _initialize_alphas(self):
        """åˆå§‹åŒ–æ¶æ„å‚æ•°"""
        k = sum(1 for i in range(self._steps) for n in range(2 + i))
        num_ops = len(PRIMITIVES)
        
        self.alphas_normal = nn.Parameter(1e-3 * torch.randn(k, num_ops))
        self.alphas_reduce = nn.Parameter(1e-3 * torch.randn(k, num_ops))
        
        self._arch_parameters = [self.alphas_normal, self.alphas_reduce]
    
    def arch_parameters(self):
        return self._arch_parameters
    
    def forward(self, input: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­ - ç¡®ä¿å°ºå¯¸å’Œé€šé“æ•°æ­£ç¡®"""
        
        # é¢„è®¡ç®—æ¶æ„æƒé‡
        weights_normal = F.softmax(self.alphas_normal, dim=-1)
        weights_reduce = F.softmax(self.alphas_reduce, dim=-1)
        
        # Stemå¤„ç†
        s0 = s1 = self.stem(input)  # [B, 3, 32, 32] -> [B, C*4, 32, 32]
        
        # é€å±‚å¤„ç†
        for i, cell in enumerate(self.cells):
            # é€‰æ‹©æƒé‡
            if cell.reduction:
                weights = weights_reduce
            else:
                weights = weights_normal
            
            # Cellå‰å‘ä¼ æ’­
            s0, s1 = s1, cell(s0, s1, weights)
        
        # å…¨å±€æ± åŒ–å’Œåˆ†ç±»
        out = self.global_pooling(s1)  # [B, C_final, H, W] -> [B, C_final, 1, 1]
        logits = self.classifier(out.view(out.size(0), -1))  # [B, C_final] -> [B, num_classes]
        
        return logits
    
    def genotype(self):
        """è§£ç æ¶æ„"""
        def _parse(weights):
            gene = []
            n = 2
            start = 0
            for i in range(self._steps):
                end = start + n
                W = weights[start:end].copy()
                edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) 
                              if k != PRIMITIVES.index('none')))[:2]
                for j in edges:
                    k_best = None
                    for k in range(len(W[j])):
                        if k != PRIMITIVES.index('none'):
                            if k_best is None or W[j][k] > W[j][k_best]:
                                k_best = k
                    # ç¡®ä¿k_bestä¸ä¸ºNone
                    if k_best is None:
                        k_best = 1  # é»˜è®¤ä½¿ç”¨skip_connect
                    gene.append((PRIMITIVES[k_best], j))
                start = end
                n += 1
            return gene
        
        gene_normal = _parse(F.softmax(self.alphas_normal, dim=-1).data.cpu().numpy())
        gene_reduce = _parse(F.softmax(self.alphas_reduce, dim=-1).data.cpu().numpy())
        
        concat = range(2 + self._steps - self._block_multiplier, self._steps + 2)
        return Genotype(
            normal=gene_normal, normal_concat=concat,
            reduce=gene_reduce, reduce_concat=concat
        )

def create_clean_network(C: int = 16, num_classes: int = 10, layers: int = 8) -> CleanNetwork:
    """
    åˆ›å»ºå¹²å‡€çš„ç½‘ç»œå®ä¾‹
    
    Args:
        C: åŸºç¡€é€šé“æ•°
        num_classes: åˆ†ç±»æ•°
        layers: å±‚æ•°
    
    Returns:
        å¹²å‡€çš„ç½‘ç»œæ¨¡å‹
    """
    return CleanNetwork(C=C, num_classes=num_classes, layers=layers) 