"""
æ™ºèƒ½æ”¶æ•›ç›‘æ§æ¨¡å—
ç›‘æ§ç½‘ç»œåœ¨å˜å¼‚åçš„æ”¶æ•›çŠ¶æ€ï¼Œå†³å®šä½•æ—¶è¿›è¡Œä¸‹ä¸€æ¬¡å˜å¼‚
"""

import torch
import numpy as np
from typing import Dict, List, Any, Optional
import logging
from collections import deque

logger = logging.getLogger(__name__)


class IntelligentConvergenceMonitor:
    """
    æ™ºèƒ½æ”¶æ•›ç›‘æ§å™¨
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. å˜å¼‚åå¿…é¡»ç­‰å¾…ç½‘ç»œå……åˆ†é€‚åº”æ–°æ¶æ„
    2. æ£€æµ‹æ€§èƒ½é¥±å’Œå’Œæ”¶æ•›ç¨³å®šæ€§
    3. åªæœ‰åœ¨ç½‘ç»œç¨³å®šä¸”å‡ºç°ç“¶é¢ˆæ—¶æ‰å…è®¸ä¸‹ä¸€æ¬¡å˜å¼‚
    """
    
    def __init__(self):
        # æ€§èƒ½å†å²è¿½è¸ª
        self.performance_history = deque(maxlen=20)
        self.loss_history = deque(maxlen=20) 
        self.gradient_norm_history = deque(maxlen=15)
        
        # å˜å¼‚å†å²è¿½è¸ª
        self.last_morphogenesis_epoch = -1
        self.morphogenesis_history = []
        self.post_morphogenesis_performance = []
        
        # æ”¶æ•›æ£€æµ‹å‚æ•°
        self.min_epochs_between_morphogenesis = 8  # å˜å¼‚é—´æœ€å°é—´éš”
        self.convergence_patience = 5              # æ”¶æ•›æ£€æµ‹è€å¿ƒå€¼
        self.stability_threshold = 0.02            # ç¨³å®šæ€§é˜ˆå€¼
        
        # æ€§èƒ½é¥±å’Œæ£€æµ‹
        self.saturation_window = 6                 # é¥±å’Œæ£€æµ‹çª—å£
        self.improvement_threshold = 0.01          # æ”¹è¿›é˜ˆå€¼
        
    def should_allow_morphogenesis(self, 
                                  current_epoch: int,
                                  current_performance: float,
                                  current_loss: float,
                                  gradient_norm: Optional[float] = None) -> Dict[str, Any]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å…è®¸å½¢æ€å‘ç”Ÿ
        
        Returns:
            DictåŒ…å«æ˜¯å¦å…è®¸ã€åŸå› ã€å»ºè®®ç­‰ä¿¡æ¯
        """
        
        # æ›´æ–°å†å²
        self.performance_history.append(current_performance)
        self.loss_history.append(current_loss)
        if gradient_norm is not None:
            self.gradient_norm_history.append(gradient_norm)
        
        # 1. æ£€æŸ¥å˜å¼‚é—´éš”
        epochs_since_last = current_epoch - self.last_morphogenesis_epoch
        if epochs_since_last < self.min_epochs_between_morphogenesis:
            return {
                'allow': False,
                'reason': 'insufficient_time_since_last_morphogenesis',
                'suggestion': f'ç­‰å¾…è‡³å°‘{self.min_epochs_between_morphogenesis}ä¸ªepochåå†å˜å¼‚',
                'epochs_to_wait': self.min_epochs_between_morphogenesis - epochs_since_last,
                'confidence': 0.9
            }
        
        # 2. æ£€æŸ¥ç½‘ç»œæ”¶æ•›çŠ¶æ€
        convergence_analysis = self._analyze_convergence()
        if not convergence_analysis['converged']:
            return {
                'allow': False,
                'reason': 'network_not_converged',
                'suggestion': 'ç½‘ç»œä»åœ¨é€‚åº”ä¸Šæ¬¡å˜å¼‚ï¼Œéœ€è¦æ›´å¤šæ—¶é—´æ”¶æ•›',
                'convergence_info': convergence_analysis,
                'confidence': 0.8
            }
        
        # 3. æ£€æŸ¥æ€§èƒ½é¥±å’ŒçŠ¶æ€
        saturation_analysis = self._analyze_performance_saturation()
        if not saturation_analysis['saturated']:
            return {
                'allow': False,
                'reason': 'performance_still_improving',
                'suggestion': 'ç½‘ç»œæ€§èƒ½ä»åœ¨æå‡ï¼Œæ— éœ€å˜å¼‚',
                'saturation_info': saturation_analysis,
                'confidence': 0.7
            }
        
        # 4. æ·±åº¦åˆ†æå˜å¼‚å¿…è¦æ€§
        necessity_analysis = self._analyze_morphogenesis_necessity(current_epoch)
        
        if necessity_analysis['urgency_score'] < 0.6:
            return {
                'allow': False,
                'reason': 'low_morphogenesis_urgency',
                'suggestion': 'å½“å‰ç½‘ç»œçŠ¶æ€è‰¯å¥½ï¼Œå˜å¼‚ä¸ç´§æ€¥',
                'necessity_info': necessity_analysis,
                'confidence': 0.6
            }
        
        # 5. æ‰€æœ‰æ¡ä»¶æ»¡è¶³ï¼Œå…è®¸å˜å¼‚
        return {
            'allow': True,
            'reason': 'optimal_morphogenesis_timing',
            'confidence': min(0.95, necessity_analysis['urgency_score']),
            'convergence_info': convergence_analysis,
            'saturation_info': saturation_analysis,
            'necessity_info': necessity_analysis,
            'suggestion': 'ç½‘ç»œå·²æ”¶æ•›ä¸”å‡ºç°ç“¶é¢ˆï¼Œå»ºè®®è¿›è¡Œæ™ºèƒ½å˜å¼‚'
        }
    
    def _analyze_convergence(self) -> Dict[str, Any]:
        """åˆ†æç½‘ç»œæ”¶æ•›çŠ¶æ€"""
        
        if len(self.performance_history) < self.convergence_patience:
            return {
                'converged': False,
                'reason': 'insufficient_data',
                'stability_score': 0.0
            }
        
        # è®¡ç®—æ€§èƒ½ç¨³å®šæ€§
        recent_performance = list(self.performance_history)[-self.convergence_patience:]
        performance_std = np.std(recent_performance)
        performance_mean = np.mean(recent_performance)
        
        # ç›¸å¯¹æ ‡å‡†å·®ä½œä¸ºç¨³å®šæ€§æŒ‡æ ‡
        relative_std = performance_std / max(performance_mean, 0.01)
        stability_score = max(0, 1 - relative_std / self.stability_threshold)
        
        # æ£€æŸ¥æŸå¤±æ”¶æ•›
        if len(self.loss_history) >= self.convergence_patience:
            recent_loss = list(self.loss_history)[-self.convergence_patience:]
            loss_trend = np.polyfit(range(len(recent_loss)), recent_loss, 1)[0]
            # æŸå¤±ä¸‹é™è¶‹åŠ¿åº”è¯¥å¹³ç¼“
            loss_converged = abs(loss_trend) < 0.01
        else:
            loss_converged = False
        
        # æ£€æŸ¥æ¢¯åº¦èŒƒæ•°ç¨³å®šæ€§
        gradient_stable = True
        if len(self.gradient_norm_history) >= 5:
            recent_grads = list(self.gradient_norm_history)[-5:]
            grad_std = np.std(recent_grads)
            grad_mean = np.mean(recent_grads)
            if grad_mean > 0:
                grad_relative_std = grad_std / grad_mean
                gradient_stable = grad_relative_std < 0.3
        
        converged = (stability_score > 0.7 and loss_converged and gradient_stable)
        
        return {
            'converged': converged,
            'stability_score': stability_score,
            'relative_std': relative_std,
            'loss_converged': loss_converged,
            'gradient_stable': gradient_stable,
            'performance_trend': np.polyfit(range(len(recent_performance)), recent_performance, 1)[0]
        }
    
    def _analyze_performance_saturation(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½é¥±å’ŒçŠ¶æ€"""
        
        if len(self.performance_history) < self.saturation_window:
            return {
                'saturated': False,
                'reason': 'insufficient_data',
                'saturation_score': 0.0
            }
        
        recent_performance = list(self.performance_history)[-self.saturation_window:]
        
        # è®¡ç®—æœ€è¿‘çš„æ”¹è¿›ç‡
        first_half = recent_performance[:len(recent_performance)//2]
        second_half = recent_performance[len(recent_performance)//2:]
        
        improvement = np.mean(second_half) - np.mean(first_half)
        relative_improvement = improvement / max(np.mean(first_half), 0.01)
        
        # è®¡ç®—é¥±å’Œåˆ†æ•°
        saturation_score = max(0, 1 - relative_improvement / self.improvement_threshold)
        
        # æ£€æŸ¥æ˜¯å¦å‡ºç°æ€§èƒ½åœæ»æˆ–ä¸‹é™
        performance_trend = np.polyfit(range(len(recent_performance)), recent_performance, 1)[0]
        saturated = (saturation_score > 0.8 or performance_trend <= 0)
        
        return {
            'saturated': saturated,
            'saturation_score': saturation_score,
            'improvement': improvement,
            'relative_improvement': relative_improvement,
            'performance_trend': performance_trend,
            'recent_performance': recent_performance
        }
    
    def _analyze_morphogenesis_necessity(self, current_epoch: int) -> Dict[str, Any]:
        """åˆ†æå˜å¼‚å¿…è¦æ€§"""
        
        urgency_factors = []
        
        # 1. æ€§èƒ½åœæ»ç´§æ€¥åº¦
        if len(self.performance_history) >= 10:
            recent_10 = list(self.performance_history)[-10:]
            max_perf = max(recent_10)
            current_perf = recent_10[-1]
            stagnation_urgency = (max_perf - current_perf) / max(max_perf, 0.01)
            urgency_factors.append(('stagnation', min(1.0, stagnation_urgency * 3)))
        
        # 2. è®­ç»ƒè¿›åº¦ç´§æ€¥åº¦
        training_progress = current_epoch / 80.0  # å‡è®¾æ€»å…±80ä¸ªepoch
        progress_urgency = min(1.0, training_progress * 1.5)  # åæœŸæ›´ç´§æ€¥
        urgency_factors.append(('training_progress', progress_urgency))
        
        # 3. å†å²å˜å¼‚æ•ˆæœ
        if self.morphogenesis_history:
            last_morphogenesis = self.morphogenesis_history[-1]
            epochs_since = current_epoch - last_morphogenesis['epoch']
            # å¦‚æœä¸Šæ¬¡å˜å¼‚æ•ˆæœä¸ä½³ï¼Œæé«˜ç´§æ€¥åº¦
            if last_morphogenesis.get('performance_improvement', 0) < 0.02:
                history_urgency = min(1.0, epochs_since / 10.0)
                urgency_factors.append(('poor_history', history_urgency))
        
        # 4. æ€§èƒ½æ°´å¹³ç»å¯¹å€¼
        if self.performance_history:
            current_perf = self.performance_history[-1]
            # æ€§èƒ½è¶Šä½ï¼Œå˜å¼‚è¶Šç´§æ€¥
            performance_urgency = max(0, 1 - current_perf / 0.9)  # 90%ä»¥ä¸Šä¸ç´§æ€¥
            urgency_factors.append(('absolute_performance', performance_urgency))
        
        # ç»¼åˆç´§æ€¥åº¦è¯„åˆ†
        if urgency_factors:
            weights = [1.0, 0.8, 0.6, 0.7][:len(urgency_factors)]
            urgency_score = sum(w * f[1] for w, f in zip(weights, urgency_factors)) / sum(weights)
        else:
            urgency_score = 0.5
        
        return {
            'urgency_score': urgency_score,
            'urgency_factors': urgency_factors,
            'recommendation': self._generate_urgency_recommendation(urgency_score)
        }
    
    def _generate_urgency_recommendation(self, urgency_score: float) -> str:
        """ç”Ÿæˆç´§æ€¥åº¦å»ºè®®"""
        if urgency_score > 0.8:
            return "å¼ºçƒˆå»ºè®®ç«‹å³è¿›è¡Œæ¿€è¿›å˜å¼‚ä»¥çªç ´ç“¶é¢ˆ"
        elif urgency_score > 0.6:
            return "å»ºè®®è¿›è¡Œé€‚åº¦å˜å¼‚ä»¥æ”¹å–„æ€§èƒ½"
        elif urgency_score > 0.4:
            return "å¯è€ƒè™‘ä¿å®ˆå˜å¼‚ï¼Œä½†ä¸ç´§æ€¥"
        else:
            return "å½“å‰çŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒ"
    
    def record_morphogenesis(self, 
                           epoch: int, 
                           morphogenesis_type: str,
                           performance_before: float,
                           performance_after: Optional[float] = None) -> None:
        """è®°å½•å˜å¼‚äº‹ä»¶"""
        
        self.last_morphogenesis_epoch = epoch
        
        morphogenesis_record = {
            'epoch': epoch,
            'type': morphogenesis_type,
            'performance_before': performance_before,
            'performance_after': performance_after
        }
        
        # å¦‚æœæœ‰ä¹‹å‰çš„è®°å½•ï¼Œè®¡ç®—æ”¹è¿›
        if len(self.morphogenesis_history) > 0 and performance_after is not None:
            prev_record = self.morphogenesis_history[-1]
            improvement = performance_after - prev_record.get('performance_before', 0)
            morphogenesis_record['performance_improvement'] = improvement
        
        self.morphogenesis_history.append(morphogenesis_record)
        logger.info(f"ğŸ“ è®°å½•å˜å¼‚: Epoch {epoch}, ç±»å‹: {morphogenesis_type}")
    
    def get_convergence_report(self) -> Dict[str, Any]:
        """è·å–æ”¶æ•›çŠ¶æ€æŠ¥å‘Š"""
        
        if not self.performance_history:
            return {'status': 'no_data'}
        
        convergence_info = self._analyze_convergence()
        saturation_info = self._analyze_performance_saturation()
        
        return {
            'current_performance': self.performance_history[-1] if self.performance_history else 0,
            'performance_trend': convergence_info.get('performance_trend', 0),
            'stability_score': convergence_info.get('stability_score', 0),
            'saturation_score': saturation_info.get('saturation_score', 0),
            'converged': convergence_info.get('converged', False),
            'saturated': saturation_info.get('saturated', False),
            'epochs_since_last_morphogenesis': len(self.performance_history) - 1 if self.last_morphogenesis_epoch >= 0 else -1,
            'morphogenesis_count': len(self.morphogenesis_history)
        }