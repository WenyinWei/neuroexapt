#!/usr/bin/env python3
"""
defgroup group_aggressive_morphogenesis Aggressive Morphogenesis
ingroup core
Aggressive Morphogenesis module for NeuroExapt framework.
"""

æ¿€è¿›å¤šç‚¹å½¢æ€å‘ç”Ÿç³»ç»Ÿ - Aggressive Multi-Point Morphogenesis

ğŸ¯ ä¸“é—¨é’ˆå¯¹å‡†ç¡®ç‡é¥±å’ŒçŠ¶æ€çš„æ¿€è¿›æ¶æ„å˜å¼‚ç­–ç•¥
- å¤šç‚¹åŒæ­¥å˜å¼‚
- åå‘æ¢¯åº¦æŠ•å½±åˆ†æ
- å‚æ•°ç©ºé—´æ‰©å±•ä¼˜åŒ–
- åŠ¨æ€ç“¶é¢ˆè¯†åˆ«ä¸çªç ´
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass
from collections import defaultdict
import logging
import copy

from .logging_utils import logger
from .advanced_morphogenesis import MorphogenesisType, MorphogenesisDecision

@dataclass
class MultiPointMutation:
    """å¤šç‚¹å˜å¼‚å†³ç­–"""
    target_locations: List[str]  # å¤šä¸ªå˜å¼‚ä½ç½®
    mutation_types: List[MorphogenesisType]  # å¯¹åº”çš„å˜å¼‚ç±»å‹
    coordination_strategy: str  # åè°ƒç­–ç•¥: 'parallel', 'cascade', 'hybrid'
    expected_improvement: float
    risk_assessment: float
    parameter_budget: int

@dataclass
class BottleneckSignature:
    """ç“¶é¢ˆç‰¹å¾ç­¾å"""
    layer_name: str
    bottleneck_type: str  # 'gradient_vanishing', 'activation_saturation', 'capacity_limit', 'information_loss'
    severity: float
    upstream_impact: float  # å¯¹ä¸Šæ¸¸çš„å½±å“
    downstream_impact: float  # å¯¹ä¸‹æ¸¸çš„å½±å“
    parameter_efficiency: float  # å‚æ•°æ•ˆç‡

class AggressiveMorphogenesisAnalyzer:
    """æ¿€è¿›å½¢æ€å‘ç”Ÿåˆ†æå™¨"""
    
    def __init__(self, 
                 accuracy_plateau_threshold: float = 0.1,  # å‡†ç¡®ç‡åœæ»é˜ˆå€¼
                 plateau_window: int = 5,  # åœæ»æ£€æµ‹çª—å£
                 aggressive_trigger_threshold: float = 0.05):  # æ¿€è¿›è§¦å‘é˜ˆå€¼
        self.accuracy_plateau_threshold = accuracy_plateau_threshold
        self.plateau_window = plateau_window
        self.aggressive_trigger_threshold = aggressive_trigger_threshold
        self.accuracy_history = []
        self.bottleneck_history = []
        
    def detect_accuracy_plateau(self, performance_history: List[float]) -> Tuple[bool, float]:
        """æ£€æµ‹å‡†ç¡®ç‡åœæ»çŠ¶æ€"""
        if len(performance_history) < self.plateau_window:
            return False, 0.0
            
        recent_performance = performance_history[-self.plateau_window:]
        improvement = max(recent_performance) - min(recent_performance)
        
        is_plateau = improvement < self.accuracy_plateau_threshold
        stagnation_severity = 1.0 - (improvement / self.accuracy_plateau_threshold)
        
        logger.info(f"å‡†ç¡®ç‡åœæ»æ£€æµ‹: æ”¹è¿›={improvement:.4f}, é˜ˆå€¼={self.accuracy_plateau_threshold:.4f}, ä¸¥é‡ç¨‹åº¦={stagnation_severity:.4f}")
        
        return is_plateau, stagnation_severity
    
    def analyze_reverse_gradient_projection(self, 
                                          activations: Dict[str, torch.Tensor],
                                          gradients: Dict[str, torch.Tensor],
                                          output_targets: torch.Tensor) -> Dict[str, BottleneckSignature]:
        """åå‘æ¢¯åº¦æŠ•å½±åˆ†æ - ä»è¾“å‡ºåæ¨å…³é”®ç“¶é¢ˆå±‚"""
        logger.enter_section("åå‘æ¢¯åº¦æŠ•å½±åˆ†æ")
        
        bottleneck_signatures = {}
        layer_names = list(activations.keys())
        
        # è®¡ç®—è¾“å‡ºå±‚çš„æ¢¯åº¦å¼ºåº¦ä½œä¸ºåŸºå‡†
        output_layer = layer_names[-1] if layer_names else None
        if not output_layer or output_layer not in gradients:
            logger.warning("æ— æ³•æ‰¾åˆ°è¾“å‡ºå±‚æ¢¯åº¦ï¼Œè·³è¿‡åå‘æŠ•å½±åˆ†æ")
            logger.exit_section("åå‘æ¢¯åº¦æŠ•å½±åˆ†æ")
            return bottleneck_signatures
            
        output_grad_intensity = torch.norm(gradients[output_layer]).item()
        logger.info(f"è¾“å‡ºå±‚æ¢¯åº¦å¼ºåº¦åŸºå‡†: {output_grad_intensity:.6f}")
        
        # ä»åå‘å‰åˆ†ææ¯ä¸€å±‚
        for i, layer_name in enumerate(reversed(layer_names)):
            if layer_name not in gradients or layer_name not in activations:
                continue
                
            gradient = gradients[layer_name]
            activation = activations[layer_name]
            
            # 1. æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸æ£€æµ‹
            grad_norm = torch.norm(gradient).item()
            grad_ratio = grad_norm / (output_grad_intensity + 1e-8)
            
            # 2. æ¿€æ´»é¥±å’Œåº¦åˆ†æ
            activation_flat = activation.flatten()
            saturation_ratio = self._compute_saturation_ratio(activation_flat)
            
            # 3. ä¿¡æ¯ä¼ é€’æ•ˆç‡
            info_efficiency = self._compute_information_efficiency(activation, gradient)
            
            # 4. å‚æ•°ç©ºé—´åˆ©ç”¨ç‡
            param_efficiency = self._compute_parameter_efficiency(layer_name, activation, gradient)
            
            # ç»¼åˆç“¶é¢ˆä¸¥é‡ç¨‹åº¦è¯„ä¼°
            bottleneck_severity = self._assess_bottleneck_severity(
                grad_ratio, saturation_ratio, info_efficiency, param_efficiency
            )
            
            # å½±å“èŒƒå›´è¯„ä¼°
            layer_index = len(layer_names) - 1 - i
            upstream_impact = layer_index / len(layer_names)  # è¶Šé å‰å½±å“è¶Šå¤§
            downstream_impact = 1.0 - upstream_impact
            
            signature = BottleneckSignature(
                layer_name=layer_name,
                bottleneck_type=self._classify_bottleneck_type(grad_ratio, saturation_ratio, info_efficiency),
                severity=bottleneck_severity,
                upstream_impact=upstream_impact,
                downstream_impact=downstream_impact,
                parameter_efficiency=param_efficiency
            )
            
            bottleneck_signatures[layer_name] = signature
            
            logger.debug(f"å±‚{layer_name}: ä¸¥é‡ç¨‹åº¦={bottleneck_severity:.3f}, "
                        f"æ¢¯åº¦æ¯”={grad_ratio:.6f}, é¥±å’Œåº¦={saturation_ratio:.3f}, "
                        f"ä¿¡æ¯æ•ˆç‡={info_efficiency:.3f}")
        
        logger.info(f"è¯†åˆ«å‡º{len(bottleneck_signatures)}ä¸ªæ½œåœ¨ç“¶é¢ˆå±‚")
        logger.exit_section("åå‘æ¢¯åº¦æŠ•å½±åˆ†æ")
        
        return bottleneck_signatures
    
    def _compute_saturation_ratio(self, activation_flat: torch.Tensor) -> float:
        """è®¡ç®—æ¿€æ´»é¥±å’Œæ¯”ä¾‹"""
        if activation_flat.numel() == 0:
            return 0.0
            
        # æ£€æµ‹æ¥è¿‘0æˆ–æ¥è¿‘æå€¼çš„æ¿€æ´»
        near_zero = torch.abs(activation_flat) < 0.01
        near_max = activation_flat > 0.99 * activation_flat.max()
        near_min = activation_flat < 0.99 * activation_flat.min()
        
        saturated = near_zero | near_max | near_min
        return saturated.float().mean().item()
    
    def _compute_information_efficiency(self, activation: torch.Tensor, gradient: torch.Tensor) -> float:
        """è®¡ç®—ä¿¡æ¯ä¼ é€’æ•ˆç‡"""
        try:
            # è®¡ç®—æ¿€æ´»çš„ä¿¡æ¯ç†µ
            activation_flat = activation.flatten()
            if activation_flat.numel() < 2:
                return 0.0
                
            # ä½¿ç”¨ç›´æ–¹å›¾ä¼°è®¡ä¿¡æ¯ç†µ
            hist, _ = torch.histogram(activation_flat, bins=50)
            hist = hist.float()
            hist = hist / hist.sum()
            hist = hist[hist > 0]  # ç§»é™¤é›¶å€¼
            
            entropy = -(hist * torch.log(hist)).sum().item()
            
            # æ¢¯åº¦ä¿¡æ¯é‡
            grad_flat = gradient.flatten()
            grad_var = torch.var(grad_flat).item()
            
            # ä¿¡æ¯æ•ˆç‡ = ç†µ Ã— æ¢¯åº¦æ–¹å·®
            return entropy * grad_var
            
        except Exception:
            return 0.0
    
    def _compute_parameter_efficiency(self, layer_name: str, activation: torch.Tensor, gradient: torch.Tensor) -> float:
        """è®¡ç®—å‚æ•°æ•ˆç‡ - å‚æ•°äº§ç”Ÿçš„ä¿¡æ¯é‡ä¸å‚æ•°æ•°é‡çš„æ¯”å€¼"""
        try:
            # ä¼°ç®—è¯¥å±‚çš„å‚æ•°æ•°é‡ï¼ˆåŸºäºæ¿€æ´»å½¢çŠ¶æ¨æ–­ï¼‰
            if len(activation.shape) == 4:  # Conv2D
                param_estimate = activation.shape[1] * 9  # å‡è®¾3x3å·ç§¯æ ¸
            elif len(activation.shape) == 2:  # Linear
                param_estimate = activation.shape[1] * 1000  # ç²—ç•¥ä¼°è®¡
            else:
                param_estimate = activation.numel()
            
            # è®¡ç®—ä¿¡æ¯äº§å‡º
            grad_norm = torch.norm(gradient).item()
            activation_norm = torch.norm(activation).item()
            information_output = grad_norm * activation_norm
            
            # å‚æ•°æ•ˆç‡
            efficiency = information_output / (param_estimate + 1e-8)
            return min(efficiency, 10.0)  # é™åˆ¶ä¸Šç•Œ
            
        except Exception:
            return 0.0
    
    def _assess_bottleneck_severity(self, grad_ratio: float, saturation_ratio: float, 
                                  info_efficiency: float, param_efficiency: float) -> float:
        """ç»¼åˆè¯„ä¼°ç“¶é¢ˆä¸¥é‡ç¨‹åº¦"""
        # æ¢¯åº¦é—®é¢˜æƒé‡
        grad_problem = 1.0 if grad_ratio < 0.01 or grad_ratio > 100 else 0.0
        
        # é¥±å’Œé—®é¢˜æƒé‡  
        saturation_problem = saturation_ratio
        
        # æ•ˆç‡é—®é¢˜æƒé‡
        efficiency_problem = 1.0 - min(info_efficiency / 0.1, 1.0)
        param_problem = 1.0 - min(param_efficiency / 0.1, 1.0)
        
        # åŠ æƒç»¼åˆ
        severity = (
            0.3 * grad_problem +
            0.3 * saturation_problem +
            0.2 * efficiency_problem +
            0.2 * param_problem
        )
        
        return min(severity, 1.0)
    
    def _classify_bottleneck_type(self, grad_ratio: float, saturation_ratio: float, info_efficiency: float) -> str:
        """åˆ†ç±»ç“¶é¢ˆç±»å‹"""
        if grad_ratio < 0.01:
            return 'gradient_vanishing'
        elif grad_ratio > 100:
            return 'gradient_exploding'
        elif saturation_ratio > 0.7:
            return 'activation_saturation'
        elif info_efficiency < 0.01:
            return 'information_loss'
        else:
            return 'capacity_limit'

class MultiPointMutationPlanner:
    """å¤šç‚¹å˜å¼‚è§„åˆ’å™¨"""
    
    def __init__(self, max_concurrent_mutations: int = 3, parameter_budget: int = 10000):
        self.max_concurrent_mutations = max_concurrent_mutations
        self.parameter_budget = parameter_budget
    
    def plan_aggressive_mutations(self, 
                                bottleneck_signatures: Dict[str, BottleneckSignature],
                                performance_history: List[float],
                                stagnation_severity: float) -> List[MultiPointMutation]:
        """è§„åˆ’æ¿€è¿›çš„å¤šç‚¹å˜å¼‚ç­–ç•¥"""
        logger.enter_section("å¤šç‚¹å˜å¼‚è§„åˆ’")
        
        mutations = []
        
        # æ ¹æ®åœæ»ä¸¥é‡ç¨‹åº¦å†³å®šæ¿€è¿›ç¨‹åº¦
        max_mutations = min(
            self.max_concurrent_mutations,
            int(stagnation_severity * 5) + 1  # åœæ»è¶Šä¸¥é‡ï¼Œå˜å¼‚ç‚¹è¶Šå¤š
        )
        
        logger.info(f"åœæ»ä¸¥é‡ç¨‹åº¦: {stagnation_severity:.3f}, è®¡åˆ’å˜å¼‚ç‚¹æ•°: {max_mutations}")
        
        # æŒ‰ç“¶é¢ˆä¸¥é‡ç¨‹åº¦æ’åº
        sorted_bottlenecks = sorted(
            bottleneck_signatures.items(),
            key=lambda x: x[1].severity * (x[1].upstream_impact + x[1].downstream_impact),
            reverse=True
        )
        
        # ç­–ç•¥1: å…³é”®ç“¶é¢ˆå±‚çš„å¯†é›†å˜å¼‚
        if max_mutations >= 2:
            mutations.extend(self._plan_dense_mutations(sorted_bottlenecks[:max_mutations]))
        
        # ç­–ç•¥2: è·¨å±‚çº§çš„åè°ƒå˜å¼‚
        if max_mutations >= 3 and len(sorted_bottlenecks) >= 3:
            mutations.extend(self._plan_coordinated_mutations(sorted_bottlenecks))
        
        # ç­–ç•¥3: æ¿€è¿›çš„æ¶æ„é‡æ„
        if stagnation_severity > 0.8:
            mutations.extend(self._plan_radical_restructuring(sorted_bottlenecks))
        
        logger.info(f"è§„åˆ’äº†{len(mutations)}ä¸ªå¤šç‚¹å˜å¼‚ç­–ç•¥")
        logger.exit_section("å¤šç‚¹å˜å¼‚è§„åˆ’")
        
        return mutations
    
    def _plan_dense_mutations(self, bottlenecks: List[Tuple[str, BottleneckSignature]]) -> List[MultiPointMutation]:
        """å¯†é›†å˜å¼‚ç­–ç•¥ - åœ¨å…³é”®å±‚è¿›è¡Œå¤šç§ç±»å‹çš„åŒæ­¥å˜å¼‚"""
        mutations = []
        
        for layer_name, signature in bottlenecks[:2]:  # é€‰æ‹©å‰2ä¸ªæœ€ä¸¥é‡çš„ç“¶é¢ˆ
            target_locations = [layer_name]
            mutation_types = []
            
            # æ ¹æ®ç“¶é¢ˆç±»å‹é€‰æ‹©åˆé€‚çš„å˜å¼‚
            if signature.bottleneck_type == 'gradient_vanishing':
                mutation_types = [MorphogenesisType.SERIAL_DIVISION, MorphogenesisType.WIDTH_EXPANSION]
            elif signature.bottleneck_type == 'activation_saturation':
                mutation_types = [MorphogenesisType.PARALLEL_DIVISION, MorphogenesisType.HYBRID_DIVISION]
            elif signature.bottleneck_type == 'capacity_limit':
                mutation_types = [MorphogenesisType.WIDTH_EXPANSION, MorphogenesisType.SERIAL_DIVISION]
            else:
                mutation_types = [MorphogenesisType.HYBRID_DIVISION]
            
            mutation = MultiPointMutation(
                target_locations=target_locations,
                mutation_types=mutation_types,
                coordination_strategy='parallel',
                expected_improvement=signature.severity * 0.1,
                risk_assessment=0.3,
                parameter_budget=self.parameter_budget // 2
            )
            mutations.append(mutation)
        
        return mutations
    
    def _plan_coordinated_mutations(self, bottlenecks: List[Tuple[str, BottleneckSignature]]) -> List[MultiPointMutation]:
        """åè°ƒå˜å¼‚ç­–ç•¥ - å¤šå±‚åŒæ­¥å˜å¼‚ä»¥ç»´æŒä¿¡æ¯æµ"""
        mutations = []
        
        # é€‰æ‹©åˆ†å¸ƒåœ¨ä¸åŒæ·±åº¦çš„å±‚
        early_layers = [b for b in bottlenecks if b[1].upstream_impact > 0.7]
        middle_layers = [b for b in bottlenecks if 0.3 <= b[1].upstream_impact <= 0.7]
        late_layers = [b for b in bottlenecks if b[1].upstream_impact < 0.3]
        
        if early_layers and late_layers:
            # æ—©æœŸå±‚æ‰©å±•å®¹é‡ï¼ŒåæœŸå±‚å¢å¼ºè¡¨è¾¾
            target_locations = [early_layers[0][0], late_layers[0][0]]
            mutation_types = [MorphogenesisType.WIDTH_EXPANSION, MorphogenesisType.SERIAL_DIVISION]
            
            mutation = MultiPointMutation(
                target_locations=target_locations,
                mutation_types=mutation_types,
                coordination_strategy='cascade',
                expected_improvement=0.15,
                risk_assessment=0.4,
                parameter_budget=self.parameter_budget
            )
            mutations.append(mutation)
        
        return mutations
    
    def _plan_radical_restructuring(self, bottlenecks: List[Tuple[str, BottleneckSignature]]) -> List[MultiPointMutation]:
        """æ¿€è¿›é‡æ„ç­–ç•¥ - å¤§å¹…åº¦æ¶æ„å˜å¼‚"""
        mutations = []
        
        # é€‰æ‹©å½±å“æœ€å¤§çš„å‰3å±‚è¿›è¡Œæ¿€è¿›å˜å¼‚
        top_bottlenecks = bottlenecks[:3]
        target_locations = [b[0] for b in top_bottlenecks]
        
        # æ··åˆä½¿ç”¨æ‰€æœ‰å˜å¼‚ç±»å‹
        mutation_types = [
            MorphogenesisType.HYBRID_DIVISION,
            MorphogenesisType.PARALLEL_DIVISION,
            MorphogenesisType.WIDTH_EXPANSION
        ]
        
        mutation = MultiPointMutation(
            target_locations=target_locations,
            mutation_types=mutation_types,
            coordination_strategy='hybrid',
            expected_improvement=0.3,  # é«˜æœŸæœ›ï¼Œä½†é£é™©ä¹Ÿé«˜
            risk_assessment=0.7,
            parameter_budget=self.parameter_budget * 2  # å…è®¸è¶…é¢„ç®—
        )
        mutations.append(mutation)
        
        return mutations

class AggressiveMorphogenesisExecutor:
    """æ¿€è¿›å½¢æ€å‘ç”Ÿæ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.execution_history = []
    
    def execute_multi_point_mutation(self, 
                                   model: nn.Module,
                                   mutation: MultiPointMutation) -> Tuple[nn.Module, int, Dict]:
        """æ‰§è¡Œå¤šç‚¹å˜å¼‚"""
        logger.enter_section(f"å¤šç‚¹å˜å¼‚æ‰§è¡Œ: {mutation.coordination_strategy}")
        
        try:
            if mutation.coordination_strategy == 'parallel':
                return self._execute_parallel_mutations(model, mutation)
            elif mutation.coordination_strategy == 'cascade':
                return self._execute_cascade_mutations(model, mutation)
            elif mutation.coordination_strategy == 'hybrid':
                return self._execute_hybrid_mutations(model, mutation)
            else:
                logger.error(f"æœªçŸ¥çš„åè°ƒç­–ç•¥: {mutation.coordination_strategy}")
                return model, 0, {'error': 'unknown_strategy'}
                
        except Exception as e:
            logger.error(f"å¤šç‚¹å˜å¼‚æ‰§è¡Œå¤±è´¥: {e}")
            return model, 0, {'error': str(e)}
        finally:
            logger.exit_section(f"å¤šç‚¹å˜å¼‚æ‰§è¡Œ: {mutation.coordination_strategy}")
    
    def _execute_parallel_mutations(self, model: nn.Module, mutation: MultiPointMutation) -> Tuple[nn.Module, int, Dict]:
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå˜å¼‚ - åŒæ—¶åœ¨å¤šä¸ªä½ç½®è¿›è¡Œç‹¬ç«‹å˜å¼‚"""
        logger.info(f"å¹¶è¡Œå˜å¼‚: {len(mutation.target_locations)}ä¸ªä½ç½®")
        
        new_model = copy.deepcopy(model)
        total_params_added = 0
        execution_details = []
        
        for i, (location, morph_type) in enumerate(zip(mutation.target_locations, mutation.mutation_types)):
            try:
                # ä¸ºæ¯ä¸ªä½ç½®æ‰§è¡Œç‹¬ç«‹çš„å˜å¼‚
                from .advanced_morphogenesis import AdvancedMorphogenesisExecutor
                executor = AdvancedMorphogenesisExecutor()
                
                decision = MorphogenesisDecision(
                    morphogenesis_type=morph_type,
                    target_location=location,
                    confidence=0.8,
                    expected_improvement=mutation.expected_improvement / len(mutation.target_locations),
                    complexity_cost=0.3,
                    parameters_added=mutation.parameter_budget // len(mutation.target_locations),
                    reasoning=f"å¹¶è¡Œå˜å¼‚{i+1}: {morph_type.value}"
                )
                
                new_model, params_added = executor.execute_morphogenesis(new_model, decision)
                total_params_added += params_added
                
                execution_details.append({
                    'location': location,
                    'type': morph_type.value,
                    'params_added': params_added,
                    'success': True
                })
                
                logger.info(f"ä½ç½®{location}å˜å¼‚æˆåŠŸ: +{params_added}å‚æ•°")
                
            except Exception as e:
                logger.warning(f"ä½ç½®{location}å˜å¼‚å¤±è´¥: {e}")
                execution_details.append({
                    'location': location,
                    'type': morph_type.value,
                    'error': str(e),
                    'success': False
                })
        
        result = {
            'strategy': 'parallel',
            'total_mutations': len(mutation.target_locations),
            'successful_mutations': sum(1 for d in execution_details if d.get('success', False)),
            'execution_details': execution_details
        }
        
        return new_model, total_params_added, result
    
    def _execute_cascade_mutations(self, model: nn.Module, mutation: MultiPointMutation) -> Tuple[nn.Module, int, Dict]:
        """çº§è”æ‰§è¡Œå˜å¼‚ - æŒ‰æ·±åº¦é¡ºåºä¾æ¬¡å˜å¼‚ï¼Œåç»­å˜å¼‚è€ƒè™‘å‰é¢çš„å½±å“"""
        logger.info(f"çº§è”å˜å¼‚: {len(mutation.target_locations)}ä¸ªä½ç½®")
        
        new_model = copy.deepcopy(model)
        total_params_added = 0
        execution_details = []
        
        # æŒ‰å±‚çš„æ·±åº¦æ’åºï¼ˆå‡è®¾å±‚ååŒ…å«ä½ç½®ä¿¡æ¯ï¼‰
        sorted_mutations = list(zip(mutation.target_locations, mutation.mutation_types))
        
        for i, (location, morph_type) in enumerate(sorted_mutations):
            try:
                from .advanced_morphogenesis import AdvancedMorphogenesisExecutor
                executor = AdvancedMorphogenesisExecutor()
                
                # çº§è”å˜å¼‚ä¸­ï¼Œåç»­å˜å¼‚çš„å‚æ•°é¢„ç®—ä¼šæ ¹æ®å‰é¢çš„ç»“æœè°ƒæ•´
                remaining_budget = mutation.parameter_budget - total_params_added
                adjusted_budget = max(remaining_budget // (len(sorted_mutations) - i), 1000)
                
                decision = MorphogenesisDecision(
                    morphogenesis_type=morph_type,
                    target_location=location,
                    confidence=0.7,  # çº§è”å˜å¼‚é£é™©ç¨é«˜
                    expected_improvement=mutation.expected_improvement * (1.2 ** i),  # åç»­å˜å¼‚æœŸæœ›æ›´é«˜
                    complexity_cost=0.4,
                    parameters_added=adjusted_budget,
                    reasoning=f"çº§è”å˜å¼‚{i+1}: {morph_type.value}"
                )
                
                new_model, params_added = executor.execute_morphogenesis(new_model, decision)
                total_params_added += params_added
                
                execution_details.append({
                    'location': location,
                    'type': morph_type.value,
                    'params_added': params_added,
                    'cascade_order': i + 1,
                    'success': True
                })
                
                logger.info(f"çº§è”{i+1}({location})å˜å¼‚æˆåŠŸ: +{params_added}å‚æ•°")
                
            except Exception as e:
                logger.warning(f"çº§è”{i+1}({location})å˜å¼‚å¤±è´¥: {e}")
                execution_details.append({
                    'location': location,
                    'type': morph_type.value,
                    'cascade_order': i + 1,
                    'error': str(e),
                    'success': False
                })
                # çº§è”å˜å¼‚ä¸­ï¼Œå¦‚æœæŸä¸€æ­¥å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤
        
        result = {
            'strategy': 'cascade',
            'total_mutations': len(mutation.target_locations),
            'successful_mutations': sum(1 for d in execution_details if d.get('success', False)),
            'execution_details': execution_details
        }
        
        return new_model, total_params_added, result
    
    def _execute_hybrid_mutations(self, model: nn.Module, mutation: MultiPointMutation) -> Tuple[nn.Module, int, Dict]:
        """æ··åˆå˜å¼‚ç­–ç•¥ - ç»“åˆå¹¶è¡Œå’Œçº§è”çš„ä¼˜åŠ¿"""
        logger.info(f"æ··åˆå˜å¼‚: {len(mutation.target_locations)}ä¸ªä½ç½®")
        
        # å°†å˜å¼‚åˆ†ä¸ºä¸¤ç»„ï¼šå¹¶è¡Œç»„å’Œçº§è”ç»„
        mid_point = len(mutation.target_locations) // 2
        parallel_group = list(zip(mutation.target_locations[:mid_point], mutation.mutation_types[:mid_point]))
        cascade_group = list(zip(mutation.target_locations[mid_point:], mutation.mutation_types[mid_point:]))
        
        new_model = copy.deepcopy(model)
        total_params_added = 0
        execution_details = []
        
        # å…ˆæ‰§è¡Œå¹¶è¡Œç»„
        if parallel_group:
            parallel_mutation = MultiPointMutation(
                target_locations=[loc for loc, _ in parallel_group],
                mutation_types=[mt for _, mt in parallel_group],
                coordination_strategy='parallel',
                expected_improvement=mutation.expected_improvement * 0.6,
                risk_assessment=mutation.risk_assessment,
                parameter_budget=mutation.parameter_budget // 2
            )
            
            new_model, parallel_params, parallel_result = self._execute_parallel_mutations(new_model, parallel_mutation)
            total_params_added += parallel_params
            execution_details.extend(parallel_result['execution_details'])
        
        # å†æ‰§è¡Œçº§è”ç»„
        if cascade_group:
            cascade_mutation = MultiPointMutation(
                target_locations=[loc for loc, _ in cascade_group],
                mutation_types=[mt for _, mt in cascade_group],
                coordination_strategy='cascade',
                expected_improvement=mutation.expected_improvement * 0.4,
                risk_assessment=mutation.risk_assessment,
                parameter_budget=mutation.parameter_budget - total_params_added
            )
            
            new_model, cascade_params, cascade_result = self._execute_cascade_mutations(new_model, cascade_mutation)
            total_params_added += cascade_params
            execution_details.extend(cascade_result['execution_details'])
        
        result = {
            'strategy': 'hybrid',
            'total_mutations': len(mutation.target_locations),
            'successful_mutations': sum(1 for d in execution_details if d.get('success', False)),
            'parallel_mutations': len(parallel_group),
            'cascade_mutations': len(cascade_group),
            'execution_details': execution_details
        }
        
        return new_model, total_params_added, result