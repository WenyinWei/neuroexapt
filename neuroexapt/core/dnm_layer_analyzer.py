#!/usr/bin/env python3
"""
"""
defgroup group_dnm_layer_analyzer Dnm Layer Analyzer
ingroup core
Dnm Layer Analyzer module for NeuroExapt framework.
"""


DNM Layer Performance Analyzer - å±‚çº§æ€§èƒ½åˆ†æå™¨

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. é€å±‚æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
2. ç‰¹å¾è¡¨ç¤ºè´¨é‡è¯„ä¼°  
3. æ¢¯åº¦æµåˆ†æ
4. ä¿¡æ¯ä¼ é€’æ•ˆç‡è¯„ä¼°
5. æ™ºèƒ½åˆ†è£‚ä½ç½®æ¨è

ğŸ§¬ åˆ†æç»´åº¦ï¼š
- ä¿¡æ¯è®ºæŒ‡æ ‡ï¼ˆç†µã€äº’ä¿¡æ¯ï¼‰
- æ¢¯åº¦å¥åº·åº¦
- ç‰¹å¾åˆ†ç¦»åº¦
- æ¿€æ´»é¥±å’Œåº¦
- å­¦ä¹ æ•ˆç‡

"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict, deque
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class LayerPerformanceAnalyzer:
    """å±‚çº§æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self, model: nn.Module):
        self.model = model
        self.layer_metrics_history = defaultdict(lambda: deque(maxlen=10))
        self.performance_baseline = {}
        self.critical_layers = set()
        
    def analyze_all_layers(self, activations: Dict[str, torch.Tensor], 
                          gradients: Dict[str, torch.Tensor],
                          targets: torch.Tensor,
                          current_accuracy: float) -> Dict[str, Dict[str, float]]:
        """åˆ†ææ‰€æœ‰å±‚çš„æ€§èƒ½æŒ‡æ ‡"""
        
        layer_analysis = {}
        
        for layer_name in activations.keys():
            if layer_name in gradients and gradients[layer_name] is not None:
                analysis = self._analyze_single_layer(
                    layer_name, 
                    activations[layer_name], 
                    gradients[layer_name],
                    targets,
                    current_accuracy
                )
                layer_analysis[layer_name] = analysis
                
                # æ›´æ–°å†å²è®°å½•
                self.layer_metrics_history[layer_name].append(analysis)
        
        return layer_analysis
    
    def _analyze_single_layer(self, layer_name: str, 
                             activation: torch.Tensor,
                             gradient: torch.Tensor, 
                             targets: torch.Tensor,
                             current_accuracy: float) -> Dict[str, float]:
        """åˆ†æå•ä¸ªå±‚çš„æ€§èƒ½"""
        
        metrics = {}
        
        # 1. ä¿¡æ¯è®ºåˆ†æ
        metrics.update(self._compute_information_metrics(activation))
        
        # 2. æ¢¯åº¦å¥åº·åº¦åˆ†æ  
        metrics.update(self._compute_gradient_health(gradient))
        
        # 3. ç‰¹å¾è¡¨ç¤ºè´¨é‡
        metrics.update(self._compute_representation_quality(activation, targets))
        
        # 4. å­¦ä¹ æ•ˆç‡åˆ†æ
        metrics.update(self._compute_learning_efficiency(layer_name, current_accuracy))
        
        # 5. è®¡ç®—ç»¼åˆç“¶é¢ˆåˆ†æ•°
        metrics['bottleneck_score'] = self._compute_bottleneck_score(metrics)
        
        return metrics
    
    def _compute_information_metrics(self, activation: torch.Tensor) -> Dict[str, float]:
        """è®¡ç®—ä¿¡æ¯è®ºæŒ‡æ ‡"""
        metrics = {}
        
        # å±•å¹³æ¿€æ´»å€¼
        act_flat = activation.view(activation.size(0), -1)
        
        if act_flat.size(1) == 0:
            return {'entropy': 0.0, 'mutual_info_proxy': 0.0, 'information_flow': 0.0}
        
        # è®¡ç®—æ¿€æ´»ç†µ
        try:
            # å½’ä¸€åŒ–æ¿€æ´»å€¼
            act_norm = F.softmax(act_flat, dim=-1) + 1e-8
            entropy = -torch.sum(act_norm * torch.log(act_norm), dim=-1).mean().item()
            metrics['entropy'] = entropy
        except:
            metrics['entropy'] = 0.0
        
        # è®¡ç®—ç‰¹å¾é—´ç›¸å…³æ€§ï¼ˆäº’ä¿¡æ¯ä»£ç†ï¼‰
        try:
            if act_flat.size(1) > 1:
                correlation_matrix = torch.corrcoef(act_flat.T)
                avg_correlation = torch.mean(torch.abs(correlation_matrix - torch.eye(correlation_matrix.size(0), device=correlation_matrix.device))).item()
                metrics['mutual_info_proxy'] = avg_correlation
            else:
                metrics['mutual_info_proxy'] = 0.0
        except:
            metrics['mutual_info_proxy'] = 0.0
        
        # ä¿¡æ¯æµæŒ‡æ ‡ï¼ˆæ¿€æ´»å€¼çš„æ ‡å‡†å·®ï¼‰
        metrics['information_flow'] = torch.std(act_flat).item()
        
        return metrics
    
    def _compute_gradient_health(self, gradient: torch.Tensor) -> Dict[str, float]:
        """è®¡ç®—æ¢¯åº¦å¥åº·åº¦"""
        metrics = {}
        
        grad_flat = gradient.view(-1)
        
        # æ¢¯åº¦èŒƒæ•°
        metrics['gradient_norm'] = torch.norm(grad_flat).item()
        
        # æ¢¯åº¦ç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®ä¸å‡å€¼çš„æ¯”ï¼‰
        grad_mean = torch.mean(torch.abs(grad_flat)).item()
        grad_std = torch.std(grad_flat).item()
        metrics['gradient_stability'] = grad_std / (grad_mean + 1e-8)
        
        # æ¢¯åº¦é¥±å’Œåº¦ï¼ˆæ¥è¿‘0çš„æ¢¯åº¦æ¯”ä¾‹ï¼‰
        near_zero_ratio = torch.sum(torch.abs(grad_flat) < 1e-6).float() / len(grad_flat)
        metrics['gradient_saturation'] = near_zero_ratio.item()
        
        # æ¢¯åº¦å¥åº·åˆ†æ•°
        if metrics['gradient_norm'] < 1e-8:
            health_score = 0.0  # æ¢¯åº¦æ¶ˆå¤±
        elif metrics['gradient_norm'] > 100:
            health_score = 0.2  # æ¢¯åº¦çˆ†ç‚¸
        else:
            health_score = 1.0 / (1.0 + metrics['gradient_stability'])
        
        metrics['gradient_health'] = health_score
        
        return metrics
    
    def _compute_representation_quality(self, activation: torch.Tensor, targets: torch.Tensor) -> Dict[str, float]:
        """è®¡ç®—ç‰¹å¾è¡¨ç¤ºè´¨é‡"""
        metrics = {}
        
        act_flat = activation.view(activation.size(0), -1)
        
        if act_flat.size(1) < 2 or len(torch.unique(targets)) < 2:
            return {
                'feature_separability': 0.0,
                'activation_diversity': 0.0,
                'representation_efficiency': 0.0
            }
        
        # ç‰¹å¾å¯åˆ†ç¦»æ€§ï¼ˆä½¿ç”¨ç±»å†…/ç±»é—´è·ç¦»æ¯”ï¼‰
        try:
            separability = self._compute_feature_separability(act_flat, targets)
            metrics['feature_separability'] = separability
        except:
            metrics['feature_separability'] = 0.0
        
        # æ¿€æ´»å¤šæ ·æ€§
        activation_diversity = self._compute_activation_diversity(act_flat)
        metrics['activation_diversity'] = activation_diversity
        
        # è¡¨ç¤ºæ•ˆç‡ï¼ˆä¿¡æ¯å¯†åº¦ï¼‰
        representation_efficiency = self._compute_representation_efficiency(act_flat)
        metrics['representation_efficiency'] = representation_efficiency
        
        return metrics
    
    def _compute_feature_separability(self, features: torch.Tensor, targets: torch.Tensor) -> float:
        """è®¡ç®—ç‰¹å¾å¯åˆ†ç¦»æ€§"""
        unique_labels = torch.unique(targets)
        
        if len(unique_labels) < 2:
            return 0.0
        
        # è®¡ç®—ç±»å†…è·ç¦»å’Œç±»é—´è·ç¦»
        intra_class_distances = []
        inter_class_distances = []
        
        for label in unique_labels:
            mask = targets == label
            if torch.sum(mask) < 2:
                continue
                
            class_features = features[mask]
            class_center = torch.mean(class_features, dim=0)
            
            # ç±»å†…è·ç¦»
            intra_dist = torch.mean(torch.norm(class_features - class_center, dim=1)).item()
            intra_class_distances.append(intra_dist)
            
            # ç±»é—´è·ç¦»
            for other_label in unique_labels:
                if other_label <= label:
                    continue
                other_mask = targets == other_label
                if torch.sum(other_mask) == 0:
                    continue
                    
                other_center = torch.mean(features[other_mask], dim=0)
                inter_dist = torch.norm(class_center - other_center).item()
                inter_class_distances.append(inter_dist)
        
        if not intra_class_distances or not inter_class_distances:
            return 0.0
        
        avg_intra = np.mean(intra_class_distances)
        avg_inter = np.mean(inter_class_distances)
        
        # å¯åˆ†ç¦»æ€§ = ç±»é—´è·ç¦» / ç±»å†…è·ç¦»
        separability = avg_inter / (avg_intra + 1e-8)
        return min(separability, 10.0)  # é™åˆ¶ä¸Šç•Œ
    
    def _compute_activation_diversity(self, activation: torch.Tensor) -> float:
        """è®¡ç®—æ¿€æ´»å¤šæ ·æ€§"""
        # ä½¿ç”¨æ¿€æ´»å€¼çš„æ–¹å·®ä½œä¸ºå¤šæ ·æ€§æŒ‡æ ‡
        variance_per_neuron = torch.var(activation, dim=0)
        avg_variance = torch.mean(variance_per_neuron).item()
        
        # è®¡ç®—æ¿€æ´»æ¨¡å¼çš„å¤šæ ·æ€§ï¼ˆä¸åŒæ ·æœ¬é—´çš„å·®å¼‚ï¼‰
        if activation.size(0) > 1:
            pairwise_distances = torch.pdist(activation)
            avg_pairwise_distance = torch.mean(pairwise_distances).item()
        else:
            avg_pairwise_distance = 0.0
        
        # ç»¼åˆå¤šæ ·æ€§åˆ†æ•°
        diversity = np.sqrt(avg_variance * avg_pairwise_distance)
        return diversity
    
    def _compute_representation_efficiency(self, activation: torch.Tensor) -> float:
        """è®¡ç®—è¡¨ç¤ºæ•ˆç‡"""
        # æœ‰æ•ˆç»´åº¦ vs æ€»ç»´åº¦
        variance_per_neuron = torch.var(activation, dim=0)
        active_neurons = torch.sum(variance_per_neuron > 1e-6).item()
        total_neurons = activation.size(1)
        
        efficiency = active_neurons / (total_neurons + 1e-8)
        return efficiency
    
    def _compute_learning_efficiency(self, layer_name: str, current_accuracy: float) -> Dict[str, float]:
        """è®¡ç®—å­¦ä¹ æ•ˆç‡"""
        metrics = {}
        
        history = self.layer_metrics_history[layer_name]
        
        if len(history) < 3:
            metrics['learning_rate'] = 0.0
            metrics['improvement_trend'] = 0.0
            return metrics
        
        # è®¡ç®—æœ€è¿‘å‡ ä¸ªepochçš„æ”¹è¿›è¶‹åŠ¿
        recent_accuracies = [current_accuracy] + [h.get('accuracy_impact', 0) for h in list(history)[-3:]]
        
        if len(recent_accuracies) > 1:
            # è®¡ç®—æ”¹è¿›è¶‹åŠ¿
            improvements = np.diff(recent_accuracies)
            avg_improvement = np.mean(improvements)
            metrics['improvement_trend'] = avg_improvement
            
            # å­¦ä¹ ç‡ï¼ˆæ”¹è¿›çš„ä¸€è‡´æ€§ï¼‰
            consistency = 1.0 - np.std(improvements)
            metrics['learning_rate'] = max(0.0, consistency)
        else:
            metrics['learning_rate'] = 0.0
            metrics['improvement_trend'] = 0.0
        
        return metrics
    
    def _compute_bottleneck_score(self, metrics: Dict[str, float]) -> float:
        """è®¡ç®—ç»¼åˆç“¶é¢ˆåˆ†æ•°ï¼ˆè¶Šé«˜è¶Šéœ€è¦æ”¹è¿›ï¼‰"""
        
        # æƒé‡é…ç½®
        weights = {
            'gradient_health': 0.25,      # æ¢¯åº¦å¥åº·åº¦ï¼ˆè¶Šä½è¶Šéœ€è¦æ”¹è¿›ï¼‰
            'feature_separability': 0.20,  # ç‰¹å¾å¯åˆ†ç¦»æ€§ï¼ˆè¶Šä½è¶Šéœ€è¦æ”¹è¿›ï¼‰
            'representation_efficiency': 0.15,  # è¡¨ç¤ºæ•ˆç‡
            'information_flow': 0.15,     # ä¿¡æ¯æµ
            'learning_rate': 0.15,        # å­¦ä¹ æ•ˆç‡
            'activation_diversity': 0.10   # æ¿€æ´»å¤šæ ·æ€§
        }
        
        score = 0.0
        total_weight = 0.0
        
        for metric, weight in weights.items():
            if metric in metrics:
                value = metrics[metric]
                
                # å°†æ‰€æœ‰æŒ‡æ ‡è½¬æ¢ä¸º"éœ€è¦æ”¹è¿›"çš„åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šéœ€è¦æ”¹è¿›ï¼‰
                if metric in ['gradient_health', 'feature_separability', 'representation_efficiency', 
                             'information_flow', 'learning_rate', 'activation_diversity']:
                    # è¿™äº›æŒ‡æ ‡è¶Šä½è¶Šéœ€è¦æ”¹è¿›
                    improvement_need = 1.0 - min(1.0, value)
                else:
                    improvement_need = min(1.0, value)
                
                score += improvement_need * weight
                total_weight += weight
        
        if total_weight > 0:
            score /= total_weight
        
        return score
    
    def recommend_optimal_layers(self, layer_analysis: Dict[str, Dict[str, float]], 
                                top_k: int = 3) -> List[Tuple[str, float, str]]:
        """æ¨èæœ€éœ€è¦æ”¹è¿›çš„å±‚"""
        
        recommendations = []
        
        for layer_name, metrics in layer_analysis.items():
            bottleneck_score = metrics.get('bottleneck_score', 0.0)
            
            # åˆ†æä¸»è¦é—®é¢˜
            main_issue = self._identify_main_issue(metrics)
            
            recommendations.append((layer_name, bottleneck_score, main_issue))
        
        # æŒ‰ç“¶é¢ˆåˆ†æ•°æ’åº
        recommendations.sort(key=lambda x: x[1], reverse=True)
        
        return recommendations[:top_k]
    
    def _identify_main_issue(self, metrics: Dict[str, float]) -> str:
        """è¯†åˆ«å±‚çš„ä¸»è¦é—®é¢˜"""
        
        issues = []
        
        # æ¢¯åº¦é—®é¢˜
        if metrics.get('gradient_health', 1.0) < 0.3:
            if metrics.get('gradient_norm', 0) < 1e-6:
                issues.append("æ¢¯åº¦æ¶ˆå¤±")
            elif metrics.get('gradient_norm', 0) > 100:
                issues.append("æ¢¯åº¦çˆ†ç‚¸")
            else:
                issues.append("æ¢¯åº¦ä¸ç¨³å®š")
        
        # ç‰¹å¾è¡¨ç¤ºé—®é¢˜
        if metrics.get('feature_separability', 1.0) < 0.5:
            issues.append("ç‰¹å¾åˆ†ç¦»åº¦ä½")
        
        # è¡¨ç¤ºæ•ˆç‡é—®é¢˜
        if metrics.get('representation_efficiency', 1.0) < 0.3:
            issues.append("è¡¨ç¤ºæ•ˆç‡ä½")
        
        # ä¿¡æ¯æµé—®é¢˜
        if metrics.get('information_flow', 1.0) < 0.1:
            issues.append("ä¿¡æ¯æµå—é˜»")
        
        # å­¦ä¹ æ•ˆç‡é—®é¢˜
        if metrics.get('learning_rate', 1.0) < 0.2:
            issues.append("å­¦ä¹ æ•ˆç‡ä½")
        
        if not issues:
            return "æ€§èƒ½è‰¯å¥½"
        
        return " + ".join(issues[:2])  # æœ€å¤šæ˜¾ç¤ºä¸¤ä¸ªä¸»è¦é—®é¢˜

class SmartLayerSelector:
    """æ™ºèƒ½å±‚é€‰æ‹©å™¨"""
    
    def __init__(self, analyzer: LayerPerformanceAnalyzer):
        self.analyzer = analyzer
        self.selection_history = deque(maxlen=20)
        
    def select_optimal_division_layers(self, layer_analysis: Dict[str, Dict[str, float]], 
                                     max_selections: int = 2) -> List[Tuple[str, float, str]]:
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜åˆ†è£‚å±‚"""
        
        # è·å–æ¨èå±‚
        recommendations = self.analyzer.recommend_optimal_layers(layer_analysis, top_k=10)
        
        # è¿‡æ»¤æ‰æœ€è¿‘å·²ç»å¤„ç†è¿‡çš„å±‚
        filtered_recommendations = []
        recent_layers = set(h['layer'] for h in list(self.selection_history)[-5:])
        
        for layer_name, score, issue in recommendations:
            # é¿å…è¿‡åº¦åˆ†è£‚åŒä¸€å±‚
            if layer_name not in recent_layers or score > 0.8:  # é«˜åˆ†æ•°å¯ä»¥é‡å¤å¤„ç†
                filtered_recommendations.append((layer_name, score, issue))
        
        # é€‰æ‹©å¤šæ ·åŒ–çš„å±‚
        selected = self._select_diverse_layers(filtered_recommendations, max_selections)
        
        # è®°å½•é€‰æ‹©å†å²
        for layer_name, score, issue in selected:
            self.selection_history.append({
                'layer': layer_name,
                'score': score,
                'issue': issue,
                'epoch': len(self.selection_history)
            })
        
        return selected
    
    def _select_diverse_layers(self, recommendations: List[Tuple[str, float, str]], 
                              max_selections: int) -> List[Tuple[str, float, str]]:
        """é€‰æ‹©å¤šæ ·åŒ–çš„å±‚ï¼ˆé¿å…éƒ½åœ¨åŒä¸€ä¸ªæ¨¡å—ï¼‰"""
        
        if len(recommendations) <= max_selections:
            return recommendations
        
        selected = []
        used_modules = set()
        
        # ä¼˜å…ˆé€‰æ‹©ä¸åŒæ¨¡å—çš„å±‚
        for layer_name, score, issue in recommendations:
            if len(selected) >= max_selections:
                break
                
            # æå–æ¨¡å—åï¼ˆå¦‚ 'features', 'classifier'ï¼‰
            module_name = layer_name.split('.')[0] if '.' in layer_name else layer_name
            
            if module_name not in used_modules or len(selected) == 0:
                selected.append((layer_name, score, issue))
                used_modules.add(module_name)
        
        # å¦‚æœè¿˜æ²¡é€‰å¤Ÿï¼Œç»§ç»­é€‰æ‹©é«˜åˆ†æ•°çš„å±‚
        while len(selected) < max_selections and len(selected) < len(recommendations):
            for layer_name, score, issue in recommendations:
                if (layer_name, score, issue) not in selected:
                    selected.append((layer_name, score, issue))
                    break
        
        return selected