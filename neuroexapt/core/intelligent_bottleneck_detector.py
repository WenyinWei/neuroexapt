"""
æ™ºèƒ½ç“¶é¢ˆæ£€æµ‹å™¨
åŸºäºäº’ä¿¡æ¯I(H_k; Y)ã€æ¡ä»¶äº’ä¿¡æ¯I(H_k; Y|H_{k+1})å’Œè´å¶æ–¯ä¸ç¡®å®šæ€§çš„ç»¼åˆç“¶é¢ˆæ£€æµ‹
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import logging
from dataclasses import dataclass
from enum import Enum

from .mutual_information_estimator import MutualInformationEstimator
from .bayesian_uncertainty_estimator import BayesianUncertaintyEstimator

logger = logging.getLogger(__name__)


class BottleneckType(Enum):
    """ç“¶é¢ˆç±»å‹"""
    INFORMATION_LEAKAGE = "information_leakage"  # ä¿¡æ¯æ³„éœ²ï¼šI(H_k; Y|H_{k+1}) â‰ˆ 0
    HIGH_UNCERTAINTY = "high_uncertainty"       # é«˜ä¸ç¡®å®šæ€§ï¼šU(H_k) >> é˜ˆå€¼
    REDUNDANT_FEATURES = "redundant_features"   # å†—ä½™ç‰¹å¾ï¼šI(H_k; Y) ä½ä½†ç»´åº¦é«˜
    GRADIENT_BOTTLENECK = "gradient_bottleneck" # æ¢¯åº¦ç“¶é¢ˆï¼šæ¢¯åº¦æµåŠ¨å—é˜»
    CAPACITY_BOTTLENECK = "capacity_bottleneck" # å®¹é‡ç“¶é¢ˆï¼šè¡¨å¾èƒ½åŠ›ä¸è¶³


@dataclass
class BottleneckReport:
    """ç“¶é¢ˆæ£€æµ‹æŠ¥å‘Š"""
    layer_name: str
    bottleneck_type: BottleneckType
    severity: float  # ä¸¥é‡ç¨‹åº¦ [0, 1]
    confidence: float  # æ£€æµ‹ç½®ä¿¡åº¦ [0, 1]
    
    # è¯¦ç»†æŒ‡æ ‡
    mutual_info: float
    conditional_mutual_info: float
    uncertainty: float
    
    # è§£é‡Šå’Œå»ºè®®
    explanation: str
    suggested_mutations: List[str]
    
    # åŸå§‹æ•°æ®
    raw_metrics: Dict[str, Any]


class IntelligentBottleneckDetector:
    """
    æ™ºèƒ½ç“¶é¢ˆæ£€æµ‹å™¨
    
    æ ¸å¿ƒç†å¿µï¼š
    1. å¤šç»´åº¦åˆ†æï¼šäº’ä¿¡æ¯ + ä¸ç¡®å®šæ€§ + æ¢¯åº¦æµ + ç»“æ„åˆ†æ
    2. è‡ªé€‚åº”é˜ˆå€¼ï¼šæ ¹æ®ç½‘ç»œçŠ¶æ€å’Œä»»åŠ¡ç‰¹ç‚¹åŠ¨æ€è°ƒæ•´
    3. åˆ†çº§è¯Šæ–­ï¼šä»ç²—ç²’åº¦åˆ°ç»†ç²’åº¦çš„é€’è¿›åˆ†æ
    4. å¯è§£é‡Šæ€§ï¼šæä¾›æ˜ç¡®çš„ç“¶é¢ˆåŸå› å’Œä¿®å¤å»ºè®®
    """
    
    def __init__(self, device: torch.device = None):
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ ¸å¿ƒåˆ†æå™¨
        self.mi_estimator = MutualInformationEstimator(device)
        self.uncertainty_estimator = BayesianUncertaintyEstimator(device)
        
        # åŠ¨æ€é˜ˆå€¼
        self.thresholds = {
            'mi_low': 0.01,           # äº’ä¿¡æ¯è¿‡ä½é˜ˆå€¼
            'conditional_mi_low': 0.005,  # æ¡ä»¶äº’ä¿¡æ¯è¿‡ä½é˜ˆå€¼
            'uncertainty_high': 1.0,   # ä¸ç¡®å®šæ€§è¿‡é«˜é˜ˆå€¼
            'redundancy_ratio': 0.8,   # å†—ä½™ç‰¹å¾æ¯”ä¾‹é˜ˆå€¼
            'gradient_flow_low': 0.1   # æ¢¯åº¦æµåŠ¨è¿‡ä½é˜ˆå€¼
        }
        
        # å†å²è®°å½•
        self.detection_history = []
        self.adaptive_thresholds_history = []
        
    def detect_bottlenecks(self,
                          model: nn.Module,
                          feature_dict: Dict[str, torch.Tensor],
                          labels: torch.Tensor,
                          gradient_dict: Dict[str, torch.Tensor] = None,
                          num_classes: int = None,
                          confidence_threshold: float = 0.7) -> List[BottleneckReport]:
        """
        ç»¼åˆç“¶é¢ˆæ£€æµ‹
        
        Args:
            model: ç¥ç»ç½‘ç»œæ¨¡å‹
            feature_dict: å„å±‚ç‰¹å¾å­—å…¸ {layer_name: features}
            labels: ç›®æ ‡æ ‡ç­¾
            gradient_dict: å„å±‚æ¢¯åº¦å­—å…¸ï¼ˆå¯é€‰ï¼‰
            num_classes: åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ•°
            confidence_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            ç“¶é¢ˆæŠ¥å‘Šåˆ—è¡¨ï¼ŒæŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        """
        logger.info("ğŸ” å¼€å§‹æ™ºèƒ½ç“¶é¢ˆæ£€æµ‹")
        
        # 1. æ‰¹é‡è®¡ç®—äº’ä¿¡æ¯
        logger.info("è®¡ç®—åˆ†å±‚äº’ä¿¡æ¯...")
        mi_results = self.mi_estimator.batch_estimate_layerwise_mi(
            feature_dict, labels, num_classes
        )
        
        # 2. æ‰¹é‡è®¡ç®—æ¡ä»¶äº’ä¿¡æ¯
        logger.info("è®¡ç®—æ¡ä»¶äº’ä¿¡æ¯...")
        conditional_mi_results = self._compute_conditional_mi(
            feature_dict, labels, num_classes
        )
        
        # 3. æ‰¹é‡è®¡ç®—ä¸ç¡®å®šæ€§
        logger.info("è®¡ç®—è´å¶æ–¯ä¸ç¡®å®šæ€§...")
        uncertainty_results = self.uncertainty_estimator.estimate_feature_uncertainty(
            feature_dict, labels
        )
        
        # 4. æ¢¯åº¦æµåˆ†æï¼ˆå¦‚æœæä¾›ï¼‰
        gradient_flow_results = {}
        if gradient_dict:
            logger.info("åˆ†ææ¢¯åº¦æµ...")
            gradient_flow_results = self._analyze_gradient_flow(gradient_dict)
        
        # 5. ç»¼åˆåˆ†æç”ŸæˆæŠ¥å‘Š
        bottleneck_reports = []
        layer_names = list(feature_dict.keys())
        
        for layer_name in layer_names:
            report = self._analyze_layer_bottleneck(
                layer_name=layer_name,
                features=feature_dict[layer_name],
                mi_value=mi_results.get(layer_name, 0.0),
                conditional_mi=conditional_mi_results.get(layer_name, 0.0),
                uncertainty=uncertainty_results.get(layer_name, float('inf')),
                gradient_flow=gradient_flow_results.get(layer_name, None),
                num_classes=num_classes
            )
            
            if report and report.confidence >= confidence_threshold:
                bottleneck_reports.append(report)
        
        # 6. æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        bottleneck_reports.sort(key=lambda x: x.severity, reverse=True)
        
        # 7. æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼
        self._update_adaptive_thresholds(mi_results, uncertainty_results)
        
        # 8. è®°å½•å†å²
        self.detection_history.append({
            'reports': bottleneck_reports,
            'mi_results': mi_results,
            'uncertainty_results': uncertainty_results,
            'timestamp': torch.tensor(len(self.detection_history))
        })
        
        logger.info(f"æ£€æµ‹åˆ° {len(bottleneck_reports)} ä¸ªæ½œåœ¨ç“¶é¢ˆ")
        return bottleneck_reports
    
    def _compute_conditional_mi(self,
                               feature_dict: Dict[str, torch.Tensor],
                               labels: torch.Tensor,
                               num_classes: int = None) -> Dict[str, float]:
        """è®¡ç®—æ¡ä»¶äº’ä¿¡æ¯"""
        conditional_mi_results = {}
        layer_names = list(feature_dict.keys())
        
        # æ„å»ºç›¸é‚»å±‚å¯¹
        feature_pairs = []
        for i in range(len(layer_names) - 1):
            current_layer = layer_names[i]
            next_layer = layer_names[i + 1]
            feature_pairs.append((
                current_layer,
                feature_dict[current_layer],
                feature_dict[next_layer]
            ))
        
        # æ‰¹é‡è®¡ç®—æ¡ä»¶äº’ä¿¡æ¯
        if feature_pairs:
            conditional_mi_results = self.mi_estimator.batch_estimate_conditional_mi(
                feature_pairs, labels, num_classes
            )
        
        return conditional_mi_results
    
    def _analyze_gradient_flow(self, gradient_dict: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """åˆ†ææ¢¯åº¦æµåŠ¨"""
        gradient_flow_results = {}
        
        for layer_name, gradients in gradient_dict.items():
            try:
                # è®¡ç®—æ¢¯åº¦èŒƒæ•°
                grad_norm = torch.norm(gradients).item()
                
                # è®¡ç®—æ¢¯åº¦åˆ†å¸ƒçš„æ–¹å·®ï¼ˆåæ˜ æ¢¯åº¦åˆ†å¸ƒçš„å‡åŒ€æ€§ï¼‰
                grad_flat = gradients.view(-1)
                grad_variance = torch.var(grad_flat).item()
                
                # ç»¼åˆæ¢¯åº¦æµæŒ‡æ ‡
                gradient_flow = grad_norm * (1 + grad_variance)  # é«˜èŒƒæ•°+é«˜æ–¹å·®=å¥½çš„æ¢¯åº¦æµ
                gradient_flow_results[layer_name] = gradient_flow
                
            except Exception as e:
                logger.warning(f"Failed to analyze gradient flow for {layer_name}: {e}")
                gradient_flow_results[layer_name] = 0.0
                
        return gradient_flow_results
    
    def _analyze_layer_bottleneck(self,
                                 layer_name: str,
                                 features: torch.Tensor,
                                 mi_value: float,
                                 conditional_mi: float,
                                 uncertainty: float,
                                 gradient_flow: Optional[float],
                                 num_classes: int = None) -> Optional[BottleneckReport]:
        """åˆ†æå•å±‚çš„ç“¶é¢ˆæƒ…å†µ"""
        
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
        raw_metrics = {
            'mi_value': mi_value,
            'conditional_mi': conditional_mi,
            'uncertainty': uncertainty,
            'gradient_flow': gradient_flow,
            'feature_shape': features.shape,
            'feature_mean': features.mean().item(),
            'feature_std': features.std().item()
        }
        
        # å¤šç»´åº¦ç“¶é¢ˆæ£€æµ‹
        bottleneck_detections = []
        
        # 1. ä¿¡æ¯æ³„éœ²æ£€æµ‹ï¼šI(H_k; Y|H_{k+1}) â‰ˆ 0
        if conditional_mi < self.thresholds['conditional_mi_low']:
            severity = 1.0 - conditional_mi / self.thresholds['conditional_mi_low']
            bottleneck_detections.append({
                'type': BottleneckType.INFORMATION_LEAKAGE,
                'severity': min(severity, 1.0),
                'confidence': 0.9,  # é«˜ç½®ä¿¡åº¦
                'explanation': f"æ¡ä»¶äº’ä¿¡æ¯è¿‡ä½ ({conditional_mi:.4f})ï¼Œå½“å‰å±‚ä¿¡æ¯è¢«åç»­å±‚å®Œå…¨åŒ…å«",
                'mutations': ['expand_capacity', 'add_attention', 'insert_residual']
            })
        
        # 2. é«˜ä¸ç¡®å®šæ€§æ£€æµ‹
        if uncertainty > self.thresholds['uncertainty_high']:
            severity = min(uncertainty / self.thresholds['uncertainty_high'] - 1.0, 1.0)
            bottleneck_detections.append({
                'type': BottleneckType.HIGH_UNCERTAINTY,
                'severity': severity,
                'confidence': 0.8,
                'explanation': f"ä¸ç¡®å®šæ€§è¿‡é«˜ ({uncertainty:.4f})ï¼Œç‰¹å¾è¡¨å¾ä¸ç¨³å®š",
                'mutations': ['regularization', 'batch_norm', 'layer_norm']
            })
        
        # 3. äº’ä¿¡æ¯è¿‡ä½æ£€æµ‹ï¼šI(H_k; Y) ä½
        if mi_value < self.thresholds['mi_low']:
            severity = 1.0 - mi_value / self.thresholds['mi_low']
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å†—ä½™ç‰¹å¾ï¼ˆé«˜ç»´åº¦ä½†ä½ä¿¡æ¯ï¼‰
            feature_dim = np.prod(features.shape[1:])
            if feature_dim > 256:  # é«˜ç»´ç‰¹å¾
                bottleneck_detections.append({
                    'type': BottleneckType.REDUNDANT_FEATURES,
                    'severity': severity,
                    'confidence': 0.7,
                    'explanation': f"é«˜ç»´ç‰¹å¾ ({feature_dim}) ä½†äº’ä¿¡æ¯ä½ ({mi_value:.4f})ï¼Œå­˜åœ¨å†—ä½™",
                    'mutations': ['feature_selection', 'dimensionality_reduction', 'pruning']
                })
            else:
                bottleneck_detections.append({
                    'type': BottleneckType.CAPACITY_BOTTLENECK,
                    'severity': severity,
                    'confidence': 0.75,
                    'explanation': f"äº’ä¿¡æ¯è¿‡ä½ ({mi_value:.4f})ï¼Œè¡¨å¾èƒ½åŠ›ä¸è¶³",
                    'mutations': ['expand_width', 'add_depth', 'change_activation']
                })
        
        # 4. æ¢¯åº¦æµæ£€æµ‹
        if gradient_flow is not None and gradient_flow < self.thresholds['gradient_flow_low']:
            severity = 1.0 - gradient_flow / self.thresholds['gradient_flow_low']
            bottleneck_detections.append({
                'type': BottleneckType.GRADIENT_BOTTLENECK,
                'severity': min(severity, 1.0),
                'confidence': 0.6,
                'explanation': f"æ¢¯åº¦æµåŠ¨å—é˜» ({gradient_flow:.4f})ï¼Œè®­ç»ƒæ•ˆç‡ä½",
                'mutations': ['residual_connection', 'gradient_clipping', 'change_optimizer']
            })
        
        # é€‰æ‹©æœ€ä¸¥é‡çš„ç“¶é¢ˆ
        if not bottleneck_detections:
            return None
            
        primary_bottleneck = max(bottleneck_detections, key=lambda x: x['severity'] * x['confidence'])
        
        return BottleneckReport(
            layer_name=layer_name,
            bottleneck_type=primary_bottleneck['type'],
            severity=primary_bottleneck['severity'],
            confidence=primary_bottleneck['confidence'],
            mutual_info=mi_value,
            conditional_mutual_info=conditional_mi,
            uncertainty=uncertainty,
            explanation=primary_bottleneck['explanation'],
            suggested_mutations=primary_bottleneck['mutations'],
            raw_metrics=raw_metrics
        )
    
    def _update_adaptive_thresholds(self,
                                   mi_results: Dict[str, float],
                                   uncertainty_results: Dict[str, float]):
        """æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼"""
        # åŸºäºå½“å‰ç½‘ç»œçŠ¶æ€è°ƒæ•´é˜ˆå€¼
        if mi_results:
            mi_values = list(mi_results.values())
            mi_mean = np.mean(mi_values)
            mi_std = np.std(mi_values)
            
            # åŠ¨æ€è°ƒæ•´äº’ä¿¡æ¯é˜ˆå€¼ï¼ˆå‡å€¼çš„10%ä½œä¸ºä½é˜ˆå€¼ï¼‰
            self.thresholds['mi_low'] = max(0.001, mi_mean * 0.1)
            self.thresholds['conditional_mi_low'] = max(0.0005, mi_mean * 0.05)
        
        if uncertainty_results:
            uncertainty_values = [u for u in uncertainty_results.values() if u != float('inf')]
            if uncertainty_values:
                uncertainty_mean = np.mean(uncertainty_values)
                uncertainty_std = np.std(uncertainty_values)
                
                # åŠ¨æ€è°ƒæ•´ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼ˆå‡å€¼+2*æ ‡å‡†å·®ä½œä¸ºé«˜é˜ˆå€¼ï¼‰
                self.thresholds['uncertainty_high'] = max(0.5, uncertainty_mean + 2 * uncertainty_std)
        
        # è®°å½•é˜ˆå€¼å†å²
        self.adaptive_thresholds_history.append(dict(self.thresholds))
        
        logger.debug(f"Updated adaptive thresholds: {self.thresholds}")
    
    def get_bottleneck_summary(self, reports: List[BottleneckReport]) -> Dict[str, Any]:
        """ç”Ÿæˆç“¶é¢ˆæ£€æµ‹æ‘˜è¦"""
        if not reports:
            return {'status': 'no_bottlenecks', 'message': 'æœªæ£€æµ‹åˆ°æ˜¾è‘—ç“¶é¢ˆ'}
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_counts = {}
        for report in reports:
            type_name = report.bottleneck_type.value
            if type_name not in type_counts:
                type_counts[type_name] = 0
            type_counts[type_name] += 1
        
        # è®¡ç®—å¹³å‡ä¸¥é‡ç¨‹åº¦
        avg_severity = np.mean([r.severity for r in reports])
        avg_confidence = np.mean([r.confidence for r in reports])
        
        # è·å–æœ€ä¸¥é‡çš„ç“¶é¢ˆ
        most_severe = max(reports, key=lambda x: x.severity)
        
        return {
            'status': 'bottlenecks_detected',
            'total_bottlenecks': len(reports),
            'type_distribution': type_counts,
            'average_severity': avg_severity,
            'average_confidence': avg_confidence,
            'most_severe_layer': most_severe.layer_name,
            'most_severe_type': most_severe.bottleneck_type.value,
            'most_severe_severity': most_severe.severity,
            'recommended_priority': [r.layer_name for r in reports[:3]]  # å‰3ä¸ªä¼˜å…ˆå¤„ç†
        }
    
    def visualize_bottlenecks(self, reports: List[BottleneckReport]) -> str:
        """ç”Ÿæˆç“¶é¢ˆå¯è§†åŒ–æŠ¥å‘Š"""
        if not reports:
            return "âœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—ç“¶é¢ˆ"
        
        visualization = "ğŸ” ç“¶é¢ˆæ£€æµ‹æŠ¥å‘Š\n" + "="*50 + "\n"
        
        for i, report in enumerate(reports[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ª
            icon = "ğŸ”´" if report.severity > 0.7 else "ğŸŸ¡" if report.severity > 0.4 else "ğŸŸ¢"
            
            visualization += f"\n{icon} #{i} å±‚: {report.layer_name}\n"
            visualization += f"   ç±»å‹: {report.bottleneck_type.value}\n"
            visualization += f"   ä¸¥é‡ç¨‹åº¦: {report.severity:.3f} | ç½®ä¿¡åº¦: {report.confidence:.3f}\n"
            visualization += f"   äº’ä¿¡æ¯: {report.mutual_info:.4f} | æ¡ä»¶äº’ä¿¡æ¯: {report.conditional_mutual_info:.4f}\n"
            visualization += f"   ä¸ç¡®å®šæ€§: {report.uncertainty:.4f}\n"
            visualization += f"   åŸå› : {report.explanation}\n"
            visualization += f"   å»ºè®®: {', '.join(report.suggested_mutations)}\n"
        
        summary = self.get_bottleneck_summary(reports)
        visualization += f"\nğŸ“Š æ€»è®¡: {summary['total_bottlenecks']} ä¸ªç“¶é¢ˆ"
        visualization += f" | å¹³å‡ä¸¥é‡ç¨‹åº¦: {summary['average_severity']:.3f}\n"
        
        return visualization
    
    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        self.mi_estimator.clear_discriminators()
        self.uncertainty_estimator.clear_probes()
        self.detection_history.clear()
        self.adaptive_thresholds_history.clear()