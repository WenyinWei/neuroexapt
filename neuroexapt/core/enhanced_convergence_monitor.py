"""
å¢å¼ºæ”¶æ•›ç›‘æ§å™¨

è§£å†³åŸå§‹ç›‘æ§å™¨è¿‡äºä¿å®ˆçš„é—®é¢˜ï¼Œæä¾›æ›´æ™ºèƒ½çš„æ”¶æ•›åˆ¤æ–­
"""

import torch
import numpy as np
from typing import Dict, List, Any, Optional
import logging
from collections import deque

logger = logging.getLogger(__name__)


class EnhancedConvergenceMonitor:
    """
    å¢å¼ºæ”¶æ•›ç›‘æ§å™¨
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. æ›´çµæ´»çš„æ”¶æ•›æ£€æµ‹æ ‡å‡†
    2. åŸºäºæ€§èƒ½æ€åŠ¿çš„åŠ¨æ€è°ƒæ•´
    3. å¤šç»´åº¦æ”¶æ•›è¯„ä¼°
    4. æ”¯æŒæ¢ç´¢æ€§å˜å¼‚
    """
    
    def __init__(self, mode='balanced'):
        # æ€§èƒ½å†å²è¿½è¸ª
        self.performance_history = deque(maxlen=25)
        self.loss_history = deque(maxlen=25) 
        self.gradient_norm_history = deque(maxlen=20)
        
        # å˜å¼‚å†å²è¿½è¸ª
        self.last_morphogenesis_epoch = -1
        self.morphogenesis_history = []
        self.post_morphogenesis_performance = []
        
        # æ¨¡å¼é…ç½®
        self.mode = mode
        self.config = self._get_mode_config(mode)
        
        # æ”¶æ•›çŠ¶æ€è·Ÿè¸ª
        self.convergence_streak = 0
        self.stagnation_streak = 0
        
    def _get_mode_config(self, mode: str) -> Dict[str, Any]:
        """è·å–æ¨¡å¼é…ç½®"""
        
        configs = {
            'aggressive': {
                'min_epochs_between_morphogenesis': 3,  # æœ€å°é—´éš”3epoch
                'convergence_patience': 3,               # æ”¶æ•›æ£€æµ‹è€å¿ƒå€¼
                'stability_threshold': 0.05,             # æ›´å®½æ¾çš„ç¨³å®šæ€§é˜ˆå€¼
                'improvement_threshold': 0.005,          # æ›´ä½çš„æ”¹è¿›é˜ˆå€¼
                'saturation_window': 4,                  # æ›´çŸ­çš„é¥±å’Œæ£€æµ‹çª—å£
                'urgency_threshold': 0.3,                # æ›´ä½çš„ç´§æ€¥åº¦é˜ˆå€¼
                'exploration_enabled': True,             # å¯ç”¨æ¢ç´¢æ€§å˜å¼‚
                'exploration_interval': 8,               # æ¢ç´¢æ€§å˜å¼‚é—´éš”
            },
            'balanced': {
                'min_epochs_between_morphogenesis': 5,  # å¹³è¡¡çš„æœ€å°é—´éš”
                'convergence_patience': 4,               # å¹³è¡¡çš„æ”¶æ•›æ£€æµ‹
                'stability_threshold': 0.03,             # å¹³è¡¡çš„ç¨³å®šæ€§é˜ˆå€¼
                'improvement_threshold': 0.008,          # å¹³è¡¡çš„æ”¹è¿›é˜ˆå€¼
                'saturation_window': 5,                  # å¹³è¡¡çš„é¥±å’Œæ£€æµ‹çª—å£
                'urgency_threshold': 0.4,                # å¹³è¡¡çš„ç´§æ€¥åº¦é˜ˆå€¼
                'exploration_enabled': True,             # å¯ç”¨æ¢ç´¢æ€§å˜å¼‚
                'exploration_interval': 12,              # æ¢ç´¢æ€§å˜å¼‚é—´éš”
            },
            'conservative': {
                'min_epochs_between_morphogenesis': 8,  # ä¿å®ˆçš„æœ€å°é—´éš”
                'convergence_patience': 6,               # ä¿å®ˆçš„æ”¶æ•›æ£€æµ‹
                'stability_threshold': 0.02,             # ä¸¥æ ¼çš„ç¨³å®šæ€§é˜ˆå€¼
                'improvement_threshold': 0.01,           # è¾ƒé«˜çš„æ”¹è¿›é˜ˆå€¼
                'saturation_window': 8,                  # è¾ƒé•¿çš„é¥±å’Œæ£€æµ‹çª—å£
                'urgency_threshold': 0.6,                # è¾ƒé«˜çš„ç´§æ€¥åº¦é˜ˆå€¼
                'exploration_enabled': False,            # ç¦ç”¨æ¢ç´¢æ€§å˜å¼‚
                'exploration_interval': 20,              # å¾ˆé•¿çš„æ¢ç´¢é—´éš”
            }
        }
        
        return configs.get(mode, configs['balanced'])
    
    def should_allow_morphogenesis(self, 
                                  current_epoch: int,
                                  current_performance: float,
                                  current_loss: float,
                                  gradient_norm: Optional[float] = None) -> Dict[str, Any]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å…è®¸å½¢æ€å‘ç”Ÿï¼ˆå¢å¼ºç‰ˆï¼‰
        """
        
        # æ›´æ–°å†å²
        self.performance_history.append(current_performance)
        self.loss_history.append(current_loss)
        if gradient_norm is not None:
            self.gradient_norm_history.append(gradient_norm)
        
        # æ£€æŸ¥åŸºæœ¬é—´éš”è¦æ±‚
        epochs_since_last = current_epoch - self.last_morphogenesis_epoch
        min_interval = self.config['min_epochs_between_morphogenesis']
        
        # 1. ç¡¬æ€§æœ€å°é—´éš”æ£€æŸ¥ï¼ˆè¾ƒçŸ­ï¼‰
        if epochs_since_last < max(2, min_interval // 2):  # è‡³å°‘2ä¸ªepoch
            return {
                'allow': False,
                'reason': 'minimum_interval_not_met',
                'suggestion': f'ç­‰å¾…è‡³å°‘{max(2, min_interval // 2)}ä¸ªepochçš„ç¡¬æ€§é—´éš”',
                'epochs_to_wait': max(2, min_interval // 2) - epochs_since_last,
                'confidence': 0.95
            }
        
        # 2. å¤šç»´åº¦æ”¶æ•›åˆ†æ
        convergence_analysis = self._enhanced_convergence_analysis()
        
        # 3. æ€§èƒ½æ€åŠ¿åˆ†æ
        performance_situation = self._analyze_performance_situation()
        
        # 4. å˜å¼‚ç´§æ€¥åº¦è¯„ä¼°
        urgency_analysis = self._evaluate_morphogenesis_urgency(current_epoch, performance_situation)
        
        # 5. æ™ºèƒ½å†³ç­–é€»è¾‘
        decision = self._make_intelligent_decision(
            epochs_since_last, 
            convergence_analysis, 
            performance_situation, 
            urgency_analysis
        )
        
        # æ›´æ–°çŠ¶æ€ï¼ˆåªæ›´æ–°ç»Ÿè®¡ï¼Œä¸æ›´æ–°last_morphogenesis_epochï¼‰
        # last_morphogenesis_epoch åº”è¯¥åœ¨å®é™…æ‰§è¡Œå˜å¼‚åæ‰æ›´æ–°
        if decision['allow']:
            self.convergence_streak = 0
            self.stagnation_streak = 0
        else:
            self.convergence_streak += 1
            if performance_situation['trend'] == 'stagnant':
                self.stagnation_streak += 1
        
        # æ·»åŠ è¯¦ç»†ä¿¡æ¯
        decision.update({
            'convergence_analysis': convergence_analysis,
            'performance_situation': performance_situation,
            'urgency_analysis': urgency_analysis,
            'epochs_since_last': epochs_since_last,
            'mode': self.mode
        })
        
        return decision
    
    def _enhanced_convergence_analysis(self) -> Dict[str, Any]:
        """å¢å¼ºçš„æ”¶æ•›åˆ†æ"""
        
        if len(self.performance_history) < 3:
            return {
                'status': 'insufficient_data',
                'converged': False,
                'stability_score': 0.0,
                'confidence': 0.0
            }
        
        performance_data = list(self.performance_history)
        
        # 1. æ€§èƒ½ç¨³å®šæ€§åˆ†æ
        recent_window = min(self.config['convergence_patience'], len(performance_data))
        recent_performance = performance_data[-recent_window:]
        
        performance_std = np.std(recent_performance)
        performance_mean = np.mean(recent_performance)
        relative_std = performance_std / max(performance_mean, 0.01)
        
        stability_score = max(0, 1 - relative_std / self.config['stability_threshold'])
        
        # 2. è¶‹åŠ¿åˆ†æ
        if len(recent_performance) >= 3:
            trend_slope = np.polyfit(range(len(recent_performance)), recent_performance, 1)[0]
            trend_direction = 'improving' if trend_slope > 0.001 else 'declining' if trend_slope < -0.001 else 'stable'
        else:
            trend_slope = 0
            trend_direction = 'unknown'
        
        # 3. æŸå¤±æ”¶æ•›åˆ†æ
        loss_converged = True
        if len(self.loss_history) >= 3:
            recent_loss = list(self.loss_history)[-3:]
            loss_trend = np.polyfit(range(len(recent_loss)), recent_loss, 1)[0]
            loss_volatility = np.std(recent_loss) / max(np.mean(recent_loss), 0.01)
            loss_converged = abs(loss_trend) < 0.02 and loss_volatility < 0.1
        
        # 4. æ¢¯åº¦ç¨³å®šæ€§åˆ†æ
        gradient_stable = True
        if len(self.gradient_norm_history) >= 3:
            recent_grads = list(self.gradient_norm_history)[-3:]
            grad_std = np.std(recent_grads)
            grad_mean = np.mean(recent_grads)
            if grad_mean > 0:
                grad_relative_std = grad_std / grad_mean
                gradient_stable = grad_relative_std < 0.5  # æ›´å®½æ¾
        
        # 5. ç»¼åˆåˆ¤æ–­ï¼ˆæ›´å®½æ¾çš„æ ‡å‡†ï¼‰
        converged = (
            stability_score > 0.4 and  # é™ä½ç¨³å®šæ€§è¦æ±‚
            loss_converged and 
            gradient_stable
        )
        
        confidence = (stability_score + (1 if loss_converged else 0) + (1 if gradient_stable else 0)) / 3
        
        return {
            'status': 'converged' if converged else 'converging',
            'converged': converged,
            'stability_score': stability_score,
            'relative_std': relative_std,
            'trend_direction': trend_direction,
            'trend_slope': trend_slope,
            'loss_converged': loss_converged,
            'gradient_stable': gradient_stable,
            'confidence': confidence
        }
    
    def _analyze_performance_situation(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æ€åŠ¿"""
        
        if len(self.performance_history) < 4:
            return {
                'trend': 'unknown',
                'situation': 'insufficient_data',
                'urgency': 0.0
            }
        
        performance_data = list(self.performance_history)
        
        # çŸ­æœŸè¶‹åŠ¿ï¼ˆæœ€è¿‘4ä¸ªç‚¹ï¼‰
        short_term = performance_data[-4:]
        short_slope = np.polyfit(range(len(short_term)), short_term, 1)[0]
        
        # ä¸­æœŸè¶‹åŠ¿ï¼ˆæœ€è¿‘8ä¸ªç‚¹æˆ–å…¨éƒ¨ï¼‰
        mid_term_len = min(8, len(performance_data))
        mid_term = performance_data[-mid_term_len:]
        mid_slope = np.polyfit(range(len(mid_term)), mid_term, 1)[0]
        
        # æ”¹è¿›ç‡åˆ†æ
        window = min(self.config['saturation_window'], len(performance_data))
        recent_perf = performance_data[-window:]
        
        if len(recent_perf) >= 2:
            first_half = recent_perf[:len(recent_perf)//2]
            second_half = recent_perf[len(recent_perf)//2:]
            improvement = np.mean(second_half) - np.mean(first_half)
        else:
            improvement = 0
        
        # åˆ†ç±»æ€§èƒ½æ€åŠ¿
        if short_slope > 0.002:
            trend = 'improving'
            urgency = 0.2  # æ­£åœ¨æ”¹è¿›ï¼Œä¸æ€¥
        elif short_slope < -0.002:
            trend = 'declining'
            urgency = 0.8  # æ€§èƒ½ä¸‹é™ï¼Œç´§æ€¥
        elif abs(improvement) < self.config['improvement_threshold']:
            trend = 'stagnant'
            urgency = 0.6  # åœæ»ï¼Œéœ€è¦å˜å¼‚
        else:
            trend = 'stable'
            urgency = 0.3  # ç¨³å®šï¼Œä¸å¤ªæ€¥
        
        # ç¡®å®šæ•´ä½“æƒ…å†µ
        if trend == 'declining':
            situation = 'performance_degradation'
        elif trend == 'stagnant' and len(performance_data) >= 6:
            situation = 'performance_plateau' 
        elif trend == 'improving':
            situation = 'performance_growth'
        else:
            situation = 'stable_performance'
        
        return {
            'trend': trend,
            'situation': situation,
            'urgency': urgency,
            'short_slope': short_slope,
            'mid_slope': mid_slope,
            'improvement': improvement,
            'stagnation_streak': self.stagnation_streak
        }
    
    def _evaluate_morphogenesis_urgency(self, current_epoch: int, performance_situation: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å˜å¼‚ç´§æ€¥åº¦"""
        
        base_urgency = performance_situation['urgency']
        
        # è°ƒæ•´å› å­
        adjustment_factors = []
        
        # 1. åœæ»æ—¶é—´è°ƒæ•´
        if self.stagnation_streak > 3:
            adjustment_factors.append(0.2 * min(self.stagnation_streak / 5, 1.0))
        
        # 2. é•¿æœŸæ— å˜å¼‚è°ƒæ•´
        epochs_since_last = current_epoch - self.last_morphogenesis_epoch
        if epochs_since_last > self.config['exploration_interval']:
            adjustment_factors.append(0.3)  # æ¢ç´¢æ€§å˜å¼‚
        
        # 3. æ¨¡å¼è°ƒæ•´
        if self.mode == 'aggressive':
            adjustment_factors.append(0.2)  # ç§¯ææ¨¡å¼æ›´å®¹æ˜“å˜å¼‚
        elif self.mode == 'conservative':
            adjustment_factors.append(-0.2)  # ä¿å®ˆæ¨¡å¼ä¸æ˜“å˜å¼‚
        
        # 4. æ€§èƒ½æ°´å¹³è°ƒæ•´
        if self.performance_history:
            current_perf = self.performance_history[-1]
            if current_perf < 0.6:  # æ€§èƒ½è¾ƒä½æ—¶æ›´éœ€è¦å˜å¼‚
                adjustment_factors.append(0.2)
            elif current_perf > 0.85:  # æ€§èƒ½å¾ˆé«˜æ—¶ä¸æ€¥äºå˜å¼‚
                adjustment_factors.append(-0.1)
        
        total_adjustment = sum(adjustment_factors)
        final_urgency = max(0, min(1, base_urgency + total_adjustment))
        
        return {
            'base_urgency': base_urgency,
            'adjustments': adjustment_factors,
            'total_adjustment': total_adjustment,
            'final_urgency': final_urgency,
            'urgency_level': 'high' if final_urgency > 0.7 else 'medium' if final_urgency > 0.4 else 'low'
        }
    
    def _make_intelligent_decision(self, 
                                 epochs_since_last: int,
                                 convergence_analysis: Dict[str, Any],
                                 performance_situation: Dict[str, Any],
                                 urgency_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ™ºèƒ½å†³ç­–é€»è¾‘"""
        
        # åŸºç¡€æ¡ä»¶æ£€æŸ¥
        min_interval = self.config['min_epochs_between_morphogenesis']
        urgency_threshold = self.config['urgency_threshold']
        
        # 1. ç´§æ€¥æƒ…å†µï¼šç«‹å³å…è®¸å˜å¼‚
        if urgency_analysis['final_urgency'] > 0.8:
            return {
                'allow': True,
                'reason': 'high_urgency_morphogenesis',
                'suggestion': 'æ£€æµ‹åˆ°ç´§æ€¥æƒ…å†µï¼ˆæ€§èƒ½ä¸‹é™/ä¸¥é‡åœæ»ï¼‰ï¼Œç«‹å³æ‰§è¡Œå˜å¼‚',
                'confidence': 0.9,
                'decision_type': 'urgent'
            }
        
        # 2. æ¢ç´¢æ€§å˜å¼‚ï¼šå®šæœŸæ¢ç´¢
        if (self.config['exploration_enabled'] and 
            epochs_since_last >= self.config['exploration_interval']):
            return {
                'allow': True,
                'reason': 'exploratory_morphogenesis',
                'suggestion': 'æ‰§è¡Œæ¢ç´¢æ€§å˜å¼‚ä»¥å‘ç°æ–°çš„æ¶æ„ä¼˜åŒ–æœºä¼š',
                'confidence': 0.7,
                'decision_type': 'exploratory'
            }
        
        # 3. æ ‡å‡†å†³ç­–ï¼šåŸºäºæ”¶æ•›å’Œç´§æ€¥åº¦
        if epochs_since_last >= min_interval:
            # æ£€æŸ¥æ”¶æ•›çŠ¶æ€
            if convergence_analysis['converged']:
                # å·²æ”¶æ•›ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å˜å¼‚
                if urgency_analysis['final_urgency'] >= urgency_threshold:
                    return {
                        'allow': True,
                        'reason': 'converged_with_sufficient_urgency',
                        'suggestion': 'ç½‘ç»œå·²æ”¶æ•›ä¸”æ£€æµ‹åˆ°è¶³å¤Ÿçš„å˜å¼‚å¿…è¦æ€§',
                        'confidence': convergence_analysis['confidence'] * 0.8,
                        'decision_type': 'standard'
                    }
                else:
                    return {
                        'allow': False,
                        'reason': 'converged_but_low_urgency',
                        'suggestion': 'ç½‘ç»œå·²æ”¶æ•›ä½†å˜å¼‚ç´§æ€¥åº¦ä¸è¶³ï¼Œç»§ç»­è®­ç»ƒ',
                        'confidence': 0.7
                    }
            else:
                # æœªå®Œå…¨æ”¶æ•›ï¼Œæ£€æŸ¥æ˜¯å¦åœæ»
                if performance_situation['trend'] == 'stagnant' and self.stagnation_streak >= 4:
                    return {
                        'allow': True,
                        'reason': 'stagnation_override',
                        'suggestion': 'ç½‘ç»œè™½æœªå®Œå…¨æ”¶æ•›ä½†å‡ºç°æ˜æ˜¾åœæ»ï¼Œæ‰§è¡Œå˜å¼‚',
                        'confidence': 0.6,
                        'decision_type': 'stagnation_break'
                    }
                else:
                    return {
                        'allow': False,
                        'reason': 'still_converging',
                        'suggestion': 'ç½‘ç»œä»åœ¨æ”¶æ•›è¿‡ç¨‹ä¸­ï¼Œç­‰å¾…ç¨³å®š',
                        'confidence': 0.8
                    }
        
        # 4. é»˜è®¤ï¼šé—´éš”ä¸è¶³
        return {
            'allow': False,
            'reason': 'interval_insufficient',
            'suggestion': f'è·ç¦»ä¸Šæ¬¡å˜å¼‚ä»…{epochs_since_last}ä¸ªepochï¼Œéœ€è¦æ›´å¤šæ—¶é—´',
            'confidence': 0.9
        }
    
    def set_mode(self, mode: str):
        """è®¾ç½®ç›‘æ§æ¨¡å¼"""
        if mode in ['aggressive', 'balanced', 'conservative']:
            self.mode = mode
            self.config = self._get_mode_config(mode)
            logger.info(f"æ”¶æ•›ç›‘æ§æ¨¡å¼å·²è®¾ç½®ä¸º: {mode}")
        else:
            logger.warning(f"æœªçŸ¥æ¨¡å¼: {mode}ï¼Œä¿æŒå½“å‰æ¨¡å¼: {self.mode}")
    
    def record_morphogenesis_execution(self, current_epoch: int, mutation_info: Dict[str, Any]):
        """è®°å½•å®é™…æ‰§è¡Œçš„å˜å¼‚"""
        self.last_morphogenesis_epoch = current_epoch
        self.morphogenesis_history.append({
            'epoch': current_epoch,
            'mutation_info': mutation_info,
            'timestamp': len(self.morphogenesis_history)
        })
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.morphogenesis_history) > 50:
            self.morphogenesis_history = self.morphogenesis_history[-50:]
        
        logger.info(f"ğŸ“ è®°å½•å˜å¼‚æ‰§è¡Œ: epoch {current_epoch}, ç±»å‹ {mutation_info.get('mutation_type', 'unknown')}")
    
    def record_morphogenesis(self, epoch: int, morphogenesis_type: str, performance_before: float = 0.0):
        """å…¼å®¹æ€§æ–¹æ³•ï¼šè®°å½•å˜å¼‚äº‹ä»¶"""
        mutation_info = {
            'mutation_type': morphogenesis_type,
            'performance_before': performance_before
        }
        self.record_morphogenesis_execution(epoch, mutation_info)
    
    def reset_history(self):
        """é‡ç½®å†å²è®°å½•"""
        self.performance_history.clear()
        self.loss_history.clear() 
        self.gradient_norm_history.clear()
        self.morphogenesis_history.clear()
        self.post_morphogenesis_performance.clear()
        self.convergence_streak = 0
        self.stagnation_streak = 0
        logger.info("æ”¶æ•›ç›‘æ§å†å²å·²é‡ç½®")
    
    def get_status_summary(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        return {
            'mode': self.mode,
            'last_morphogenesis_epoch': self.last_morphogenesis_epoch,
            'convergence_streak': self.convergence_streak,
            'stagnation_streak': self.stagnation_streak,
            'performance_history_length': len(self.performance_history),
            'config': self.config
        }