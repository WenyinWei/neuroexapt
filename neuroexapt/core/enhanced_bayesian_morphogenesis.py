"""
å¢å¼ºè´å¶æ–¯å½¢æ€å‘ç”Ÿå¼•æ“

åŸºäºè´å¶æ–¯æ¨æ–­ã€é«˜æ–¯è¿‡ç¨‹å›å½’å’Œè’™ç‰¹å¡ç½—é‡‡æ ·çš„æ™ºèƒ½æ¶æ„å˜å¼‚å¼•æ“
è§£å†³ç°æœ‰ç³»ç»Ÿå˜å¼‚å†³ç­–è¿‡äºä¿å®ˆçš„é—®é¢˜
"""

from typing import Dict, Any, List, Tuple, Optional
import torch
import torch.nn as nn
import numpy as np
import logging
from scipy import stats
from scipy.optimize import minimize
import json
from collections import defaultdict, deque

logger = logging.getLogger(__name__)


class BayesianMorphogenesisEngine:
    """
    å¢å¼ºè´å¶æ–¯å½¢æ€å‘ç”Ÿå¼•æ“
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. è´å¶æ–¯ç½‘ç»œå»ºæ¨¡æ¶æ„å˜å¼‚çš„æˆåŠŸæ¦‚ç‡
    2. é«˜æ–¯è¿‡ç¨‹å›å½’é¢„æµ‹æ€§èƒ½æ”¹è¿›
    3. è’™ç‰¹å¡ç½—é‡‡æ ·é‡åŒ–ä¸ç¡®å®šæ€§
    4. æœŸæœ›æ•ˆç”¨æœ€å¤§åŒ–çš„å†³ç­–ç†è®º
    5. åœ¨çº¿å­¦ä¹ æ›´æ–°å…ˆéªŒåˆ†å¸ƒ
    """
    
    def __init__(self):
        # è´å¶æ–¯å…ˆéªŒåˆ†å¸ƒå‚æ•°
        self.mutation_priors = {
            'width_expansion': {'alpha': 15, 'beta': 5},      # è¾ƒé«˜æˆåŠŸç‡å…ˆéªŒ
            'depth_expansion': {'alpha': 12, 'beta': 8},      # ä¸­é«˜æˆåŠŸç‡å…ˆéªŒ
            'attention_enhancement': {'alpha': 10, 'beta': 10}, # ä¸­ç­‰æˆåŠŸç‡å…ˆéªŒ
            'residual_connection': {'alpha': 18, 'beta': 2},   # å¾ˆé«˜æˆåŠŸç‡å…ˆéªŒ
            'batch_norm_insertion': {'alpha': 20, 'beta': 5}, # å¾ˆé«˜æˆåŠŸç‡å…ˆéªŒ
            'parallel_division': {'alpha': 8, 'beta': 12},    # ä¸­ä½æˆåŠŸç‡ä½†é«˜æ”¶ç›Š
            'serial_division': {'alpha': 12, 'beta': 8},      # ä¸­é«˜æˆåŠŸç‡å…ˆéªŒ
            'channel_attention': {'alpha': 10, 'beta': 10},   # ä¸­ç­‰æˆåŠŸç‡å…ˆéªŒ
            'layer_norm': {'alpha': 16, 'beta': 4},          # é«˜æˆåŠŸç‡å…ˆéªŒ
            'information_enhancement': {'alpha': 9, 'beta': 11} # ä¸­ç­‰æˆåŠŸç‡å…ˆéªŒ
        }
        
        # é«˜æ–¯è¿‡ç¨‹è¶…å‚æ•°
        self.gp_params = {
            'length_scale': 1.0,
            'signal_variance': 1.0,
            'noise_variance': 0.1,
            'mean_function': 0.0
        }
        
        # å†å²æ•°æ®å­˜å‚¨
        self.mutation_history = deque(maxlen=100)  # å˜å¼‚å†å²
        self.performance_history = deque(maxlen=50)  # æ€§èƒ½å†å²
        self.architecture_features = deque(maxlen=100)  # æ¶æ„ç‰¹å¾å†å²
        
        # æ•ˆç”¨å‡½æ•°å‚æ•°
        self.utility_params = {
            'accuracy_weight': 1.0,        # å‡†ç¡®ç‡æƒé‡
            'efficiency_weight': 0.3,      # æ•ˆç‡æƒé‡
            'risk_aversion': 0.2,          # é£é™©åŒæ¶ç¨‹åº¦
            'exploration_bonus': 0.1       # æ¢ç´¢å¥–åŠ±
        }
        
        # ä¸ç¡®å®šæ€§é‡åŒ–å‚æ•°
        self.mc_samples = 500
        self.confidence_levels = [0.68, 0.95, 0.99]
        
        # åŠ¨æ€é˜ˆå€¼ï¼ˆæ›´ç§¯æï¼‰
        self.dynamic_thresholds = {
            'min_expected_improvement': 0.002,   # æœ€å°æœŸæœ›æ”¹è¿›ï¼ˆ0.2%ï¼‰
            'max_acceptable_risk': 0.4,         # æœ€å¤§å¯æ¥å—é£é™©
            'confidence_threshold': 0.3,        # ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ›´ä½ï¼‰
            'exploration_threshold': 0.25       # æ¢ç´¢é˜ˆå€¼
        }
    
    def bayesian_morphogenesis_analysis(self, 
                                      model: nn.Module,
                                      context: Dict[str, Any]) -> Dict[str, Any]:
        """
        è´å¶æ–¯å½¢æ€å‘ç”Ÿåˆ†æ
        
        æ•´åˆå¤šç§è´å¶æ–¯æ–¹æ³•è¿›è¡Œæ™ºèƒ½å†³ç­–
        """
        logger.info("ğŸ§  å¯åŠ¨å¢å¼ºè´å¶æ–¯å½¢æ€å‘ç”Ÿåˆ†æ")
        
        try:
            # 1. æå–æ¶æ„ç‰¹å¾
            arch_features = self._extract_architecture_features(model, context)
            
            # 2. è¯†åˆ«å€™é€‰å˜å¼‚ç‚¹ï¼ˆä½¿ç”¨æ›´ç§¯æçš„æ£€æµ‹ï¼‰
            candidates = self._aggressive_candidate_detection(model, context, arch_features)
            
            # 3. è´å¶æ–¯å˜å¼‚æˆåŠŸç‡æ¨æ–­
            success_probabilities = self._bayesian_success_inference(candidates, arch_features)
            
            # 4. é«˜æ–¯è¿‡ç¨‹æ€§èƒ½æ”¹è¿›é¢„æµ‹
            improvement_predictions = self._gaussian_process_prediction(candidates, arch_features)
            
            # 5. è’™ç‰¹å¡ç½—ä¸ç¡®å®šæ€§é‡åŒ–
            uncertainty_analysis = self._monte_carlo_uncertainty(
                candidates, success_probabilities, improvement_predictions
            )
            
            # 6. æœŸæœ›æ•ˆç”¨æœ€å¤§åŒ–å†³ç­–
            optimal_decisions = self._expected_utility_maximization(
                candidates, success_probabilities, improvement_predictions, uncertainty_analysis
            )
            
            # 7. ç”Ÿæˆæ‰§è¡Œå»ºè®®
            execution_plan = self._generate_bayesian_execution_plan(
                optimal_decisions, uncertainty_analysis, context
            )
            
            # 8. æ›´æ–°å†å²æ•°æ®
            self._update_bayesian_history(arch_features, candidates, context)
            
            return {
                'bayesian_analysis': {
                    'candidates_found': len(candidates),
                    'success_probabilities': success_probabilities,
                    'improvement_predictions': improvement_predictions,
                    'uncertainty_analysis': uncertainty_analysis,
                    'decision_confidence': self._calculate_overall_confidence(uncertainty_analysis)
                },
                'optimal_decisions': optimal_decisions,
                'execution_plan': execution_plan,
                'bayesian_insights': {
                    'most_promising_mutation': optimal_decisions[0] if optimal_decisions else None,
                    'expected_performance_gain': self._calculate_expected_gain(optimal_decisions),
                    'risk_assessment': self._comprehensive_risk_assessment(optimal_decisions)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ è´å¶æ–¯åˆ†æå¤±è´¥: {e}")
            return self._fallback_bayesian_analysis()
    
    def _extract_architecture_features(self, model: nn.Module, context: Dict[str, Any]) -> Dict[str, float]:
        """æå–æ¶æ„ç‰¹å¾å‘é‡"""
        
        features = {}
        
        # åŸºç¡€æ¶æ„ç»Ÿè®¡
        total_params = sum(p.numel() for p in model.parameters())
        features['total_parameters'] = float(total_params)
        features['model_depth'] = len(list(model.modules()))
        
        # å±‚ç±»å‹åˆ†å¸ƒ
        layer_types = defaultdict(int)
        for module in model.modules():
            layer_types[type(module).__name__] += 1
        
        features['conv_layers'] = layer_types.get('Conv2d', 0)
        features['linear_layers'] = layer_types.get('Linear', 0)
        features['norm_layers'] = layer_types.get('BatchNorm2d', 0) + layer_types.get('LayerNorm', 0)
        features['activation_layers'] = layer_types.get('ReLU', 0) + layer_types.get('GELU', 0)
        
        # æ€§èƒ½æŒ‡æ ‡
        performance_history = context.get('performance_history', [])
        if performance_history:
            features['current_accuracy'] = performance_history[-1]
            features['accuracy_trend'] = self._calculate_trend(performance_history[-5:])
            features['accuracy_variance'] = np.var(performance_history[-10:]) if len(performance_history) >= 10 else 0
        
        # è®­ç»ƒçŠ¶æ€
        features['current_epoch'] = context.get('epoch', 0)
        features['train_loss'] = context.get('train_loss', 1.0)
        features['learning_rate'] = context.get('learning_rate', 0.1)
        
        # æ¿€æ´»ç»Ÿè®¡
        activations = context.get('activations', {})
        if activations:
            features['avg_activation_magnitude'] = np.mean([
                torch.mean(torch.abs(act)).item() for act in activations.values()
            ])
            features['activation_sparsity'] = np.mean([
                (act == 0).float().mean().item() for act in activations.values()
            ])
        
        # æ¢¯åº¦ç»Ÿè®¡
        gradients = context.get('gradients', {})
        if gradients:
            features['avg_gradient_norm'] = np.mean([
                torch.norm(grad).item() for grad in gradients.values()
            ])
            features['gradient_variance'] = np.var([
                torch.norm(grad).item() for grad in gradients.values()
            ])
        
        return features
    
    def _aggressive_candidate_detection(self, 
                                      model: nn.Module, 
                                      context: Dict[str, Any],
                                      arch_features: Dict[str, float]) -> List[Dict[str, Any]]:
        """ç§¯æçš„å€™é€‰ç‚¹æ£€æµ‹ï¼ˆæ›´å®¹æ˜“å‘ç°å€™é€‰ç‚¹ï¼‰"""
        
        candidates = []
        activations = context.get('activations', {})
        gradients = context.get('gradients', {})
        
        # é™ä½æ£€æµ‹é˜ˆå€¼ï¼Œæ›´å®¹æ˜“å‘ç°å€™é€‰ç‚¹
        bottleneck_threshold = 0.3    # ä»0.5é™ä½åˆ°0.3
        improvement_threshold = 0.2   # ä»0.3é™ä½åˆ°0.2
        
        for name, module in model.named_modules():
            if not isinstance(module, (nn.Conv2d, nn.Linear, nn.BatchNorm2d)):
                continue
            
            candidate = {
                'layer_name': name,
                'layer_type': type(module).__name__,
                'module': module,
                'bottleneck_indicators': {},
                'improvement_signals': {},
                'mutation_suitability': {}
            }
            
            # 1. å‚æ•°åˆ©ç”¨ç‡åˆ†æï¼ˆæ›´æ•æ„Ÿï¼‰
            param_utilization = self._analyze_parameter_utilization(module, activations.get(name))
            candidate['bottleneck_indicators']['parameter_utilization'] = param_utilization
            
            # 2. ä¿¡æ¯æµæ•ˆç‡åˆ†æï¼ˆæ›´æ•æ„Ÿï¼‰
            if name in activations:
                info_efficiency = self._analyze_information_efficiency(activations[name])
                candidate['bottleneck_indicators']['information_efficiency'] = info_efficiency
            
            # 3. æ¢¯åº¦è´¨é‡åˆ†æï¼ˆæ›´æ•æ„Ÿï¼‰
            if name in gradients:
                gradient_quality = self._analyze_gradient_quality(gradients[name])
                candidate['bottleneck_indicators']['gradient_quality'] = gradient_quality
            
            # 4. æ¶æ„åŒ¹é…åº¦åˆ†æ
            arch_mismatch = self._analyze_architecture_mismatch(module, arch_features)
            candidate['bottleneck_indicators']['architecture_mismatch'] = arch_mismatch
            
            # ç»¼åˆè¯„åˆ†ï¼ˆæ›´å®¹æ˜“é€šè¿‡ï¼‰
            bottleneck_score = np.mean(list(candidate['bottleneck_indicators'].values()))
            
            if bottleneck_score > bottleneck_threshold:
                # åˆ†æå˜å¼‚é€‚ç”¨æ€§
                self._analyze_mutation_suitability(candidate, arch_features)
                
                # è®¡ç®—æ”¹è¿›ä¿¡å·
                candidate['improvement_potential'] = min(1.0, bottleneck_score * 1.5)
                candidate['urgency_score'] = self._calculate_urgency_score(candidate, context)
                
                candidates.append(candidate)
                logger.info(f"âœ… å‘ç°å€™é€‰å±‚: {name}, ç“¶é¢ˆåˆ†æ•°: {bottleneck_score:.3f}")
        
        # å³ä½¿æ²¡æœ‰æ˜æ˜¾ç“¶é¢ˆï¼Œä¹Ÿæ ¹æ®æ€§èƒ½æ€åŠ¿æ·»åŠ æ¢ç´¢æ€§å€™é€‰
        if len(candidates) < 2:
            exploration_candidates = self._generate_exploration_candidates(model, arch_features, context)
            candidates.extend(exploration_candidates)
        
        # æŒ‰æ½œåŠ›æ’åº
        candidates.sort(key=lambda x: x['improvement_potential'], reverse=True)
        
        logger.info(f"ğŸ¯ ç§¯ææ£€æµ‹å‘ç°: {len(candidates)}ä¸ªå€™é€‰ç‚¹")
        return candidates
    
    def _bayesian_success_inference(self, 
                                  candidates: List[Dict[str, Any]], 
                                  arch_features: Dict[str, float]) -> Dict[str, Dict[str, float]]:
        """è´å¶æ–¯å˜å¼‚æˆåŠŸç‡æ¨æ–­"""
        
        success_probs = {}
        
        for candidate in candidates:
            layer_name = candidate['layer_name']
            success_probs[layer_name] = {}
            
            for mutation_type in candidate.get('mutation_suitability', {}):
                # è·å–å…ˆéªŒåˆ†å¸ƒ
                prior = self.mutation_priors.get(mutation_type, {'alpha': 5, 'beta': 5})
                
                # åŸºäºå†å²æ•°æ®æ›´æ–°å…ˆéªŒ
                updated_prior = self._update_prior_with_history(mutation_type, arch_features)
                
                # è®¡ç®—åéªŒæ¦‚ç‡
                posterior_prob = self._calculate_posterior_success_probability(
                    updated_prior, candidate, mutation_type, arch_features
                )
                
                success_probs[layer_name][mutation_type] = posterior_prob
        
        return success_probs
    
    def _gaussian_process_prediction(self, 
                                   candidates: List[Dict[str, Any]], 
                                   arch_features: Dict[str, float]) -> Dict[str, Dict[str, Dict[str, float]]]:
        """é«˜æ–¯è¿‡ç¨‹æ€§èƒ½æ”¹è¿›é¢„æµ‹"""
        
        predictions = {}
        
        for candidate in candidates:
            layer_name = candidate['layer_name']
            predictions[layer_name] = {}
            
            for mutation_type in candidate.get('mutation_suitability', {}):
                # æ„å»ºç‰¹å¾å‘é‡
                feature_vector = self._build_gp_feature_vector(candidate, mutation_type, arch_features)
                
                # é«˜æ–¯è¿‡ç¨‹é¢„æµ‹
                mean_improvement, variance = self._gp_predict_improvement(
                    feature_vector, mutation_type
                )
                
                # è®¡ç®—ç½®ä¿¡åŒºé—´
                std_dev = np.sqrt(variance)
                confidence_intervals = {}
                for confidence in self.confidence_levels:
                    z_score = stats.norm.ppf((1 + confidence) / 2)
                    ci_lower = mean_improvement - z_score * std_dev
                    ci_upper = mean_improvement + z_score * std_dev
                    confidence_intervals[f'{int(confidence*100)}%'] = (ci_lower, ci_upper)
                
                predictions[layer_name][mutation_type] = {
                    'mean_improvement': mean_improvement,
                    'variance': variance,
                    'std_dev': std_dev,
                    'confidence_intervals': confidence_intervals
                }
        
        return predictions
    
    def _monte_carlo_uncertainty(self, 
                               candidates: List[Dict[str, Any]],
                               success_probabilities: Dict[str, Dict[str, float]],
                               improvement_predictions: Dict[str, Dict[str, Dict[str, float]]]) -> Dict[str, Any]:
        """è’™ç‰¹å¡ç½—ä¸ç¡®å®šæ€§é‡åŒ–"""
        
        mc_results = {}
        
        for candidate in candidates:
            layer_name = candidate['layer_name']
            mc_results[layer_name] = {}
            
            for mutation_type in candidate.get('mutation_suitability', {}):
                success_prob = success_probabilities[layer_name][mutation_type]
                improvement_pred = improvement_predictions[layer_name][mutation_type]
                
                # è’™ç‰¹å¡ç½—é‡‡æ ·
                mc_samples = []
                for _ in range(self.mc_samples):
                    # é‡‡æ ·æˆåŠŸ/å¤±è´¥
                    success = np.random.random() < success_prob
                    
                    if success:
                        # ä»é¢„æµ‹åˆ†å¸ƒä¸­é‡‡æ ·æ”¹è¿›å€¼
                        improvement = np.random.normal(
                            improvement_pred['mean_improvement'],
                            improvement_pred['std_dev']
                        )
                    else:
                        # å¤±è´¥æƒ…å†µä¸‹çš„æ€§èƒ½æŸå¤±
                        improvement = np.random.normal(-0.01, 0.005)  # å°å¹…æ€§èƒ½ä¸‹é™
                    
                    mc_samples.append(improvement)
                
                mc_samples = np.array(mc_samples)
                
                # ç»Ÿè®¡åˆ†æ
                mc_results[layer_name][mutation_type] = {
                    'expected_value': np.mean(mc_samples),
                    'variance': np.var(mc_samples),
                    'percentiles': {
                        '5%': np.percentile(mc_samples, 5),
                        '25%': np.percentile(mc_samples, 25),
                        '50%': np.percentile(mc_samples, 50),
                        '75%': np.percentile(mc_samples, 75),
                        '95%': np.percentile(mc_samples, 95)
                    },
                    'probability_positive': np.mean(mc_samples > 0),
                    'value_at_risk_5%': np.percentile(mc_samples, 5),  # VaR
                    'expected_shortfall_5%': np.mean(mc_samples[mc_samples <= np.percentile(mc_samples, 5)])
                }
        
        return mc_results
    
    def _expected_utility_maximization(self,
                                     candidates: List[Dict[str, Any]],
                                     success_probabilities: Dict[str, Dict[str, float]],
                                     improvement_predictions: Dict[str, Dict[str, Dict[str, float]]],
                                     uncertainty_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æœŸæœ›æ•ˆç”¨æœ€å¤§åŒ–å†³ç­–"""
        
        decisions = []
        
        for candidate in candidates:
            layer_name = candidate['layer_name']
            
            for mutation_type in candidate.get('mutation_suitability', {}):
                # è®¡ç®—æœŸæœ›æ•ˆç”¨
                expected_utility = self._calculate_expected_utility(
                    layer_name, mutation_type, 
                    success_probabilities, improvement_predictions, uncertainty_analysis
                )
                
                # è®¡ç®—å†³ç­–ç½®ä¿¡åº¦
                decision_confidence = self._calculate_decision_confidence(
                    layer_name, mutation_type, uncertainty_analysis
                )
                
                # æ£€æŸ¥æ˜¯å¦æ»¡è¶³å†³ç­–é˜ˆå€¼
                if (expected_utility > self.dynamic_thresholds['min_expected_improvement'] and
                    decision_confidence > self.dynamic_thresholds['confidence_threshold']):
                    
                    decision = {
                        'layer_name': layer_name,
                        'mutation_type': mutation_type,
                        'expected_utility': expected_utility,
                        'decision_confidence': decision_confidence,
                        'success_probability': success_probabilities[layer_name][mutation_type],
                        'expected_improvement': improvement_predictions[layer_name][mutation_type]['mean_improvement'],
                        'risk_metrics': {
                            'value_at_risk': uncertainty_analysis[layer_name][mutation_type]['value_at_risk_5%'],
                            'expected_shortfall': uncertainty_analysis[layer_name][mutation_type]['expected_shortfall_5%'],
                            'probability_positive': uncertainty_analysis[layer_name][mutation_type]['probability_positive']
                        },
                        'rationale': self._generate_decision_rationale(
                            candidate, mutation_type, expected_utility, decision_confidence
                        )
                    }
                    
                    decisions.append(decision)
        
        # æŒ‰æœŸæœ›æ•ˆç”¨æ’åº
        decisions.sort(key=lambda x: x['expected_utility'], reverse=True)
        
        # é€‰æ‹©æœ€ä¼˜å†³ç­–ï¼ˆè€ƒè™‘å¤šæ ·æ€§ï¼‰
        selected_decisions = self._select_diverse_decisions(decisions)
        
        logger.info(f"ğŸ¯ æœŸæœ›æ•ˆç”¨æœ€å¤§åŒ–: é€‰æ‹©{len(selected_decisions)}ä¸ªæœ€ä¼˜å†³ç­–")
        return selected_decisions
    
    def _generate_bayesian_execution_plan(self,
                                        optimal_decisions: List[Dict[str, Any]],
                                        uncertainty_analysis: Dict[str, Any],
                                        context: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè´å¶æ–¯æ‰§è¡Œè®¡åˆ’"""
        
        if not optimal_decisions:
            return {
                'execute': False,
                'reason': 'no_viable_decisions_after_bayesian_analysis',
                'recommendations': [
                    'continue_training_with_current_architecture',
                    'adjust_hyperparameters',
                    'consider_data_augmentation'
                ]
            }
        
        primary_decision = optimal_decisions[0]
        
        execution_plan = {
            'execute': True,
            'bayesian_strategy': {
                'primary_decision': primary_decision,
                'expected_improvement': primary_decision['expected_improvement'],
                'success_probability': primary_decision['success_probability'],
                'decision_confidence': primary_decision['decision_confidence']
            },
            'alternative_strategies': optimal_decisions[1:3] if len(optimal_decisions) > 1 else [],
            'risk_management': {
                'monitoring_metrics': [
                    'accuracy_improvement',
                    'loss_reduction', 
                    'gradient_stability',
                    'computational_efficiency'
                ],
                'early_stopping_criteria': [
                    f"accuracy_drop > {abs(primary_decision['risk_metrics']['value_at_risk']):.3f}",
                    'loss_divergence_detected',
                    'gradient_explosion_detected'
                ],
                'rollback_triggers': [
                    f"performance_below_5th_percentile_for_3_epochs",
                    'critical_model_instability'
                ]
            },
            'adaptive_execution': {
                'success_threshold': primary_decision['expected_improvement'] * 0.5,
                'monitoring_frequency': 'every_epoch',
                'adaptation_strategy': 'bayesian_update_with_new_evidence'
            },
            'uncertainty_tracking': {
                'confidence_evolution': 'track_decision_confidence_over_time',
                'posterior_updates': 'update_priors_based_on_results',
                'next_decision_preparation': 'prepare_for_next_bayesian_cycle'
            }
        }
        
        return execution_plan
    
    # === è¾…åŠ©æ–¹æ³•å®ç° ===
    
    def _calculate_trend(self, values: List[float]) -> float:
        """è®¡ç®—è¶‹åŠ¿æ–œç‡"""
        if len(values) < 2:
            return 0.0
        x = np.arange(len(values))
        slope, _ = np.polyfit(x, values, 1)
        return slope
    
    def _analyze_parameter_utilization(self, module: nn.Module, activation: Optional[torch.Tensor]) -> float:
        """åˆ†æå‚æ•°åˆ©ç”¨ç‡ï¼ˆæ›´æ•æ„Ÿçš„æ£€æµ‹ï¼‰"""
        
        base_score = 0.0
        
        if isinstance(module, nn.Conv2d):
            # é€šé“æ•°ç›¸å¯¹å……åˆ†æ€§
            channel_ratio = module.out_channels / max(16, module.in_channels)  # é™ä½åŸºå‡†
            if channel_ratio < 0.8:  # æ›´æ•æ„Ÿçš„é˜ˆå€¼
                base_score += 0.6
            
            # å·ç§¯æ ¸å¤§å°é€‚ç”¨æ€§
            if module.kernel_size[0] <= 3:
                base_score += 0.3
                
        elif isinstance(module, nn.Linear):
            # ç‰¹å¾æ•°ç›¸å¯¹å……åˆ†æ€§
            feature_ratio = module.out_features / max(32, module.in_features)  # é™ä½åŸºå‡†
            if feature_ratio < 0.5:  # æ›´æ•æ„Ÿçš„é˜ˆå€¼
                base_score += 0.7
        
        # å¦‚æœæœ‰æ¿€æ´»å€¼ï¼Œåˆ†ææ¿€æ´»æ¨¡å¼
        if activation is not None:
            try:
                # æ¿€æ´»ç¨€ç–æ€§
                sparsity = (activation == 0).float().mean().item()
                if sparsity > 0.7:  # é«˜ç¨€ç–æ€§è¡¨æ˜å‚æ•°æœªå……åˆ†åˆ©ç”¨
                    base_score += 0.4
                
                # æ¿€æ´»åˆ†å¸ƒé›†ä¸­åº¦
                flat_act = activation.flatten()
                if len(flat_act) > 0:
                    std_act = torch.std(flat_act).item()
                    if std_act < 0.1:  # ä½æ–¹å·®è¡¨æ˜ä¿¡æ¯ä¸è¶³
                        base_score += 0.3
            except:
                pass
        
        return min(1.0, base_score)
    
    def _analyze_information_efficiency(self, activation: torch.Tensor) -> float:
        """åˆ†æä¿¡æ¯æ•ˆç‡ï¼ˆæ›´æ•æ„Ÿçš„æ£€æµ‹ï¼‰"""
        
        try:
            flat_activation = activation.flatten()
            
            # æœ‰æ•ˆæ¿€æ´»æ¯”ä¾‹
            non_zero_ratio = torch.count_nonzero(flat_activation).float() / flat_activation.numel()
            efficiency_loss = 1 - non_zero_ratio
            
            # åŠ¨æ€èŒƒå›´åˆ©ç”¨
            activation_range = torch.max(flat_activation) - torch.min(flat_activation)
            if activation_range < 1.0:  # åŠ¨æ€èŒƒå›´ä¸è¶³
                efficiency_loss += 0.3
            
            # ä¿¡æ¯ç†µ
            hist = torch.histc(flat_activation, bins=20)
            hist_normalized = hist / (hist.sum() + 1e-10)
            entropy = -torch.sum(hist_normalized * torch.log(hist_normalized + 1e-10))
            max_entropy = np.log(20)
            if entropy / max_entropy < 0.5:  # ç†µä¸è¶³
                efficiency_loss += 0.4
            
            return min(1.0, efficiency_loss)
            
        except Exception:
            return 0.5  # é»˜è®¤ä¸­ç­‰æ•ˆç‡æŸå¤±
    
    def _analyze_gradient_quality(self, gradient: torch.Tensor) -> float:
        """åˆ†ææ¢¯åº¦è´¨é‡ï¼ˆæ›´æ•æ„Ÿçš„æ£€æµ‹ï¼‰"""
        
        try:
            # æ¢¯åº¦èŒƒæ•°
            grad_norm = torch.norm(gradient).item()
            quality_loss = 0.0
            
            # æ¢¯åº¦æ¶ˆå¤±æ£€æµ‹
            if grad_norm < 1e-5:
                quality_loss += 0.8
            elif grad_norm < 1e-3:
                quality_loss += 0.4
            
            # æ¢¯åº¦çˆ†ç‚¸æ£€æµ‹
            if grad_norm > 10.0:
                quality_loss += 0.6
            elif grad_norm > 1.0:
                quality_loss += 0.2
            
            # æ¢¯åº¦åˆ†å¸ƒ
            grad_std = torch.std(gradient).item()
            grad_mean = torch.mean(torch.abs(gradient)).item()
            
            if grad_std / (grad_mean + 1e-10) > 10:  # é«˜æ–¹å·®
                quality_loss += 0.3
            
            return min(1.0, quality_loss)
            
        except Exception:
            return 0.4  # é»˜è®¤ä¸­ç­‰è´¨é‡æŸå¤±
    
    def _analyze_architecture_mismatch(self, module: nn.Module, arch_features: Dict[str, float]) -> float:
        """åˆ†ææ¶æ„ä¸åŒ¹é…åº¦"""
        
        mismatch_score = 0.0
        
        # æ¨¡å‹å¤æ‚åº¦ç›¸å¯¹äºæ€§èƒ½çš„ä¸åŒ¹é…
        current_accuracy = arch_features.get('current_accuracy', 0.5)
        total_params = arch_features.get('total_parameters', 1000000)
        
        # å‚æ•°æ•ˆç‡
        param_efficiency = current_accuracy / (total_params / 1000000)  # æ¯ç™¾ä¸‡å‚æ•°çš„å‡†ç¡®ç‡
        if param_efficiency < 0.3:  # å‚æ•°æ•ˆç‡ä½
            mismatch_score += 0.4
        
        # æ·±åº¦vså®½åº¦å¹³è¡¡
        depth = arch_features.get('model_depth', 10)
        conv_layers = arch_features.get('conv_layers', 1)
        if conv_layers > 0 and depth / conv_layers > 10:  # è¿‡æ·±ç›¸å¯¹äºå®½åº¦
            mismatch_score += 0.3
        
        return min(1.0, mismatch_score)
    
    def _analyze_mutation_suitability(self, candidate: Dict[str, Any], arch_features: Dict[str, float]):
        """åˆ†æå˜å¼‚é€‚ç”¨æ€§"""
        
        suitability = {}
        layer_type = candidate['layer_type']
        bottlenecks = candidate['bottleneck_indicators']
        
        # ä¸ºæ¯ç§å˜å¼‚ç±»å‹è®¡ç®—é€‚ç”¨æ€§åˆ†æ•°
        mutations_to_check = [
            'width_expansion', 'depth_expansion', 'attention_enhancement',
            'residual_connection', 'batch_norm_insertion', 'parallel_division',
            'serial_division', 'channel_attention', 'layer_norm', 'information_enhancement'
        ]
        
        for mutation in mutations_to_check:
            score = self._calculate_mutation_suitability_score(
                mutation, layer_type, bottlenecks, arch_features
            )
            if score > 0.2:  # è¾ƒä½çš„é˜ˆå€¼
                suitability[mutation] = score
        
        candidate['mutation_suitability'] = suitability
    
    def _calculate_mutation_suitability_score(self, 
                                            mutation: str,
                                            layer_type: str,
                                            bottlenecks: Dict[str, float],
                                            arch_features: Dict[str, float]) -> float:
        """è®¡ç®—ç‰¹å®šå˜å¼‚çš„é€‚ç”¨æ€§åˆ†æ•°"""
        
        score = 0.0
        
        # åŸºäºå±‚ç±»å‹çš„åŸºç¡€é€‚ç”¨æ€§
        layer_compatibility = {
            'Conv2d': {
                'width_expansion': 0.8, 'depth_expansion': 0.6, 'attention_enhancement': 0.7,
                'parallel_division': 0.9, 'channel_attention': 0.8
            },
            'Linear': {
                'width_expansion': 0.9, 'depth_expansion': 0.4, 'serial_division': 0.7,
                'batch_norm_insertion': 0.3, 'layer_norm': 0.8
            }
        }
        
        score += layer_compatibility.get(layer_type, {}).get(mutation, 0.5)
        
        # åŸºäºç“¶é¢ˆç±»å‹çš„é€‚ç”¨æ€§
        if bottlenecks.get('parameter_utilization', 0) > 0.4:
            if mutation in ['width_expansion', 'depth_expansion', 'parallel_division']:
                score += 0.3
        
        if bottlenecks.get('information_efficiency', 0) > 0.4:
            if mutation in ['attention_enhancement', 'channel_attention', 'information_enhancement']:
                score += 0.3
        
        if bottlenecks.get('gradient_quality', 0) > 0.4:
            if mutation in ['residual_connection', 'batch_norm_insertion', 'layer_norm']:
                score += 0.3
        
        # åŸºäºæ¶æ„ç‰¹å¾çš„é€‚ç”¨æ€§
        current_accuracy = arch_features.get('current_accuracy', 0.5)
        if current_accuracy < 0.7:  # å‡†ç¡®ç‡è¾ƒä½æ—¶ï¼Œæ›´æ¿€è¿›çš„å˜å¼‚
            if mutation in ['depth_expansion', 'parallel_division', 'attention_enhancement']:
                score += 0.2
        
        return min(1.0, score)
    
    def _calculate_urgency_score(self, candidate: Dict[str, Any], context: Dict[str, Any]) -> float:
        """è®¡ç®—ç´§æ€¥æ€§åˆ†æ•°"""
        
        urgency = 0.0
        
        # åŸºäºæ€§èƒ½æ€åŠ¿
        performance_history = context.get('performance_history', [])
        if len(performance_history) >= 5:
            recent_trend = self._calculate_trend(performance_history[-5:])
            if recent_trend < -0.001:  # æ€§èƒ½ä¸‹é™
                urgency += 0.6
            elif recent_trend < 0.001:  # æ€§èƒ½åœæ»
                urgency += 0.4
        
        # åŸºäºç“¶é¢ˆä¸¥é‡ç¨‹åº¦
        bottleneck_severity = np.mean(list(candidate['bottleneck_indicators'].values()))
        urgency += bottleneck_severity * 0.4
        
        return min(1.0, urgency)
    
    def _generate_exploration_candidates(self, 
                                       model: nn.Module, 
                                       arch_features: Dict[str, float],
                                       context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¢ç´¢æ€§å€™é€‰ç‚¹"""
        
        exploration_candidates = []
        
        # å¦‚æœæ€§èƒ½åœæ»ï¼Œæ·»åŠ æ¢ç´¢æ€§å˜å¼‚
        performance_history = context.get('performance_history', [])
        if len(performance_history) >= 10:
            recent_improvement = performance_history[-1] - performance_history[-10]
            if recent_improvement < 0.01:  # æ€§èƒ½åœæ»
                
                # é€‰æ‹©ä¸€äº›éšæœºå±‚è¿›è¡Œæ¢ç´¢æ€§å˜å¼‚
                all_layers = [(name, module) for name, module in model.named_modules() 
                             if isinstance(module, (nn.Conv2d, nn.Linear))]
                
                if all_layers:
                    # éšæœºé€‰æ‹©1-2å±‚
                    selected_layers = np.random.choice(len(all_layers), 
                                                     size=min(2, len(all_layers)), 
                                                     replace=False)
                    
                    for idx in selected_layers:
                        name, module = all_layers[idx]
                        candidate = {
                            'layer_name': name,
                            'layer_type': type(module).__name__,
                            'module': module,
                            'bottleneck_indicators': {'exploration': 0.5},
                            'improvement_signals': {'exploration_driven': 0.6},
                            'improvement_potential': 0.5,
                            'urgency_score': 0.4,
                            'mutation_suitability': {
                                'width_expansion': 0.6,
                                'attention_enhancement': 0.5,
                                'residual_connection': 0.7
                            }
                        }
                        exploration_candidates.append(candidate)
        
        return exploration_candidates
    
    def _update_prior_with_history(self, mutation_type: str, arch_features: Dict[str, float]) -> Dict[str, float]:
        """åŸºäºå†å²æ•°æ®æ›´æ–°å…ˆéªŒ"""
        
        prior = self.mutation_priors.get(mutation_type, {'alpha': 5, 'beta': 5}).copy()
        
        # åŸºäºå†å²å˜å¼‚æ•°æ®æ›´æ–°
        relevant_history = [h for h in self.mutation_history 
                           if h.get('mutation_type') == mutation_type]
        
        if relevant_history:
            successes = sum(1 for h in relevant_history if h.get('success', False))
            failures = len(relevant_history) - successes
            
            # è´å¶æ–¯æ›´æ–°
            prior['alpha'] += successes
            prior['beta'] += failures
        
        return prior
    
    def _calculate_posterior_success_probability(self,
                                               prior: Dict[str, float],
                                               candidate: Dict[str, Any],
                                               mutation_type: str,
                                               arch_features: Dict[str, float]) -> float:
        """è®¡ç®—åéªŒæˆåŠŸæ¦‚ç‡"""
        
        # Betaåˆ†å¸ƒçš„æœŸæœ›å€¼
        alpha = prior['alpha']
        beta = prior['beta']
        base_prob = alpha / (alpha + beta)
        
        # åŸºäºå½“å‰æƒ…å†µè°ƒæ•´
        adjustment_factors = []
        
        # ç“¶é¢ˆä¸¥é‡ç¨‹åº¦è°ƒæ•´
        bottleneck_severity = np.mean(list(candidate['bottleneck_indicators'].values()))
        adjustment_factors.append(bottleneck_severity * 0.3)
        
        # å˜å¼‚é€‚ç”¨æ€§è°ƒæ•´
        suitability = candidate['mutation_suitability'].get(mutation_type, 0.5)
        adjustment_factors.append(suitability * 0.2)
        
        # æ¶æ„ç‰¹å¾è°ƒæ•´
        current_accuracy = arch_features.get('current_accuracy', 0.5)
        if current_accuracy < 0.6:  # ä½å‡†ç¡®ç‡æ—¶å˜å¼‚æ›´å®¹æ˜“æˆåŠŸ
            adjustment_factors.append(0.1)
        
        # ç»¼åˆè°ƒæ•´
        total_adjustment = sum(adjustment_factors)
        adjusted_prob = base_prob + total_adjustment
        
        return np.clip(adjusted_prob, 0.01, 0.99)
    
    def _build_gp_feature_vector(self,
                               candidate: Dict[str, Any],
                               mutation_type: str,
                               arch_features: Dict[str, float]) -> np.ndarray:
        """æ„å»ºé«˜æ–¯è¿‡ç¨‹ç‰¹å¾å‘é‡"""
        
        features = []
        
        # æ¶æ„ç‰¹å¾
        features.extend([
            arch_features.get('total_parameters', 0) / 1e6,  # æ ‡å‡†åŒ–
            arch_features.get('model_depth', 0) / 100,
            arch_features.get('current_accuracy', 0),
            arch_features.get('accuracy_trend', 0),
            arch_features.get('train_loss', 0)
        ])
        
        # å€™é€‰å±‚ç‰¹å¾
        features.extend([
            candidate.get('improvement_potential', 0),
            candidate.get('urgency_score', 0),
            np.mean(list(candidate['bottleneck_indicators'].values())),
            candidate['mutation_suitability'].get(mutation_type, 0)
        ])
        
        # å˜å¼‚ç±»å‹ç¼–ç ï¼ˆone-hotï¼‰
        mutation_types = ['width_expansion', 'depth_expansion', 'attention_enhancement', 
                         'residual_connection', 'batch_norm_insertion']
        mutation_encoding = [1.0 if mt == mutation_type else 0.0 for mt in mutation_types]
        features.extend(mutation_encoding)
        
        return np.array(features)
    
    def _gp_predict_improvement(self, feature_vector: np.ndarray, mutation_type: str) -> Tuple[float, float]:
        """é«˜æ–¯è¿‡ç¨‹é¢„æµ‹æ”¹è¿›å€¼"""
        
        # ç®€åŒ–çš„é«˜æ–¯è¿‡ç¨‹é¢„æµ‹ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨GPyTorchç­‰åº“ï¼‰
        # è¿™é‡Œä½¿ç”¨åŸºäºç‰¹å¾çš„å¯å‘å¼é¢„æµ‹
        
        # åŸºç¡€æ”¹è¿›é¢„æœŸ
        base_improvements = {
            'width_expansion': 0.02,
            'depth_expansion': 0.025,
            'attention_enhancement': 0.03,
            'residual_connection': 0.015,
            'batch_norm_insertion': 0.01,
            'parallel_division': 0.035,
            'serial_division': 0.02,
            'channel_attention': 0.025,
            'layer_norm': 0.012,
            'information_enhancement': 0.028
        }
        
        base_improvement = base_improvements.get(mutation_type, 0.015)
        
        # åŸºäºç‰¹å¾è°ƒæ•´
        feature_score = np.mean(feature_vector[:4])  # ä½¿ç”¨å‰4ä¸ªå…³é”®ç‰¹å¾
        adjustment = feature_score * 0.02
        
        mean_improvement = base_improvement + adjustment
        variance = (mean_improvement * 0.3) ** 2  # æ–¹å·®ä¸ºå‡å€¼çš„30%
        
        return mean_improvement, variance
    
    def _calculate_expected_utility(self,
                                  layer_name: str,
                                  mutation_type: str,
                                  success_probabilities: Dict[str, Dict[str, float]],
                                  improvement_predictions: Dict[str, Dict[str, Dict[str, float]]],
                                  uncertainty_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—æœŸæœ›æ•ˆç”¨"""
        
        success_prob = success_probabilities[layer_name][mutation_type]
        expected_improvement = improvement_predictions[layer_name][mutation_type]['mean_improvement']
        mc_analysis = uncertainty_analysis[layer_name][mutation_type]
        
        # æœŸæœ›æ”¶ç›Š
        expected_return = success_prob * expected_improvement
        
        # é£é™©è°ƒæ•´
        risk_penalty = (1 - success_prob) * abs(mc_analysis['value_at_risk_5%'])
        
        # æ•ˆç”¨è®¡ç®—
        utility = (expected_return * self.utility_params['accuracy_weight'] - 
                  risk_penalty * self.utility_params['risk_aversion'])
        
        # æ¢ç´¢å¥–åŠ±ï¼ˆé¼“åŠ±å°è¯•æ–°çš„å˜å¼‚ç±»å‹ï¼‰
        if mutation_type not in [h.get('mutation_type') for h in self.mutation_history[-10:]]:
            utility += self.utility_params['exploration_bonus']
        
        return utility
    
    def _calculate_decision_confidence(self,
                                     layer_name: str,
                                     mutation_type: str,
                                     uncertainty_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        
        mc_analysis = uncertainty_analysis[layer_name][mutation_type]
        
        # åŸºäºæ¦‚ç‡åˆ†å¸ƒçš„ç½®ä¿¡åº¦
        prob_positive = mc_analysis['probability_positive']
        
        # åŸºäºä¸ç¡®å®šæ€§çš„ç½®ä¿¡åº¦
        variance = mc_analysis['variance']
        uncertainty_penalty = np.exp(-variance * 10)  # æ–¹å·®è¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šä½
        
        confidence = prob_positive * uncertainty_penalty
        
        return confidence
    
    def _select_diverse_decisions(self, decisions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """é€‰æ‹©å¤šæ ·åŒ–çš„å†³ç­–"""
        
        if len(decisions) <= 3:
            return decisions
        
        selected = [decisions[0]]  # é€‰æ‹©æœ€ä¼˜çš„
        
        for decision in decisions[1:]:
            # æ£€æŸ¥å¤šæ ·æ€§
            is_diverse = True
            for selected_decision in selected:
                if (decision['layer_name'] == selected_decision['layer_name'] or
                    decision['mutation_type'] == selected_decision['mutation_type']):
                    is_diverse = False
                    break
            
            if is_diverse and len(selected) < 3:
                selected.append(decision)
        
        return selected
    
    def _generate_decision_rationale(self,
                                   candidate: Dict[str, Any],
                                   mutation_type: str,
                                   expected_utility: float,
                                   decision_confidence: float) -> str:
        """ç”Ÿæˆå†³ç­–ç†ç”±"""
        
        rationale_parts = []
        
        if expected_utility > 0.03:
            rationale_parts.append("é«˜æœŸæœ›æ•ˆç”¨")
        elif expected_utility > 0.01:
            rationale_parts.append("ä¸­ç­‰æœŸæœ›æ•ˆç”¨")
        
        if decision_confidence > 0.7:
            rationale_parts.append("é«˜ç½®ä¿¡åº¦é¢„æµ‹")
        elif decision_confidence > 0.4:
            rationale_parts.append("ä¸­ç­‰ç½®ä¿¡åº¦")
        
        bottleneck_severity = np.mean(list(candidate['bottleneck_indicators'].values()))
        if bottleneck_severity > 0.6:
            rationale_parts.append("æ˜¾è‘—ç“¶é¢ˆæ£€æµ‹")
        
        improvement_potential = candidate.get('improvement_potential', 0)
        if improvement_potential > 0.7:
            rationale_parts.append("é«˜æ”¹è¿›æ½œåŠ›")
        
        return "; ".join(rationale_parts) if rationale_parts else f"è´å¶æ–¯åˆ†ææ¨è{mutation_type}"
    
    def _calculate_overall_confidence(self, uncertainty_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
        
        all_confidences = []
        for layer_analysis in uncertainty_analysis.values():
            for mutation_analysis in layer_analysis.values():
                all_confidences.append(mutation_analysis['probability_positive'])
        
        return np.mean(all_confidences) if all_confidences else 0.0
    
    def _calculate_expected_gain(self, optimal_decisions: List[Dict[str, Any]]) -> float:
        """è®¡ç®—æœŸæœ›æ”¶ç›Š"""
        
        if not optimal_decisions:
            return 0.0
        
        total_gain = sum(d['expected_improvement'] * d['success_probability'] 
                        for d in optimal_decisions)
        return total_gain
    
    def _comprehensive_risk_assessment(self, optimal_decisions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç»¼åˆé£é™©è¯„ä¼°"""
        
        if not optimal_decisions:
            return {'overall_risk': 0.0, 'risk_factors': []}
        
        risks = []
        risk_factors = []
        
        for decision in optimal_decisions:
            risk_metrics = decision['risk_metrics']
            risks.append(abs(risk_metrics['value_at_risk']))
            
            if risk_metrics['probability_positive'] < 0.6:
                risk_factors.append(f"ä½æˆåŠŸæ¦‚ç‡: {decision['mutation_type']}")
            
            if abs(risk_metrics['expected_shortfall']) > 0.02:
                risk_factors.append(f"é«˜æœŸæœ›æŸå¤±: {decision['mutation_type']}")
        
        return {
            'overall_risk': np.mean(risks),
            'max_risk': np.max(risks),
            'risk_factors': risk_factors
        }
    
    def _update_bayesian_history(self,
                               arch_features: Dict[str, float],
                               candidates: List[Dict[str, Any]],
                               context: Dict[str, Any]):
        """æ›´æ–°è´å¶æ–¯å†å²"""
        
        history_entry = {
            'timestamp': context.get('epoch', 0),
            'architecture_features': arch_features.copy(),
            'candidates_found': len(candidates),
            'context_summary': {
                'current_accuracy': arch_features.get('current_accuracy', 0),
                'train_loss': context.get('train_loss', 0),
                'learning_rate': context.get('learning_rate', 0)
            }
        }
        
        self.architecture_features.append(arch_features)
        
        # æ›´æ–°æ€§èƒ½å†å²
        if 'current_accuracy' in arch_features:
            self.performance_history.append(arch_features['current_accuracy'])
    
    def _fallback_bayesian_analysis(self) -> Dict[str, Any]:
        """è´å¶æ–¯åˆ†æå¤±è´¥çš„å›é€€"""
        
        return {
            'bayesian_analysis': {
                'candidates_found': 0,
                'success_probabilities': {},
                'improvement_predictions': {},
                'uncertainty_analysis': {},
                'decision_confidence': 0.0
            },
            'optimal_decisions': [],
            'execution_plan': {
                'execute': False,
                'reason': 'bayesian_analysis_failed'
            },
            'bayesian_insights': {
                'most_promising_mutation': None,
                'expected_performance_gain': 0.0,
                'risk_assessment': {'overall_risk': 1.0, 'risk_factors': ['analysis_failure']}
            }
        }
    
    def update_mutation_outcome(self, 
                              mutation_type: str,
                              layer_name: str,
                              success: bool,
                              performance_change: float,
                              context: Dict[str, Any]):
        """æ›´æ–°å˜å¼‚ç»“æœï¼Œç”¨äºåœ¨çº¿å­¦ä¹ """
        
        outcome = {
            'mutation_type': mutation_type,
            'layer_name': layer_name,
            'success': success,
            'performance_change': performance_change,
            'timestamp': context.get('epoch', 0),
            'context': context.copy()
        }
        
        self.mutation_history.append(outcome)
        
        # æ›´æ–°å…ˆéªŒåˆ†å¸ƒ
        if mutation_type in self.mutation_priors:
            prior = self.mutation_priors[mutation_type]
            if success:
                prior['alpha'] += 1
            else:
                prior['beta'] += 1
        
        logger.info(f"ğŸ“Š æ›´æ–°å˜å¼‚ç»“æœ: {mutation_type} @ {layer_name} -> {'æˆåŠŸ' if success else 'å¤±è´¥'}")